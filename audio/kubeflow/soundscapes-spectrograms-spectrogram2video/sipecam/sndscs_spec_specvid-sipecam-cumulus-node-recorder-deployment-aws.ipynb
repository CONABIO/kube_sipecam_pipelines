{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "imports"
    ]
   },
   "outputs": [],
   "source": [
    "import base64\n",
    "import datetime\n",
    "import glob\n",
    "import hashlib\n",
    "import io\n",
    "import itertools\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import multiprocessing \n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import psutil\n",
    "import requests\n",
    "import shutil\n",
    "import subprocess\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "from dask.distributed import Client, LocalCluster\n",
    "from datetime import timedelta\n",
    "from dotenv import load_dotenv\n",
    "from matplotlib import cm\n",
    "from moviepy.editor import concatenate, VideoFileClip, AudioFileClip\n",
    "from moviepy.audio.AudioClip import AudioArrayClip\n",
    "from moviepy.video.VideoClip import ImageClip\n",
    "from os.path import exists as file_exists\n",
    "from PIL import Image\n",
    "from skimage.transform import resize\n",
    "\n",
    "from yuntu import Audio\n",
    "from yuntu.soundscape.utils import aware_time\n",
    "from yuntu.collection.methods import collection\n",
    "from yuntu.soundscape.hashers.crono import DEFAULT_HASHER_CONFIG\n",
    "from yuntu.soundscape.processors.indices.direct import ICOMPLEXITY, TAIL\n",
    "from yuntu.soundscape.pipelines.build_soundscape import CronoSoundscape, HASHER_CONFIG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "pipeline-parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# alfresco query\n",
    "CUMULO = 92 # INT\n",
    "SAMPLERATE = 48000.0\n",
    "PAGESIZE = 1000\n",
    "LIMIT = None\n",
    "# soundscape pltos\n",
    "RED_IDX = \"EXAG\"\n",
    "GREEN_IDX = \"INFORMATION\"\n",
    "BLUE_IDX = \"CORE\"\n",
    "MIN_FREQ_SC = 10000\n",
    "\n",
    "# soundscape computing\n",
    "WORK_DIR_PIPELINE = \".\"\n",
    "TIME_UNIT = 30\n",
    "FREQUENCY_BINS = 96 # 250 Hz x bin\n",
    "FREQUENCY_LIMITS_LB = 0\n",
    "FREQUENCY_LIMITS_UB = 24000\n",
    "SPECTRUM = \"Audible\"\n",
    "# Hasher \n",
    "HASHER_TIME_UNIT =  1800\n",
    "HASHER_TIME_MODULE = 48\n",
    "HASH_NAME = \"crono_hash_30m\"\n",
    "\n",
    "## cluster\n",
    "THREADS_PER_WORKER = 2\n",
    "\n",
    "# results directory\n",
    "RESULTS_DIR = '/shared_volume/audio/soundscapes'\n",
    "\n",
    "# uoload to alfresco\n",
    "ALFRESCO_NODE_ID = \"cf3a1b97-965d-489f-bfdf-5c8e26c4ac95\"\n",
    "BASE_ENDPOINT = \"alfresco/api/-default-/public/alfresco/versions/1\"\n",
    "AUTH_ENDPOINT = \"alfresco/api/-default-/public/authentication/versions/1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "functions"
    ]
   },
   "outputs": [],
   "source": [
    "def audio2video(audio_id,\n",
    "                identifier,\n",
    "                audio_df,\n",
    "                save_path_folder,\n",
    "                product_spectrum,\n",
    "                cumulus,\n",
    "                abs_start=None,\n",
    "                fps=60,\n",
    "                spec_configs={'hop_length': 512, 'n_fft': 1024, 'window_function': 'hann'},\n",
    "                rate=24,\n",
    "                frame_duration=3.0,\n",
    "                min_freq=0,\n",
    "                max_freq=None,\n",
    "                cmap=\"Greys\",\n",
    "                figsize=(5, 8),\n",
    "                dpi=100,\n",
    "                bands=None):\n",
    "    '''Takes and audio object and produces a mp4 video of the spectrogram with audio'''\n",
    "\n",
    "    sub_audio_df = audio_df[audio_df[\"id\"]==audio_id]\n",
    "    id_audio = sub_audio_df['id'].values[0]\n",
    "    node = sub_audio_df['node'].values[0]\n",
    "    recorder = sub_audio_df['recorder'].values[0]\n",
    "    deployment = sub_audio_df['deployment'].values[0]\n",
    "    audio = sub_audio_df.audio[0]\n",
    "    \n",
    "    colormap = cm.get_cmap(cmap)\n",
    "    duration = audio.duration\n",
    "    step = 1/rate\n",
    "    start = -(frame_duration/2.0)\n",
    "    stop = start + frame_duration\n",
    "    clips = []\n",
    "    last_stop = None\n",
    "\n",
    "    if max_freq is None:\n",
    "        max_freq = audio.samplerate / 2.0\n",
    "    \n",
    "    if min_freq is None:\n",
    "        min_freq = 0\n",
    "    \n",
    "\n",
    "    with audio.features.db_spectrogram(**spec_configs) as spec:\n",
    "        min_spec = np.amin(spec)\n",
    "        max_spec = np.amax(spec)\n",
    "        spec_range = (max_spec-min_spec)\n",
    "        \n",
    "        while stop <= duration+(frame_duration/2.0):\n",
    "            clip = produce_clip(spec, frame_duration, min_freq, max_freq, start, stop, step, abs_start, colormap,\n",
    "                                min_spec, spec_range, figsize, dpi, bands=bands)\n",
    "            clips.append(clip)\n",
    "            \n",
    "            if start + step + frame_duration > duration:\n",
    "                last_stop = stop\n",
    "\n",
    "            start = start + step\n",
    "            stop = start + frame_duration\n",
    "    \n",
    "    video = concatenate(clips)\n",
    "    # edaudio = AudioArrayClip(audio_array, fps=audio.samplerate)\n",
    "    edaudio = AudioFileClip(audio.path).set_end(audio.duration)\n",
    "    video = video.set_audio(edaudio)\n",
    "    file_path = os.path.join(save_path_folder, f\"{identifier}_spectrogram_video.mp4\")\n",
    "    video.write_videofile(file_path, fps=fps)\n",
    "    \n",
    "    save_metadata_videoclip(id_audio, identifier, product_spectrum,\n",
    "                  save_path_folder, cumulus, node, recorder, deployment, 0.0, audio.duration)\n",
    "    video.close()\n",
    "    edaudio.close()\n",
    "    \n",
    "    for c in clips:\n",
    "        c.close()\n",
    "\n",
    "def change_type_sipecam_sc(session, root_folder_id, path, file_type):\n",
    "    if file_type == \"sequence.png\":\n",
    "        metadata_name = \"soundscape_seq_metadata.json\"\n",
    "        aggr_type = \"None\"\n",
    "    elif file_type == \"mean_soundscape.png\":\n",
    "        metadata_name = \"mean_soundscape_metadata.json\"\n",
    "        aggr_type = \"Mean\"\n",
    "    elif file_type ==  \"std_soundscape.png\":\n",
    "        metadata_name = \"std_soundscape_metadata.json\" \n",
    "        aggr_type = \"Standard deviation\"\n",
    "    elif file_type == \"hashed_soundscape.parquet\":\n",
    "        metadata_name = \"soundscape_metadata.json.json\" \n",
    "        aggr_type = \"None\"\n",
    "\n",
    "    try:\n",
    "        semi_path = path.split(\"soundscapes/\")[-1]\n",
    "        semi_path_file = os.path.join(semi_path, file_type)\n",
    "        local_path_file_metadata = os.path.join(path, metadata_name)\n",
    "        print(f\"Changing type for {os.path.join(semi_path_file)}\")\n",
    "        alfresco_path = os.path.join(\"/Company Home/Sites/sipecam-soundscape/documentLibrary/\", semi_path)\n",
    "        response = session.get(\n",
    "            os.getenv(\"ALFRESCO_URL\")\n",
    "            + BASE_ENDPOINT\n",
    "            + \"/nodes/\"\n",
    "            + root_folder_id\n",
    "            + \"/children?relativePath=\"+semi_path_file+\"&include=aspectNames&skipCount=0&maxItems=1\"\n",
    "        )\n",
    "\n",
    "        # error flag\n",
    "        is_error = False\n",
    "\n",
    "        # if request is successful then continue\n",
    "        if response.status_code == 200:\n",
    "\n",
    "            data_file = open(local_path_file_metadata)\n",
    "            data_json = json.load(data_file)\n",
    "            response_entries = response.json()[\"list\"][\"entries\"][0]\n",
    "\n",
    "            if response_entries[\"entry\"][\"isFile\"]:\n",
    "\n",
    "                prop_dict = {}\n",
    "                # map properties\n",
    "                prop_dict[\"soundscape:CumulusName\"] = str(data_json[\"CumulusName\"])\n",
    "                prop_dict[\"soundscape:DateDeployment\"] = data_json[\"DateDeployment\"]\n",
    "                prop_dict[\"soundscape:NodeCategoryIntegrity\"] = str(data_json[\"NodeCategoryIntegrity\"])\n",
    "                prop_dict[\"soundscape:NomenclatureNode\"] = str(data_json[\"NomenclatureNode\"])\n",
    "                prop_dict[\"soundscape:SerialNumber\"] = str(data_json[\"SerialNumber\"])\n",
    "                prop_dict[\"soundscape:aggr\"] = str(aggr_type)\n",
    "                prop_dict[\"soundscape:cycle_config_aware_start\"] = str(data_json[\"product_configs\"]['hasher_config']['kwargs']['aware_start'])\n",
    "                prop_dict[\"soundscape:cycle_config_start_format\"] = str(data_json[\"product_configs\"]['hasher_config']['kwargs']['start_format'])\n",
    "                prop_dict[\"soundscape:cycle_config_start_time\"] = data_json[\"product_configs\"]['hasher_config']['kwargs']['start_time'] #\n",
    "                prop_dict[\"soundscape:cycle_config_start_tzone\"] = str(data_json[\"product_configs\"]['hasher_config']['kwargs']['start_tzone'])\n",
    "                prop_dict[\"soundscape:cycle_config_time_module\"] = int(data_json[\"product_configs\"]['hasher_config']['kwargs']['time_module'])\n",
    "                prop_dict[\"soundscape:cycle_config_time_unit\"] = str(data_json[\"product_configs\"]['hasher_config']['kwargs']['time_unit'])\n",
    "                prop_dict[\"soundscape:cycle_config_time_utc_column\"] = str(data_json[\"product_configs\"]['hasher_config']['kwargs']['time_utc_column'])\n",
    "                prop_dict[\"soundscape:frequency_bins\"] = int(data_json[\"product_configs\"][\"slice_config\"][\"frequency_bins\"])\n",
    "                prop_dict[\"soundscape:frequency_hop\"] = int(data_json[\"product_configs\"][\"slice_config\"][\"frequency_hop\"])\n",
    "                prop_dict[\"soundscape:frequency_limits\"] = str(data_json[\"product_configs\"][\"slice_config\"][\"frequency_limits\"])\n",
    "                prop_dict[\"soundscape:hash_name\"] = str(data_json[\"product_configs\"][\"hash_name\"])\n",
    "                prop_dict[\"soundscape:hop_length\"] = int(data_json[\"product_configs\"][\"slice_config\"][\"feature_config\"][\"hop_length\"])\n",
    "                prop_dict[\"soundscape:indices\"] = str(data_json['product_configs']['indices'])\n",
    "                prop_dict[\"soundscape:n_fft\"] = int(data_json[\"product_configs\"][\"slice_config\"][\"feature_config\"][\"n_fft\"])\n",
    "                prop_dict[\"soundscape:npartitions\"] = int(data_json[\"product_configs\"]['npartitions'])\n",
    "                prop_dict[\"soundscape:product_id\"] = str(data_json[\"product_id\"])\n",
    "                prop_dict[\"soundscape:product_name\"] = str(data_json[\"product_name\"])\n",
    "                prop_dict[\"soundscape:product_parent\"] = str(data_json[\"product_parent\"])\n",
    "                prop_dict[\"soundscape:product_path\"] = str(alfresco_path)\n",
    "                prop_dict[\"soundscape:product_spectrum\"] = str(data_json[\"product_spectrum\"])\n",
    "                prop_dict[\"soundscape:slice_config_feature_type\"] = str(data_json[\"product_configs\"][\"slice_config\"][\"feature_type\"])\n",
    "                prop_dict[\"soundscape:slice_config_frequency_bins\"] = int(data_json[\"product_configs\"][\"slice_config\"][\"frequency_bins\"])\n",
    "                prop_dict[\"soundscape:slice_config_time_unit\"] = int(data_json[\"product_configs\"][\"slice_config\"][\"time_unit\"])\n",
    "                prop_dict[\"soundscape:time_hop\"] = int(data_json[\"product_configs\"][\"slice_config\"][\"time_hop\"])\n",
    "                prop_dict[\"soundscape:window_function\"] = str(data_json[\"product_configs\"][\"slice_config\"][\"feature_config\"][\"window_function\"])\n",
    "\n",
    "\n",
    "                aspects = response_entries[\"entry\"][\"aspectNames\"]\n",
    "\n",
    "                data = {\"aspectNames\": aspects, \"nodeType\": 'soundscape:product', \"properties\": prop_dict}\n",
    "\n",
    "                # update properties request\n",
    "                update = session.put(\n",
    "                    os.getenv(\"ALFRESCO_URL\")\n",
    "                    + BASE_ENDPOINT\n",
    "                    + \"/nodes/\"\n",
    "                    + response_entries[\"entry\"][\"id\"],\n",
    "                    data=json.dumps(data),\n",
    "                )\n",
    "                print(update.json())\n",
    "                if update.status_code == 200:\n",
    "                    print(\"Updated \" + response_entries[\"entry\"][\"id\"])\n",
    "    except Exception as e:\n",
    "        print(\"Could not add any aspect to this file: \", e)\n",
    "        \n",
    "def create_results_folder_str(results_dir, cumulo, nodes_list, rec_list, dep_list): \n",
    "    # results directory\n",
    "    os.makedirs(results_dir, exist_ok=True)\n",
    "    # cumulus subdir\n",
    "    cum_subdir = os.path.join(results_dir, str(cumulo))\n",
    "    os.makedirs(cum_subdir, exist_ok=True)\n",
    "    # node subdirs\n",
    "    for node in nodes_list:\n",
    "        node_subdir = os.path.join(cum_subdir, node)\n",
    "        os.makedirs(node_subdir, exist_ok=True)\n",
    "        # recorder subdirs\n",
    "        for rec in rec_list:\n",
    "            rec_subdir = os.path.join(node_subdir, rec)\n",
    "            os.makedirs(rec_subdir, exist_ok=True)\n",
    "            # deployment subdirs\n",
    "            for dep in dep_list:\n",
    "                dep_subdir = os.path.join(rec_subdir, dep)\n",
    "                os.makedirs(dep_subdir, exist_ok=True)\n",
    "                \n",
    "def distance_to_mean(vector, mean):\n",
    "    '''Return euclidean distance to mean'''\n",
    "    return np.sqrt(np.sum(np.square(mean - vector)))\n",
    "\n",
    "def find_subfolders(path_abs):\n",
    "    subdir_list = []\n",
    "    walk = list(os.walk(path_abs))\n",
    "    for path, _, _ in walk[::-1]:\n",
    "        len_path = path.split(\"/\")\n",
    "        if len(len_path) == 8:\n",
    "            subdir_list.append(path)  \n",
    "            \n",
    "    return subdir_list\n",
    "\n",
    "def get_audio_ids(soundscape_path, indices):\n",
    "    df = pd.read_parquet(os.path.join(soundscape_path, \"hashed_soundscape.parquet\"))\n",
    "\n",
    "    with open(os.path.join(soundscape_path, \"soundscape_metadata.json\")) as f:\n",
    "        metadata = json.load(f)\n",
    "        f.close()\n",
    "\n",
    "    # indices = metadata[\"product_configs\"][\"indices\"]\n",
    "    # indices = [\"EXAG\", \"ICOMPLEXITY\", \"CORE\"]\n",
    "    hash_name = metadata[\"product_configs\"][\"hash_name\"]\n",
    "    cycle_config = metadata[\"product_configs\"][\"hasher_config\"][\"kwargs\"]\n",
    "    time_unit = cycle_config[\"time_unit\"]\n",
    "    zero_t = aware_time( cycle_config[\"start_time\"], cycle_config[\"start_tzone\"], cycle_config[\"start_format\"]) \n",
    "    \n",
    "    # sample\n",
    "    samples_df = get_recording_samples(df, hash_name, indices, time_unit, zero_t, nsamples=3)\n",
    "    sub_df = samples_df[samples_df.crono_hash_30m == 8]\n",
    "    audio_id_list = list(sub_df[\"id\"].unique())\n",
    "    \n",
    "    return audio_id_list\n",
    "\n",
    "def get_recording_samples(df, hash_name, indices, time_unit, zero_t, nsamples=5):\n",
    "    '''Return dataframe of 'nsamples' samples for each tag in 'hash_name' column that are closest to the mean vector by tag'''\n",
    "    proj_df = df[(df.max_freq <= 10000)]\n",
    "    crono_tags = proj_df.crono_hash_30m.unique()\n",
    "    proj_df.loc[: , f\"{hash_name}_time\"] = proj_df[hash_name].apply(lambda x: zero_t + datetime.timedelta(seconds=float(x*time_unit)))\n",
    "    vectors = vectorize_soundscape(proj_df, hash_name, indices)\n",
    "    min_index_vector = np.amin(np.stack(list(vectors.index_vector.values)), axis=(0,1))\n",
    "    max_index_vector = np.amax(np.stack(list(vectors.index_vector.values)), axis=(0,1))\n",
    "    index_range = (max_index_vector - min_index_vector)\n",
    "    vectors.loc[:, \"normalized_index_vector\"] = vectors.index_vector.apply(lambda x: (x-min_index_vector)/index_range)\n",
    "    all_samples = []\n",
    "\n",
    "    for crono_tag in crono_tags:\n",
    "        unit_vectors = vectors[vectors[hash_name] == crono_tag]\n",
    "        mean_unit_vector = unit_vectors.normalized_index_vector.mean()\n",
    "        unit_vectors.loc[:, \"distance\"] = unit_vectors.normalized_index_vector.apply(lambda x: distance_to_mean(x, mean_unit_vector))\n",
    "        all_samples.append(unit_vectors.sort_values(by=\"distance\").head(nsamples))\n",
    "\n",
    "    return pd.concat(all_samples)\n",
    "\n",
    "def get_vectors(group, indices):\n",
    "    '''Return array of indices by frequency'''\n",
    "    return group.sort_values(by=\"max_freq\")[indices].values\n",
    "\n",
    "def login():\n",
    "    \"\"\"\n",
    "    Tries a login to alfresco api and returns a session\n",
    "    object with credentials \n",
    "    Returns: \n",
    "        session (Session):  A session object to make \n",
    "                            requests to zendro.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        auth = {\n",
    "            \"userId\": os.getenv(\"ALFRESCO_USER\"),\n",
    "            \"password\": os.getenv(\"ALFRESCO_PASSWORD\"),\n",
    "        }\n",
    "\n",
    "        login = requests.post(os.getenv(\"ALFRESCO_URL\") + AUTH_ENDPOINT + \"/tickets\",data=json.dumps(auth))\n",
    "\n",
    "        base64_login = base64.b64encode(bytes(login.json()[\"entry\"][\"id\"], 'utf-8')).decode()\n",
    "\n",
    "        # se crea un objeto de Session para hacer requests\n",
    "        session = requests.Session()\n",
    "        # se establece bearer token\n",
    "        session.headers.update({'Authorization': 'Basic ' + base64_login})\n",
    "\n",
    "        return session\n",
    "    except Exception as e:\n",
    "        print(\"Login failed: \",e)\n",
    "\n",
    "def plot_spectrogram(audio_id, identifier, audio_df, save_path_folder, spectrum, cumulus):\n",
    "    sub_audio_df = audio_df[audio_df[\"id\"]==audio_id]\n",
    "    node = sub_audio_df['node'].values[0]\n",
    "    recorder = sub_audio_df['recorder'].values[0]\n",
    "    deployment = sub_audio_df['deployment'].values[0]\n",
    "    # plot\n",
    "    fig, ax = plt.subplots(2,1,figsize=(20,10), sharex=True)\n",
    "    sub_audio_df.audio[0].plot(ax=ax[0], color='grey')\n",
    "    sub_audio_df.audio[0].features.db_spectrogram().plot(ax=ax[1])\n",
    "    ax[0].set_ylabel('Amplitude')\n",
    "    ax[0].grid(False)\n",
    "    ax[1].set_ylabel('F (KHz)')\n",
    "    ax[1].set_xlabel('Time (seconds)')\n",
    "    fig.text(0.75, 0.04, f\"Cumulus: {cumulus} - Node: {node} - Recorder: {recorder}\", va='center')\n",
    "    plt.show()\n",
    "    if save_path_folder:\n",
    "        file_path = os.path.join(save_path_folder, f\"{identifier}_spectrogram.png\")\n",
    "        fig.savefig(file_path)\n",
    "    \n",
    "    save_metadata_spectrogram(audio_id, identifier, spectrum, save_path_folder, \n",
    "                              cumulus, node, recorder, deployment, parent=\"Null\")\n",
    "    \n",
    "def plot_soundscape(soundscape, product_type, product_spectrum, sc_config, path, \n",
    "                    cumulus, node, recorder, deployment, parent, indices, min_freq=None,\n",
    "                  figsize=(20,15), plt_style='ggplot'):\n",
    "    \n",
    "    if min_freq:\n",
    "        soundscape = soundscape[soundscape['min_freq']<=min_freq]\n",
    "        \n",
    "    if product_type == \"sequence\":\n",
    "        file_path = os.path.join(path, \"sequence.png\")\n",
    "        product_id = hashlib.md5(file_path.encode('utf-8')).hexdigest()\n",
    "        \n",
    "        plt.style.use(plt_style)\n",
    "        fig, ax = plt.subplots(figsize=figsize)\n",
    "        soundscape.sndscape.plot_sequence(rgb=indices, time_format='%Y-%m %H:%M', ax=ax)\n",
    "        plt.xticks(rotation = 90)\n",
    "        ax.grid(False)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(file_path) \n",
    "        plt.show()\n",
    "        # save metadata\n",
    "        save_metadata_sc(product_id, product_type, product_spectrum, sc_config,\n",
    "                  path, cumulus, node, recorder, deployment, parent=parent)\n",
    "         \n",
    "    elif product_type == \"standard_deviation\":\n",
    "        file_path = os.path.join(path, \"std_soundscape.png\")\n",
    "        product_id = hashlib.md5(file_path.encode('utf-8')).hexdigest()\n",
    "        \n",
    "        plt.style.use(plt_style)\n",
    "        fig, ax = plt.subplots(figsize=figsize)\n",
    "        soundscape.sndscape.plot_cycle(rgb=indices, aggr=\"std\", time_format='%H:%M', \n",
    "                                       xticks=24, ax=ax)\n",
    "        plt.xticks(rotation = 90)\n",
    "        ax.grid(False)\n",
    "        plt.tight_layout() \n",
    "        plt.savefig(file_path)\n",
    "        plt.show()\n",
    "        \n",
    "        # save metadata\n",
    "        save_metadata_sc(product_id, product_type, product_spectrum, sc_config,\n",
    "                  path, cumulus, node, recorder, deployment, parent)     \n",
    "        \n",
    "    elif product_type == \"mean\": \n",
    "        file_path = os.path.join(path, \"mean_soundscape.png\")\n",
    "        product_id = hashlib.md5(file_path.encode('utf-8')).hexdigest()\n",
    "        \n",
    "        plt.style.use(plt_style)\n",
    "        fig, ax = plt.subplots(figsize=figsize)\n",
    "        soundscape.sndscape.plot_cycle(rgb=indices, aggr=\"mean\", time_format='%H:%M', \n",
    "                                       xticks=24, ax=ax)\n",
    "        plt.xticks(rotation = 90)\n",
    "        ax.grid(False)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(file_path)\n",
    "        plt.show()\n",
    "        \n",
    "        # save metadata\n",
    "        save_metadata_sc(product_id, product_type, product_spectrum, sc_config,\n",
    "                  path, cumulus, node, recorder, deployment, parent)    \n",
    "        \n",
    "    print(f\"File saved at {file_path}\")\n",
    "    \n",
    "def produce_clip(spec, frame_duration, min_freq, max_freq, start, stop, step, abs_start=None, \n",
    "                 colormap=cm.get_cmap(\"Greys\"), min_spec=0, spec_range=1.0, figsize=(5, 4), \n",
    "                 dpi=100, bands=None):\n",
    "    '''Takes an individual frame and produces an image with references'''\n",
    "    frame = spec.cut_array(start_time=start, end_time=stop, min_freq=min_freq, max_freq=max_freq, pad=True)\n",
    "    plt.style.use('dark_background')\n",
    "    frame = np.flip((frame - min_spec)/spec_range, axis=0)\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    ax.imshow(frame, cmap=colormap, extent=[0, frame_duration, min_freq/1000, max_freq/1000], \n",
    "              aspect=\"auto\", vmin = 0, vmax = 1.0)\n",
    "\n",
    "    if bands is not None:\n",
    "        band_arr = np.flip(resize(np.expand_dims(bands, axis=1), (frame.shape[0], frame.shape[1])), axis=0)\n",
    "        ax.imshow(band_arr, extent=[0, frame_duration, min_freq/1000, max_freq/1000], aspect=\"auto\", vmin = 0, \n",
    "                  vmax = 1.0, alpha=0.5)\n",
    "\n",
    "    ax.tick_params(axis='both', which='major', labelsize=8)\n",
    "    ax.tick_params(axis='both', which='minor', labelsize=8)\n",
    "    mid = frame_duration/2.0\n",
    "    ax.axvline(x=mid, color=\"red\")\n",
    "    ax.set_ylabel('F (kHz)')\n",
    "    ax.set_xticks([])\n",
    "    ax.set_xticks([], minor=True)\n",
    "\n",
    "    if abs_start is not None:\n",
    "        time_text = (abs_start + datetime.timedelta(seconds=start+mid)).strftime('%H:%M:%S.%f').strip()[:-4]\n",
    "        ax.text(mid-0.3, -0.6, time_text)\n",
    "\n",
    "    buf = io.BytesIO()\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(buf, dpi=dpi)\n",
    "    buf.seek(0)\n",
    "    im = Image.open(buf)\n",
    "    im.format = \"PNG\"\n",
    "    plt.close(fig)\n",
    "\n",
    "    return ImageClip(np.asarray(im),\n",
    "                     duration=step)\n",
    "    \n",
    "def remove_empty_folders(path_abs):\n",
    "    walk = list(os.walk(path_abs))\n",
    "    for path, _, _ in walk[::-1]:\n",
    "        if len(os.listdir(path)) == 0:\n",
    "            os.rmdir(path)            \n",
    "            \n",
    "def save_metadata_sc(product_id, product_type, product_spectrum, sc_config,\n",
    "                  path, cumulus, node, recorder, deployment, parent=\"Null\"):\n",
    "    if product_type == \"soundscape\":\n",
    "        product_name = \"Soundscape\"\n",
    "        file_path = os.path.join(path, \"hashed_soundscape.parquet\")\n",
    "        metadata_filename = os.path.join(path, \"soundscape_metadata.json\")\n",
    "    elif product_type == \"sequence\":\n",
    "        product_name = \"Soundscape sequential plot\"\n",
    "        file_path = os.path.join(path, \"soundscape_seq.png\")\n",
    "        metadata_filename = os.path.join(path, \"soundscape_seq_metadata.json\")\n",
    "    elif product_type == \"standard_deviation\":\n",
    "        product_name = \"Soundscape standard deviation plot\"\n",
    "        file_path = os.path.join(path, \"std_soundscape.png\")\n",
    "        metadata_filename = os.path.join(path, \"std_soundscape_metadata.json\")\n",
    "    elif product_type == \"mean\":\n",
    "        product_name = \"Soundscape mean plot\"\n",
    "        file_path = os.path.join(path, \"mean_soundscape.png\")\n",
    "        metadata_filename = os.path.join(path, \"mean_soundscape_metadata.json\")\n",
    "    \n",
    "    if int(node.split(\"_\")[2]) == 0:\n",
    "        node_category = \"Degradado\"\n",
    "    elif int(node.split(\"_\")[2]) == 1:\n",
    "        node_category = \"Integro\"\n",
    "\n",
    "    metadata = {\n",
    "        \"product_id\": product_id,\n",
    "        \"product_parent\": parent,\n",
    "        \"product_name\": product_name,\n",
    "        \"product_configs\": sc_config,\n",
    "        \"product_path\": file_path,\n",
    "        \"product_spectrum\": product_spectrum,\n",
    "        \"CumulusName\": cumulus,\n",
    "        \"NodeCategoryIntegrity\": node_category,\n",
    "        \"NomenclatureNode\": node,\n",
    "        \"SerialNumber\": recorder,\n",
    "        \"DateDeployment\": deployment\n",
    "    }\n",
    "    \n",
    "    with open(metadata_filename, 'w', encoding='utf-8') as f:\n",
    "        json.dump(metadata, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "def save_metadata_spectrogram(product_id, identifier, product_spectrum,\n",
    "                  path, cumulus, node, recorder, deployment, parent=\"Null\"):\n",
    "    product_name = \"Spectrogram\"\n",
    "    file_path = os.path.join(path, f\"{identifier}_spectrogram.png\")\n",
    "    metadata_filename = os.path.join(path, f\"{identifier}_spectrogram_metadata.json\")\n",
    "\n",
    "    if int(node.split(\"_\")[2]) == 0:\n",
    "        node_category = \"Degradado\"\n",
    "    elif int(node.split(\"_\")[2]) == 1:\n",
    "        node_category = \"Integro\"\n",
    "\n",
    "    metadata = {\n",
    "        \"product_id\": product_id,\n",
    "        \"product_parent\": parent,\n",
    "        \"product_name\": product_name,\n",
    "        \"product_path\": file_path,\n",
    "        \"product_spectrum\": product_spectrum,\n",
    "        \"CumulusName\": cumulus,\n",
    "        \"NodeCategoryIntegrity\": node_category,\n",
    "        \"NomenclatureNode\": node,\n",
    "        \"SerialNumber\": recorder,\n",
    "        \"DateDeployment\": deployment\n",
    "    }\n",
    "    with open(metadata_filename, 'w', encoding='utf-8') as f:\n",
    "        json.dump(metadata, f, ensure_ascii=False, indent=4)\n",
    "        \n",
    "    print(f\"{file_path} saved.\")\n",
    "    print(f\"{metadata_filename} saved.\")\n",
    "    \n",
    "def save_metadata_videoclip(product_id, identifier, product_spectrum, path, cumulus, node, recorder, \n",
    "                            deployment, clip_start, clip_end, parent=\"Null\"):\n",
    "    product_name = \"spectrogram_video\"\n",
    "    file_path = os.path.join(path, f\"{identifier}_spectrogram_video.mp4\")\n",
    "    metadata_filename = os.path.join(path, f\"{identifier}_spectrogram_video_metadata.json\")\n",
    "\n",
    "    if int(node.split(\"_\")[2]) == 0:\n",
    "        node_category = \"Degradado\"\n",
    "    elif int(node.split(\"_\")[2]) == 1:\n",
    "        node_category = \"Integro\"\n",
    "\n",
    "    metadata = {\n",
    "        \"product_id\": product_id,\n",
    "        \"product_parent\": \"Null\",\n",
    "        \"product_name\": product_name,\n",
    "        \"product_path\": file_path,\n",
    "        \"product_spectrum\": product_spectrum,\n",
    "        \"CumulusName\": cumulus,\n",
    "        \"NodeCategoryIntegrity\": node_category,\n",
    "        \"NomenclatureNode\": node,\n",
    "        \"SerialNumber\": recorder,\n",
    "        \"DateDeployment\": deployment,\n",
    "        \"ClipStart\": clip_start,\n",
    "        \"ClipEnd\": clip_end\n",
    "    }\n",
    "    \n",
    "    with open(metadata_filename, 'w', encoding='utf-8') as f:\n",
    "        json.dump(metadata, f, ensure_ascii=False, indent=4)\n",
    "        \n",
    "    print(f\"{file_path} saved.\")\n",
    "    print(f\"{metadata_filename} saved.\")\n",
    "    \n",
    "def upload(session, node_id, data, file):\n",
    "    \"\"\"\n",
    "    Uploads a file to a specific folder.\n",
    "    Parameters:\n",
    "        session (Session):          A session object to make\n",
    "                                    requests to alfresco.\n",
    "        node_id (string):           Node id to which the file is going to be created\n",
    "        data (dict):                Dict that contains file options\n",
    "        file (object):              File to upload\n",
    "    \n",
    "    Returns:\n",
    "        (list):     A list containing status code and status data\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        response = session.post(os.getenv(\"ALFRESCO_URL\")\n",
    "                    + BASE_ENDPOINT + \"/nodes/\" + node_id + \"/children\",\n",
    "                    data = data,\n",
    "                    files = file\n",
    "                    )\n",
    "                    \n",
    "        return [response.json(), response.status_code];\n",
    "    except Exception as e: \n",
    "        print(\"File \" + data[\"name\"] + \" could not be uploaded: \", e)\n",
    "\n",
    "def upload_files(file_patterns ,session, node_id, dir_path, recursive, file_identifier=\"\"):\n",
    "    \"\"\"\n",
    "    Uploads the files stored in a specific dir\n",
    "    to alfresco\n",
    "    Parameters:\n",
    "        session (Session):          A session object to make\n",
    "                                    requests to alfresco.\n",
    "        node_id (string):           Node id to which the file is going to be created\n",
    "        dir_path (string):          The name and path of the dir where files are stored\n",
    "        recursive (boolean):        A boolean to know if upload  must be recursive\n",
    "                                    in the specifed dir, and should preserve the\n",
    "                                    structure of dirs inside.\n",
    "        file_identifier (string):   File identifier for all files inside a dir\n",
    "    Returns:\n",
    "        (string):           Returns the info of recent created site.\n",
    "    \"\"\"\n",
    "\n",
    "    if recursive:\n",
    "        expression = \"/**/*\"\n",
    "    else:\n",
    "        expression = \"/*\"\n",
    "\n",
    "    files_in_dir = list(\n",
    "        itertools.chain.from_iterable(\n",
    "            glob.iglob(dir_path + expression + pattern, recursive=recursive)\n",
    "            for pattern in file_patterns\n",
    "        )\n",
    "    )\n",
    "    print(\"files_in_dir\", files_in_dir)\n",
    "    filename = \"logs/upload_log\" + dir_path.replace('/','-') + '.txt'\n",
    "    \n",
    "    os.makedirs(os.path.dirname(filename), exist_ok=True)\n",
    "\n",
    "    total_files = len(files_in_dir)\n",
    "    print(total_files)\n",
    "    starttime = time.time()\n",
    "\n",
    "    try:\n",
    "        files_uploaded = []\n",
    "        for idx, file_with_path in enumerate(files_in_dir):\n",
    "\n",
    "            # total time since last login or script start\n",
    "            total_time = round((time.time() - starttime), 2)\n",
    "\n",
    "            if total_time > 2400:\n",
    "                \"\"\"\n",
    "                if total time is bigger than 2400\n",
    "                or 40 minutes relogin to avoid ticket\n",
    "                expiration\n",
    "                \"\"\"\n",
    "                time.sleep(5)\n",
    "\n",
    "                print(\"Re-logging in to alfresco...\")\n",
    "\n",
    "                session = login.login()\n",
    "                # restart time\n",
    "                starttime = time.time()\n",
    "                time.sleep(5)\n",
    "                print(\"Login sucessful, continuing upload\\n\")\n",
    "\n",
    "            len_of_path = len(file_with_path.split(\"/\"))\n",
    "            name_of_file = file_with_path.split(\"/\")[len_of_path - 1]\n",
    "            root_dir_path = file_with_path.replace(dir_path, \"\").replace(\n",
    "                file_with_path.split(\"/\")[len_of_path - 1], \"\"\n",
    "            )\n",
    "\n",
    "            data = {\n",
    "                \"name\": (\n",
    "                    name_of_file[0 : len(name_of_file) - 4]\n",
    "                    + file_identifier\n",
    "                    + name_of_file[len(name_of_file) - 4 : len(name_of_file)]\n",
    "                ),\n",
    "                \"nodeType\": \"cm:content\",\n",
    "            }\n",
    "\n",
    "            data[\"relativePath\"] = root_dir_path\n",
    "\n",
    "            data[\"properties\"] = {\n",
    "                \"cm:title\": (\n",
    "                    name_of_file[0 : len(name_of_file) - 4]\n",
    "                    + file_identifier\n",
    "                    + name_of_file[len(name_of_file) - 4 : len(name_of_file)]\n",
    "                )\n",
    "            }\n",
    "\n",
    "            print(\"Uploading \" + data[\"name\"] + \" file...\")\n",
    "\n",
    "            files = {\"filedata\": open(file_with_path, \"rb\")}\n",
    "            upload_response = upload(session, node_id, data, files)\n",
    "            if upload_response[1] and upload_response[1] == 201:\n",
    "                files_uploaded.append(upload_response[0])\n",
    "                print(\"Uploaded \" + data[\"name\"])\n",
    "\n",
    "                filename = \"logs/upload_log\" + dir_path.replace('/','-') + '.txt'\n",
    "                with open(filename, 'a') as log_file:\n",
    "                    log_file.writelines(\"%s\\n\" % file_with_path)\n",
    "\n",
    "            elif upload_response[1] and upload_response[1] == 409:\n",
    "                if \"already exists\" in upload_response[0][\"error\"][\"errorKey\"]:\n",
    "                    print(\"File \" + data[\"name\"] + \" already uploaded\")\n",
    "\n",
    "            else:\n",
    "                print(\"An error ocurred, file \" + data[\"name\"] + \" cannot be uploaded\")\n",
    "\n",
    "            print(\"Uploaded file \" + str(idx + 1) + \" of \" + str(total_files))\n",
    "            print(\"\\n\\n\")\n",
    "\n",
    "        return files_uploaded\n",
    "    except Exception as e:\n",
    "        print(\"An error ocurred in file upload: \", e)\n",
    "    \n",
    "def vectorize_soundscape(df, hash_name, indices):\n",
    "    '''Return dataframe with array column containing indices by frequency'''\n",
    "    return (df\n",
    "            .groupby(by=[\"id\", hash_name, \"start_time\", \"end_time\"])\n",
    "            .apply(get_vectors, indices)\n",
    "            .reset_index()\n",
    "            .rename(columns={0:\"index_vector\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## SoundScapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "block:get_audio_df"
    ]
   },
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "DB_CONFIG = {\n",
    "    'provider': 'alfresco',\n",
    "    'config': {\n",
    "        'api_url': 'https://api.conabio.gob.mx/test',\n",
    "        'page_size': PAGESIZE,\n",
    "        'api_key': os.getenv(\"X_API_KEY\"),\n",
    "        'base_filter': \"+TYPE: \\\"sipecam:audio\\\" AND -TYPE: \\\"dummyType\\\"\",\n",
    "        'recording_parser': {\"path\": \"/shared_volume/audio/utils.py\",\n",
    "                             \"object_name\": \"parser\"}\n",
    "    }\n",
    "}\n",
    "\n",
    "COL_CONFIG = {\n",
    "    \"col_type\": \"alfresco\",\n",
    "    \"db_config\": DB_CONFIG\n",
    "}\n",
    "\n",
    "col = collection(**COL_CONFIG)\n",
    "query = f\"(sipecam:CumulusName:\\\"{CUMULO}\\\") AND (sipecam:SampleRate:{SAMPLERATE})\"\n",
    "\n",
    "if LIMIT:\n",
    "    recs = col.get_recording_dataframe(query, limit=LIMIT, with_metadata = True, with_geometry = False)\n",
    "else:\n",
    "    recs = col.get_recording_dataframe(query, with_metadata = True, with_geometry = False)\n",
    "\n",
    "# include filtering columns for processing units\n",
    "recs.loc[:, \"node\"] = recs.metadata.apply(lambda x: x[\"entry\"][\"properties\"][\"sipecam:NomenclatureNode\"])\n",
    "recs.loc[:, \"recorder\"] = recs.metadata.apply(lambda x: x[\"entry\"][\"properties\"][\"sipecam:SerialNumber\"]) \n",
    "recs.loc[:, \"deployment\"] = recs.metadata.apply(lambda x: x[\"entry\"][\"path\"][\"name\"].split(\"/audio\")[0].split(\"/\")[-1])\n",
    "recs.loc[:,\"proc_unit\"] = recs.apply(lambda x: (x[\"node\"], x[\"recorder\"], x[\"deployment\"]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "block:create_results_dirstruct",
     "prev:get_audio_df"
    ]
   },
   "outputs": [],
   "source": [
    "# create results folder structure\n",
    "nodes_list = recs.node.unique()\n",
    "recorders_list = recs.recorder.unique()\n",
    "deployments_list = recs.deployment.unique()\n",
    "if os.path.isdir(RESULTS_DIR):\n",
    "    shutil.rmtree(RESULTS_DIR)\n",
    "create_results_folder_str(RESULTS_DIR, CUMULO, nodes_list, recorders_list, deployments_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "block:compute_soundscapes",
     "prev:create_results_dirstruct",
     "prev:get_audio_df"
    ]
   },
   "outputs": [],
   "source": [
    "# hasher config \n",
    "hasher_config = {'module': {'object_name': 'yuntu.soundscape.hashers.crono.CronoHasher'},\n",
    "                 'kwargs': {'time_utc_column': 'abs_start_time'}}\n",
    "\n",
    "hasher_config[\"kwargs\"][\"time_unit\"] = HASHER_TIME_UNIT\n",
    "hasher_config[\"kwargs\"][\"time_module\"] = HASHER_TIME_MODULE\n",
    "hasher_config[\"kwargs\"][\"start_tzone\"] = \"America/Mexico_City\"\n",
    "hasher_config[\"kwargs\"][\"start_time\"] = DEFAULT_HASHER_CONFIG[\"start_time\"]\n",
    "hasher_config[\"kwargs\"][\"start_format\"] = DEFAULT_HASHER_CONFIG[\"start_format\"]\n",
    "hasher_config[\"kwargs\"][\"aware_start\"] = None\n",
    "\n",
    "# soundscape config \n",
    "slice_config  = dict(CronoSoundscape()[\"slice_config\"].data)\n",
    "slice_config[\"time_unit\"] = TIME_UNIT\n",
    "slice_config[\"frequency_bins\"] = FREQUENCY_BINS\n",
    "slice_config[\"frequency_limits\"] = (FREQUENCY_LIMITS_LB, FREQUENCY_LIMITS_UB)\n",
    "\n",
    "# FED configuration [\"TOTAL\", \"CORE\", \"TAIL\", \"INFORMATION\", \"ICOMPLEXITY\", \"EXAG\"]\n",
    "indices = CronoSoundscape()[\"indices\"].data + [ICOMPLEXITY()]  + [TAIL()]\n",
    "\n",
    "# dask local cluster\n",
    "n_workers = int(0.95 * multiprocessing .cpu_count()) \n",
    "cluster = LocalCluster(n_workers = n_workers, \n",
    "                       threads_per_worker = THREADS_PER_WORKER)\n",
    "client = Client(cluster)\n",
    "npartitions = len(client.ncores())\n",
    "\n",
    "# FEED\n",
    "FEED = {\n",
    "    \"slice_config\": slice_config,\n",
    "    \"indices\": indices,\n",
    "    \"hash_name\": HASH_NAME,\n",
    "    \"hasher_config\": hasher_config,\n",
    "    \"npartitions\": npartitions\n",
    "}\n",
    "\n",
    "# adjust for metadata\n",
    "indexes_computed = [\"TOTAL\", \"CORE\", \"TAIL\", \"INFORMATION\", \"ICOMPLEXITY\", \"EXAG\"]\n",
    "FEED_metadata = FEED.copy()\n",
    "FEED_metadata[\"indices\"] = indexes_computed\n",
    "\n",
    "plot_indices = [RED_IDX, GREEN_IDX, BLUE_IDX] # rgb order\n",
    "\n",
    "# soundscape per unit (cumulus-node-recorder-deployment_date)\n",
    "proc_units = recs.proc_unit.unique()\n",
    "\n",
    "for proc_unit in proc_units:\n",
    "    try: \n",
    "        start_soundscape = time.monotonic()\n",
    "        node, recorder, deployment = proc_unit\n",
    "        print(f\"* Processing: node {node} | recorder {recorder} | deployment date {deployment}\")\n",
    "        file_path = os.path.join(RESULTS_DIR, str(CUMULO), str(node), recorder, deployment)\n",
    "        parent_id = hashlib.md5(file_path.encode('utf-8')).hexdigest()\n",
    "        # soundscape = recs[recs.proc_unit == proc_unit].audio.get_soundscape(client=client, npartitions=n_workers, **soundscape_config)\n",
    "        soundscape_data = recs[recs.proc_unit == proc_unit]\n",
    "        pipeline = CronoSoundscape(name = \"soundscape\", work_dir = WORK_DIR_PIPELINE, recordings = soundscape_data)\n",
    "        soundscape = pipeline[\"hashed_soundscape\"].compute(client=client, feed=FEED)\n",
    "\n",
    "        # sequence\n",
    "        plot_soundscape(soundscape, \"sequence\", SPECTRUM, FEED_metadata, file_path,\n",
    "                        CUMULO, node, recorder, deployment, parent_id, plot_indices, MIN_FREQ_SC)    \n",
    "        # mean\n",
    "        plot_soundscape(soundscape, \"mean\", SPECTRUM, FEED_metadata, file_path, \n",
    "                        CUMULO, node, recorder, deployment, parent_id, plot_indices, MIN_FREQ_SC)\n",
    "\n",
    "        # standard deviation\n",
    "        plot_soundscape(soundscape, \"standard_deviation\", SPECTRUM, FEED_metadata, file_path, \n",
    "                        CUMULO, node, recorder, deployment, parent_id, plot_indices, MIN_FREQ_SC)\n",
    "\n",
    "        # save soundscape vector\n",
    "        soundscape_path = os.path.join(file_path, \"hashed_soundscape.parquet\")\n",
    "        # soundscape_orig_path = os.path.join(RESULTS_DIR, \"get_soundscape/persist/hashed_soundscape.parquet\") \n",
    "        soundscape_orig_path = '/shared_volume/audio/soundscape/persist/hashed_soundscape.parquet'\n",
    "        shutil.move(soundscape_orig_path,soundscape_path)\n",
    "        save_metadata_sc(parent_id, \"soundscape\", SPECTRUM, FEED_metadata, file_path,\n",
    "                      CUMULO, node, recorder, deployment)\n",
    "        shutil.rmtree('/shared_volume/audio/soundscape')\n",
    "\n",
    "    except:\n",
    "        pass\n",
    "    # restart client\n",
    "    client.restart()\n",
    "\n",
    "    \n",
    "client.close()\n",
    "cluster.close()\n",
    "\n",
    "# remove empty subdirectories\n",
    "remove_empty_folders(RESULTS_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Spectrograms & Spectrogram Videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "block:spec_n_specvid",
     "prev:compute_soundscapes"
    ]
   },
   "outputs": [],
   "source": [
    "plt.style.use('dark_background')\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "sub_folder_results = find_subfolders(RESULTS_DIR)\n",
    "\n",
    "for sc_path in sub_folder_results:\n",
    "    ids_audios = get_audio_ids(sc_path, indices = [\"EXAG\", \"ICOMPLEXITY\", \"CORE\"])\n",
    "    idx_audio = 1\n",
    "    for id_audio in ids_audios:\n",
    "        print(f\"Processing audio {id_audio}\")\n",
    "        plot_spectrogram(id_audio, f\"spl{idx_audio}\", recs, sc_path, SPECTRUM, CUMULO)   \n",
    "        audio2video(id_audio, f\"spl{idx_audio}\", recs, sc_path, SPECTRUM, CUMULO)\n",
    "        idx_audio += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Upload files to alfresco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "block:upload_to_alfresco",
     "prev:spec_n_specvid"
    ]
   },
   "outputs": [],
   "source": [
    "FILE_PATTERNS = [\".mp4\", \".png\"] #\".parquet\"\n",
    "session = login()\n",
    "upload_files(FILE_PATTERNS, session, ALFRESCO_NODE_ID, RESULTS_DIR, recursive= True, file_identifier=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Assign metadata to alfresco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "block:upload_alfresco_model_data",
     "prev:upload_to_alfresco"
    ]
   },
   "outputs": [],
   "source": [
    "session = login()\n",
    "for sc_path in sub_folder_results:\n",
    "    for file_type in [\"sequence.png\", \"mean_soundscape.png\", \"std_soundscape.png\"]:\n",
    "        change_type_sipecam_sc(session, ALFRESCO_NODE_ID, sc_path, file_type)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "kubeflow_notebook": {
   "autosnapshot": false,
   "docker_image": "sipecam/audio-dgpi-kale-tensorflow-yuntu-dask-cert:0.6.1_dev",
   "experiment": {
    "id": "9781c353-80ec-416a-8557-a802c70b7523",
    "name": "Default"
   },
   "experiment_name": "Default",
   "katib_metadata": {
    "algorithm": {
     "algorithmName": "grid"
    },
    "maxFailedTrialCount": 3,
    "maxTrialCount": 12,
    "objective": {
     "objectiveMetricName": "",
     "type": "minimize"
    },
    "parallelTrialCount": 3,
    "parameters": []
   },
   "katib_run": false,
   "pipeline_description": "Computes Sipecam Soundscapes using cumulus, node, recorder and deployment",
   "pipeline_name": "sound-scape-nod-rec-dep",
   "snapshot_volumes": false,
   "steps_defaults": [],
   "volume_access_mode": "rwm",
   "volumes": [
    {
     "annotations": [],
     "mount_point": "/shared_volume",
     "name": "hostpath-pvc",
     "size": 1,
     "size_type": "Gi",
     "snapshot": false,
     "snapshot_name": "",
     "type": "pvc"
    }
   ]
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
