{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "imports"
    ]
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import hashlib\n",
    "import json\n",
    "import multiprocessing \n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "import psutil\n",
    "import shutil\n",
    "import subprocess\n",
    "import time\n",
    "\n",
    "from dask.distributed import Client, LocalCluster\n",
    "from datetime import timedelta\n",
    "from dotenv import load_dotenv\n",
    "from os.path import exists as file_exists\n",
    "\n",
    "from yuntu.collection.methods import collection\n",
    "from yuntu.soundscape.hashers.crono import DEFAULT_HASHER_CONFIG\n",
    "from yuntu.soundscape.processors.indices.direct import ICOMPLEXITY, TAIL\n",
    "from yuntu.soundscape.pipelines.build_soundscape import CronoSoundscape, HASHER_CONFIG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "pipeline-parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# alfresco query\n",
    "CUMULO = 92 # INT\n",
    "SAMPLERATE = 48000.0\n",
    "PAGESIZE = 1000\n",
    "\n",
    "# soundscape pltos\n",
    "RED_IDX = \"EXAG\"\n",
    "GREEN_IDX = \"INFORMATION\"\n",
    "BLUE_IDX = \"CORE\"\n",
    "MIN_FREQ_SC = 10000\n",
    "\n",
    "# soundscape computing\n",
    "WORK_DIR_PIPELINE = \".\"\n",
    "TIME_UNIT = 30\n",
    "FREQUENCY_BINS = 96 # 250 Hz x bin\n",
    "FREQUENCY_LIMITS_LB = 0\n",
    "FREQUENCY_LIMITS_UB = 24000\n",
    "SPECTRUM = \"Audible\"\n",
    "# Hasher \n",
    "HASHER_TIME_UNIT =  1800\n",
    "HASHER_TIME_MODULE = 48\n",
    "HASH_NAME = \"crono_hash_30m\"\n",
    "\n",
    "## cluster\n",
    "THREADS_PER_WORKER = 2\n",
    "\n",
    "# results directory\n",
    "RESULTS_DIR = '/shared_volume/audio/soundscapes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "functions"
    ]
   },
   "outputs": [],
   "source": [
    "def create_results_folder_str(results_dir, cumulo, nodes_list, rec_list, dep_list): \n",
    "    # results directory\n",
    "    os.makedirs(results_dir, exist_ok=True)\n",
    "    # cumulus subdir\n",
    "    cum_subdir = os.path.join(results_dir, str(cumulo))\n",
    "    os.makedirs(cum_subdir, exist_ok=True)\n",
    "    # node subdirs\n",
    "    for node in nodes_list:\n",
    "        node_subdir = os.path.join(cum_subdir, node)\n",
    "        os.makedirs(node_subdir, exist_ok=True)\n",
    "        # recorder subdirs\n",
    "        for rec in rec_list:\n",
    "            rec_subdir = os.path.join(node_subdir, rec)\n",
    "            os.makedirs(rec_subdir, exist_ok=True)\n",
    "            # deployment subdirs\n",
    "            for dep in dep_list:\n",
    "                dep_subdir = os.path.join(rec_subdir, dep)\n",
    "                os.makedirs(dep_subdir, exist_ok=True)\n",
    "                \n",
    "def remove_empty_folders(path_abs):\n",
    "    walk = list(os.walk(path_abs))\n",
    "    for path, _, _ in walk[::-1]:\n",
    "        if len(os.listdir(path)) == 0:\n",
    "            os.rmdir(path)            \n",
    "            \n",
    "def save_metadata(product_id, product_type, product_spectrum, sc_config,\n",
    "                  path, cumulus, node, recorder, deployment, parent=\"Null\"):\n",
    "    if product_type == \"soundscape\":\n",
    "        product_name = \"Soundscape\"\n",
    "        file_path = os.path.join(path, \"hashed_soundscape.parquet\")\n",
    "        metadata_filename = os.path.join(path, \"soundscape_metadata.json\")\n",
    "    elif product_type == \"sequence\":\n",
    "        product_name = \"Soundscape sequential plot\"\n",
    "        file_path = os.path.join(path, \"soundscape_seq.png\")\n",
    "        metadata_filename = os.path.join(path, \"soundscape_seq_metadata.json\")\n",
    "    elif product_type == \"standard_deviation\":\n",
    "        product_name = \"Soundscape standard deviation plot\"\n",
    "        file_path = os.path.join(path, \"std_soundscape.png\")\n",
    "        metadata_filename = os.path.join(path, \"std_soundscape_metadata.json\")\n",
    "    elif product_type == \"mean\":\n",
    "        product_name = \"Soundscape mean plot\"\n",
    "        file_path = os.path.join(path, \"mean_soundscape.png\")\n",
    "        metadata_filename = os.path.join(path, \"mean_soundscape_metadata.json\")\n",
    "    \n",
    "    if int(node.split(\"_\")[2]) == 0:\n",
    "        node_category = \"Degradado\"\n",
    "    elif int(node.split(\"_\")[2]) == 1:\n",
    "        node_category = \"Integro\"\n",
    "\n",
    "    metadata = {\n",
    "        \"product_id\": product_id,\n",
    "        \"product_parent\": parent,\n",
    "        \"product_name\": product_name,\n",
    "        \"product_configs\": sc_config,\n",
    "        \"product_path\": file_path,\n",
    "        \"product_spectrum\": product_spectrum,\n",
    "        \"CumulusName\": cumulus,\n",
    "        \"NodeCategoryIntegrity\": node_category,\n",
    "        \"NomenclatureNode\": node,\n",
    "        \"SerialNumber\": recorder,\n",
    "        \"DateDeployment\": deployment\n",
    "    }\n",
    "    \n",
    "    with open(metadata_filename, 'w', encoding='utf-8') as f:\n",
    "        json.dump(metadata, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "def plot_soundscape(soundscape, product_type, product_spectrum, sc_config, path, \n",
    "                    cumulus, node, recorder, deployment, parent, indices, min_freq=None,\n",
    "                  figsize=(20,15), plt_style='ggplot'):\n",
    "    \n",
    "    if min_freq:\n",
    "        soundscape = soundscape[soundscape['min_freq']<=min_freq]\n",
    "        \n",
    "    if product_type == \"sequence\":\n",
    "        file_path = os.path.join(path, \"sequence.png\")\n",
    "        product_id = hashlib.md5(file_path.encode('utf-8')).hexdigest()\n",
    "        \n",
    "        plt.style.use(plt_style)\n",
    "        fig, ax = plt.subplots(figsize=figsize)\n",
    "        soundscape.sndscape.plot_sequence(rgb=indices, time_format='%Y-%m %H:%M', ax=ax)\n",
    "        plt.xticks(rotation = 90)\n",
    "        ax.grid(False)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(file_path) \n",
    "        plt.show()\n",
    "        # save metadata\n",
    "        save_metadata(product_id, product_type, product_spectrum, sc_config,\n",
    "                  path, cumulus, node, recorder, deployment, parent=parent)\n",
    "         \n",
    "    elif product_type == \"standard_deviation\":\n",
    "        file_path = os.path.join(path, \"std_soundscape.png\")\n",
    "        product_id = hashlib.md5(file_path.encode('utf-8')).hexdigest()\n",
    "        \n",
    "        plt.style.use(plt_style)\n",
    "        fig, ax = plt.subplots(figsize=figsize)\n",
    "        soundscape.sndscape.plot_cycle(rgb=indices, aggr=\"std\", time_format='%H:%M', \n",
    "                                       xticks=24, ax=ax)\n",
    "        plt.xticks(rotation = 90)\n",
    "        ax.grid(False)\n",
    "        plt.tight_layout() \n",
    "        plt.savefig(file_path)\n",
    "        plt.show()\n",
    "        \n",
    "        # save metadata\n",
    "        save_metadata(product_id, product_type, product_spectrum, sc_config,\n",
    "                  path, cumulus, node, recorder, deployment, parent)     \n",
    "        \n",
    "    elif product_type == \"mean\": \n",
    "        file_path = os.path.join(path, \"mean_soundscape.png\")\n",
    "        product_id = hashlib.md5(file_path.encode('utf-8')).hexdigest()\n",
    "        \n",
    "        plt.style.use(plt_style)\n",
    "        fig, ax = plt.subplots(figsize=figsize)\n",
    "        soundscape.sndscape.plot_cycle(rgb=indices, aggr=\"mean\", time_format='%H:%M', \n",
    "                                       xticks=24, ax=ax)\n",
    "        plt.xticks(rotation = 90)\n",
    "        ax.grid(False)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(file_path)\n",
    "        plt.show()\n",
    "        \n",
    "        # save metadata\n",
    "        save_metadata(product_id, product_type, product_spectrum, sc_config,\n",
    "                  path, cumulus, node, recorder, deployment, parent)    \n",
    "        \n",
    "    print(f\"File saved at {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "block:get_audio_df"
    ]
   },
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "DB_CONFIG = {\n",
    "    'provider': 'alfresco',\n",
    "    'config': {\n",
    "        'api_url': 'https://api.conabio.gob.mx',\n",
    "        'page_size': PAGESIZE,\n",
    "        'api_key': os.getenv(\"X_API_KEY\"),\n",
    "        'base_filter': \"+TYPE: \\\"sipecamAudio:audiofileSipecam\\\"\",\n",
    "        'recording_parser': {\"path\": \"/shared_volume/audio/utils.py\",\n",
    "                             \"object_name\": \"parser_prev\"}\n",
    "    }\n",
    "}\n",
    "\n",
    "COL_CONFIG = {\n",
    "    \"col_type\": \"alfresco\",\n",
    "    \"db_config\": DB_CONFIG\n",
    "}\n",
    "\n",
    "col = collection(**COL_CONFIG)\n",
    "query = f\"(sipecam:CumulusName:\\\"{CUMULO}\\\") AND (sipecamAudio:SampleRate:{SAMPLERATE})\"\n",
    "recs = col.get_recording_dataframe(with_metadata = True, with_geometry = False)\n",
    "\n",
    "# include filtering columns for processing units\n",
    "recs.loc[:, \"node\"] = recs.metadata.apply(lambda x: x[\"entry\"][\"properties\"][\"sipecam:NomenclatureNode\"])\n",
    "recs.loc[:, \"recorder\"] = recs.metadata.apply(lambda x: x[\"entry\"][\"properties\"][\"sipecamAudio:SerialNumber\"]) \n",
    "recs.loc[:, \"deployment\"] = recs.metadata.apply(lambda x: x[\"entry\"][\"path\"][\"name\"].split(\"/audio\")[0].split(\"/\")[-1])\n",
    "recs.loc[:,\"proc_unit\"] = recs.apply(lambda x: (x[\"node\"], x[\"recorder\"], x[\"deployment\"]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "block:create_results_dirstruct",
     "prev:get_audio_df"
    ]
   },
   "outputs": [],
   "source": [
    "# create results folder structure\n",
    "nodes_list = recs.node.unique()\n",
    "recorders_list = recs.recorder.unique()\n",
    "deployments_list = recs.deployment.unique()\n",
    "if os.path.isdir(RESULTS_DIR):\n",
    "    shutil.rmtree(RESULTS_DIR)\n",
    "create_results_folder_str(RESULTS_DIR, CUMULO, nodes_list, recorders_list, deployments_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "block:compute_soundscapes",
     "prev:create_results_dirstruct",
     "prev:get_audio_df"
    ]
   },
   "outputs": [],
   "source": [
    "execution_info = {}\n",
    "start_time_compute_soundscapes = time.monotonic()\n",
    "\n",
    "# hasher config \n",
    "hasher_config = {'module': {'object_name': 'yuntu.soundscape.hashers.crono.CronoHasher'},\n",
    "                 'kwargs': {'time_utc_column': 'abs_start_time'}}\n",
    "\n",
    "hasher_config[\"kwargs\"][\"time_unit\"] = HASHER_TIME_UNIT\n",
    "hasher_config[\"kwargs\"][\"time_module\"] = HASHER_TIME_MODULE\n",
    "hasher_config[\"kwargs\"][\"start_tzone\"] = \"America/Mexico_City\"\n",
    "hasher_config[\"kwargs\"][\"start_time\"] = DEFAULT_HASHER_CONFIG[\"start_time\"]\n",
    "hasher_config[\"kwargs\"][\"start_format\"] = DEFAULT_HASHER_CONFIG[\"start_format\"]\n",
    "hasher_config[\"kwargs\"][\"aware_start\"] = None\n",
    "\n",
    "# soundscape config \n",
    "slice_config  = dict(CronoSoundscape()[\"slice_config\"].data)\n",
    "slice_config[\"time_unit\"] = TIME_UNIT\n",
    "slice_config[\"frequency_bins\"] = FREQUENCY_BINS\n",
    "slice_config[\"frequency_limits\"] = (FREQUENCY_LIMITS_LB, FREQUENCY_LIMITS_UB)\n",
    "\n",
    "# FED configuration [\"TOTAL\", \"CORE\", \"TAIL\", \"INFORMATION\", \"ICOMPLEXITY\", \"EXAG\"]\n",
    "indices = CronoSoundscape()[\"indices\"].data + [ICOMPLEXITY()]  + [TAIL()]\n",
    "\n",
    "# dask local cluster\n",
    "n_workers = int(0.95 * multiprocessing .cpu_count()) \n",
    "cluster = LocalCluster(n_workers = n_workers, \n",
    "                       threads_per_worker = THREADS_PER_WORKER)\n",
    "client = Client(cluster)\n",
    "npartitions = len(client.ncores())\n",
    "\n",
    "# FEED\n",
    "FEED = {\n",
    "    \"slice_config\": slice_config,\n",
    "    \"indices\": indices,\n",
    "    \"hash_name\": HASH_NAME,\n",
    "    \"hasher_config\": hasher_config,\n",
    "    \"npartitions\": npartitions\n",
    "}\n",
    "\n",
    "# adjust for metadata\n",
    "indexes_computed = [\"TOTAL\", \"CORE\", \"TAIL\", \"INFORMATION\", \"ICOMPLEXITY\", \"EXAG\"]\n",
    "FEED_metadata = FEED.copy()\n",
    "FEED_metadata[\"indices\"] = indexes_computed\n",
    "\n",
    "plot_indices = [RED_IDX, GREEN_IDX, BLUE_IDX] # rgb order\n",
    "\n",
    "# soundscape per unit (cumulus-node-recorder-deployment_date)\n",
    "proc_units = recs.proc_unit.unique()\n",
    "\n",
    "for proc_unit in proc_units:\n",
    "    try: \n",
    "        start_soundscape = time.monotonic()\n",
    "        node, recorder, deployment = proc_unit\n",
    "        print(f\"* Processing: node {node} | recorder {recorder} | deployment date {deployment}\")\n",
    "        file_path = os.path.join(RESULTS_DIR, str(CUMULO), str(node), recorder, deployment)\n",
    "        parent_id = hashlib.md5(file_path.encode('utf-8')).hexdigest()\n",
    "        # soundscape = recs[recs.proc_unit == proc_unit].audio.get_soundscape(client=client, npartitions=n_workers, **soundscape_config)\n",
    "        soundscape_data = recs[recs.proc_unit == proc_unit]\n",
    "        pipeline = CronoSoundscape(name = \"soundscape\", work_dir = WORK_DIR_PIPELINE, recordings = soundscape_data)\n",
    "        soundscape = pipeline[\"hashed_soundscape\"].compute(client=client, feed=FEED)\n",
    "\n",
    "        # sequence\n",
    "        plot_soundscape(soundscape, \"sequence\", SPECTRUM, FEED_metadata, file_path,\n",
    "                        CUMULO, node, recorder, deployment, parent_id, plot_indices, MIN_FREQ_SC)    \n",
    "        # mean\n",
    "        plot_soundscape(soundscape, \"mean\", SPECTRUM, FEED_metadata, file_path, \n",
    "                        CUMULO, node, recorder, deployment, parent_id, plot_indices, MIN_FREQ_SC)\n",
    "\n",
    "        # standard deviation\n",
    "        plot_soundscape(soundscape, \"standard_deviation\", SPECTRUM, FEED_metadata, file_path, \n",
    "                        CUMULO, node, recorder, deployment, parent_id, plot_indices, MIN_FREQ_SC)\n",
    "\n",
    "        # save soundscape vector\n",
    "        soundscape_path = os.path.join(file_path, \"hashed_soundscape.parquet\")\n",
    "        # soundscape_orig_path = os.path.join(RESULTS_DIR, \"get_soundscape/persist/hashed_soundscape.parquet\") \n",
    "        soundscape_orig_path = '/shared_volume/audio/soundscape/persist/hashed_soundscape.parquet'\n",
    "        shutil.move(soundscape_orig_path,soundscape_path)\n",
    "        save_metadata(parent_id, \"soundscape\", SPECTRUM, FEED_metadata, file_path,\n",
    "                      CUMULO, node, recorder, deployment)\n",
    "        shutil.rmtree('/shared_volume/audio/soundscape')\n",
    "\n",
    "    except:\n",
    "        pass\n",
    "    # restart client\n",
    "    client.restart()\n",
    "\n",
    "# total time (soundscapes)\n",
    "execution_info[\"time_compute_soundscapes\"] = str(timedelta(seconds=time.monotonic() - start_time_compute_soundscapes))\n",
    "   \n",
    "client.close()\n",
    "cluster.close()\n",
    "\n",
    "# remove empty subdirectories\n",
    "remove_empty_folders(RESULTS_DIR)\n",
    "\n",
    "# execution info\n",
    "# arch info\n",
    "arch_info_dict = {}\n",
    "arch_info = subprocess.check_output(\"lscpu\", shell=True).strip().decode().split(\"\\n\")[:-1]\n",
    "arch_info = [x.replace(\" \", \"\") for x in arch_info]\n",
    "\n",
    "for field in arch_info:\n",
    "    key, value = field.split(\":\")\n",
    "    arch_info_dict[key] = value\n",
    "arch_info_dict[\"RAM Memory (GB)\"] = psutil.virtual_memory().total >> 30\n",
    "\n",
    "execution_info[\"arch_info_dict\"] = arch_info_dict\n",
    "\n",
    "execution_path = os.path.join(RESULTS_DIR, \"execution_info.json\")\n",
    "\n",
    "if os.path.exists(execution_path):\n",
    "    os.remove(execution_path)\n",
    "with open(execution_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(execution_info, f, ensure_ascii=False, indent=4)    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "kubeflow_notebook": {
   "autosnapshot": false,
   "docker_image": "sipecam/audio-dgpi-kale-tensorflow-yuntu-dask-cert:0.6.1_dev",
   "experiment": {
    "id": "new",
    "name": "soundscapes-nod-rec-dep-dask-indices"
   },
   "experiment_name": "soundscapes-nod-rec-dep-dask-indices",
   "katib_metadata": {
    "algorithm": {
     "algorithmName": "grid"
    },
    "maxFailedTrialCount": 3,
    "maxTrialCount": 12,
    "objective": {
     "objectiveMetricName": "",
     "type": "minimize"
    },
    "parallelTrialCount": 3,
    "parameters": []
   },
   "katib_run": false,
   "pipeline_description": "Computes Sipecam Soundscapes using cumulus, node, recorder and deployment",
   "pipeline_name": "sound-scape-nod-rec-dep",
   "snapshot_volumes": false,
   "steps_defaults": [],
   "volume_access_mode": "rwm",
   "volumes": [
    {
     "annotations": [],
     "mount_point": "/shared_volume",
     "name": "hostpath-pvc",
     "size": 1,
     "size_type": "Gi",
     "snapshot": false,
     "snapshot_name": "",
     "type": "pvc"
    }
   ]
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
