apiVersion: argoproj.io/v1alpha1
kind: Workflow
metadata:
  generateName: sound-scape-nod-rec-dep-rs7g6-
  annotations: {pipelines.kubeflow.org/kfp_sdk_version: 1.8.11, pipelines.kubeflow.org/pipeline_compilation_time: '2022-07-20T05:43:13.914234',
    pipelines.kubeflow.org/pipeline_spec: '{"description": "Computes Sipecam Soundscapes
      using cumulus, node, recorder and deployment", "inputs": [{"default": "cf3a1b97-965d-489f-bfdf-5c8e26c4ac95",
      "name": "ALFRESCO_NODE_ID", "optional": true}, {"default": "alfresco/api/-default-/public/authentication/versions/1",
      "name": "AUTH_ENDPOINT", "optional": true}, {"default": "alfresco/api/-default-/public/alfresco/versions/1",
      "name": "BASE_ENDPOINT", "optional": true}, {"default": "CORE", "name": "BLUE_IDX",
      "optional": true}, {"default": "92", "name": "CUMULO", "optional": true}, {"default":
      "96", "name": "FREQUENCY_BINS", "optional": true}, {"default": "0", "name":
      "FREQUENCY_LIMITS_LB", "optional": true}, {"default": "24000", "name": "FREQUENCY_LIMITS_UB",
      "optional": true}, {"default": "INFORMATION", "name": "GREEN_IDX", "optional":
      true}, {"default": "48", "name": "HASHER_TIME_MODULE", "optional": true}, {"default":
      "1800", "name": "HASHER_TIME_UNIT", "optional": true}, {"default": "crono_hash_30m",
      "name": "HASH_NAME", "optional": true}, {"default": "False", "name": "LIMIT",
      "optional": true}, {"default": "10000", "name": "MIN_FREQ_SC", "optional": true},
      {"default": "10000", "name": "PAGESIZE", "optional": true}, {"default": "EXAG",
      "name": "RED_IDX", "optional": true}, {"default": "/shared_volume/audio/soundscapes",
      "name": "RESULTS_DIR", "optional": true}, {"default": "48000.0", "name": "SAMPLERATE",
      "optional": true}, {"default": "Audible", "name": "SPECTRUM", "optional": true},
      {"default": "2", "name": "THREADS_PER_WORKER", "optional": true}, {"default":
      "30", "name": "TIME_UNIT", "optional": true}, {"default": "3", "name": "VIDS_PER_HOUR",
      "optional": true}, {"default": ".", "name": "WORK_DIR_PIPELINE", "optional":
      true}, {"default": "hostpath-pvc", "name": "vol_shared_volume", "optional":
      true}], "name": "sound-scape-nod-rec-dep-rs7g6"}'}
  labels: {pipelines.kubeflow.org/kfp_sdk_version: 1.8.11}
spec:
  entrypoint: sound-scape-nod-rec-dep-rs7g6
  templates:
  - name: compute-soundscapes
    container:
      args: [--AUTH-ENDPOINT, '{{inputs.parameters.AUTH_ENDPOINT}}', --BASE-ENDPOINT,
        '{{inputs.parameters.BASE_ENDPOINT}}', --BLUE-IDX, '{{inputs.parameters.BLUE_IDX}}',
        --CUMULO, '{{inputs.parameters.CUMULO}}', --FREQUENCY-BINS, '{{inputs.parameters.FREQUENCY_BINS}}',
        --FREQUENCY-LIMITS-LB, '{{inputs.parameters.FREQUENCY_LIMITS_LB}}', --FREQUENCY-LIMITS-UB,
        '{{inputs.parameters.FREQUENCY_LIMITS_UB}}', --GREEN-IDX, '{{inputs.parameters.GREEN_IDX}}',
        --HASHER-TIME-MODULE, '{{inputs.parameters.HASHER_TIME_MODULE}}', --HASHER-TIME-UNIT,
        '{{inputs.parameters.HASHER_TIME_UNIT}}', --HASH-NAME, '{{inputs.parameters.HASH_NAME}}',
        --MIN-FREQ-SC, '{{inputs.parameters.MIN_FREQ_SC}}', --RED-IDX, '{{inputs.parameters.RED_IDX}}',
        --RESULTS-DIR, '{{inputs.parameters.RESULTS_DIR}}', --SPECTRUM, '{{inputs.parameters.SPECTRUM}}',
        --THREADS-PER-WORKER, '{{inputs.parameters.THREADS_PER_WORKER}}', --TIME-UNIT,
        '{{inputs.parameters.TIME_UNIT}}', --WORK-DIR-PIPELINE, '{{inputs.parameters.WORK_DIR_PIPELINE}}']
      command:
      - sh
      - -ec
      - |
        program_path=$(mktemp)
        printf "%s" "$0" > "$program_path"
        python3 -u "$program_path" "$@"
      - "def compute_soundscapes(AUTH_ENDPOINT, BASE_ENDPOINT, BLUE_IDX, CUMULO, FREQUENCY_BINS,\
        \ FREQUENCY_LIMITS_LB, FREQUENCY_LIMITS_UB, GREEN_IDX, HASHER_TIME_MODULE,\
        \ HASHER_TIME_UNIT, HASH_NAME, MIN_FREQ_SC, RED_IDX, RESULTS_DIR, SPECTRUM,\
        \ THREADS_PER_WORKER, TIME_UNIT, WORK_DIR_PIPELINE):\n    _kale_pipeline_parameters_block\
        \ = '''\n    AUTH_ENDPOINT = \"{}\"\n    BASE_ENDPOINT = \"{}\"\n    BLUE_IDX\
        \ = \"{}\"\n    CUMULO = {}\n    FREQUENCY_BINS = {}\n    FREQUENCY_LIMITS_LB\
        \ = {}\n    FREQUENCY_LIMITS_UB = {}\n    GREEN_IDX = \"{}\"\n    HASHER_TIME_MODULE\
        \ = {}\n    HASHER_TIME_UNIT = {}\n    HASH_NAME = \"{}\"\n    MIN_FREQ_SC\
        \ = {}\n    RED_IDX = \"{}\"\n    RESULTS_DIR = \"{}\"\n    SPECTRUM = \"\
        {}\"\n    THREADS_PER_WORKER = {}\n    TIME_UNIT = {}\n    WORK_DIR_PIPELINE\
        \ = \"{}\"\n    '''.format(AUTH_ENDPOINT, BASE_ENDPOINT, BLUE_IDX, CUMULO,\
        \ FREQUENCY_BINS, FREQUENCY_LIMITS_LB, FREQUENCY_LIMITS_UB, GREEN_IDX, HASHER_TIME_MODULE,\
        \ HASHER_TIME_UNIT, HASH_NAME, MIN_FREQ_SC, RED_IDX, RESULTS_DIR, SPECTRUM,\
        \ THREADS_PER_WORKER, TIME_UNIT, WORK_DIR_PIPELINE)\n\n    from kale.common\
        \ import mlmdutils as _kale_mlmdutils\n    _kale_mlmdutils.init_metadata()\n\
        \n    _kale_data_loading_block = '''\n    # -----------------------DATA LOADING\
        \ START--------------------------------\n    from kale import marshal as _kale_marshal\n\
        \    _kale_marshal.set_data_dir(\"/shared_volume/audio/.sndscs_spec_specvid-sipecam-cumulus-node-recorder-deployment-aws.ipynb.kale.marshal.dir\"\
        )\n    recs = _kale_marshal.load(\"recs\")\n    # -----------------------DATA\
        \ LOADING END----------------------------------\n    '''\n\n    _kale_block1\
        \ = '''\n    import base64\n    import datetime\n    import glob\n    import\
        \ hashlib\n    import io\n    import itertools\n    import json\n    import\
        \ matplotlib.pyplot as plt\n    import multiprocessing \n    import numpy\
        \ as np\n    import os\n    import pandas as pd\n    import psutil\n    import\
        \ requests\n    import shutil\n    import subprocess\n    import time\n  \
        \  import warnings\n\n    from dask.distributed import Client, LocalCluster\n\
        \    from datetime import timedelta\n    from dotenv import load_dotenv\n\
        \    from matplotlib import cm\n    from moviepy.editor import concatenate,\
        \ VideoFileClip, AudioFileClip\n    from moviepy.audio.AudioClip import AudioArrayClip\n\
        \    from moviepy.video.VideoClip import ImageClip\n    from os.path import\
        \ exists as file_exists\n    from PIL import Image\n    from skimage.transform\
        \ import resize\n\n    from yuntu import Audio\n    from yuntu.soundscape.utils\
        \ import aware_time\n    from yuntu.collection.methods import collection\n\
        \    from yuntu.soundscape.hashers.crono import DEFAULT_HASHER_CONFIG\n  \
        \  from yuntu.soundscape.processors.indices.direct import ICOMPLEXITY, TAIL\n\
        \    from yuntu.soundscape.pipelines.build_soundscape import CronoSoundscape,\
        \ HASHER_CONFIG\n    '''\n\n    _kale_block2 = '''\n    def audio2video(audio_id,\n\
        \                    audio_df,\n                    save_path_folder,\n  \
        \                  product_spectrum,\n                    cumulus,\n     \
        \               abs_start=None,\n                    fps=60,\n           \
        \         spec_configs={'hop_length': 512, 'n_fft': 1024, 'window_function':\
        \ 'hann'},\n                    rate=24,\n                    frame_duration=3.0,\n\
        \                    min_freq=0,\n                    max_freq=None,\n   \
        \                 cmap=\"Greys\",\n                    figsize=(5, 8),\n \
        \                   dpi=100,\n                    bands=None):\n        \\\
        '\\'\\'Takes and audio object and produces a mp4 video of the spectrogram\
        \ with audio\\'\\'\\'\n\n        sub_audio_df = audio_df[audio_df[\"id\"]==audio_id]\n\
        \        id_audio = sub_audio_df['id'].values[0]\n        node = sub_audio_df['node'].values[0]\n\
        \        recorder = sub_audio_df['recorder'].values[0]\n        deployment\
        \ = sub_audio_df['deployment'].values[0]\n        audio = sub_audio_df.audio[0]\n\
        \n        colormap = cm.get_cmap(cmap)\n        duration = audio.duration\n\
        \        step = 1/rate\n        start = -(frame_duration/2.0)\n        stop\
        \ = start + frame_duration\n        clips = []\n        last_stop = None\n\
        \n        if max_freq is None:\n            max_freq = audio.samplerate /\
        \ 2.0\n\n        if min_freq is None:\n            min_freq = 0\n\n      \
        \  with audio.features.db_spectrogram(**spec_configs) as spec:\n         \
        \   min_spec = np.amin(spec)\n            max_spec = np.amax(spec)\n     \
        \       spec_range = (max_spec-min_spec)\n\n            while stop <= duration+(frame_duration/2.0):\n\
        \                clip = produce_clip(spec, frame_duration, min_freq, max_freq,\
        \ start, stop, step, abs_start, colormap,\n                              \
        \      min_spec, spec_range, figsize, dpi, bands=bands)\n                clips.append(clip)\n\
        \n                if start + step + frame_duration > duration:\n         \
        \           last_stop = stop\n\n                start = start + step\n   \
        \             stop = start + frame_duration\n\n        video = concatenate(clips)\n\
        \        # edaudio = AudioArrayClip(audio_array, fps=audio.samplerate)\n \
        \       edaudio = AudioFileClip(audio.path).set_end(audio.duration)\n    \
        \    video = video.set_audio(edaudio)\n        file_path = os.path.join(save_path_folder,\
        \ f\"{audio_id}.mp4\")\n        video.write_videofile(file_path, fps=fps)\n\
        \n        save_metadata_videoclip(audio_id, product_spectrum,\n          \
        \            save_path_folder, cumulus, node, recorder, deployment, 0.0, audio.duration)\n\
        \        video.close()\n        edaudio.close()\n\n        for c in clips:\n\
        \            c.close()\n\n    def change_type_sipecam_sc(session, root_folder_id,\
        \ path, file_type, node_type):\n        if file_type == \"sequence.png\":\n\
        \            metadata_name = \"soundscape_seq_metadata.json\"\n          \
        \  aggr_type = \"None\"\n        elif file_type == \"mean_soundscape.png\"\
        :\n            metadata_name = \"mean_soundscape_metadata.json\"\n       \
        \     aggr_type = \"Mean\"\n        elif file_type ==  \"std_soundscape.png\"\
        :\n            metadata_name = \"std_soundscape_metadata.json\" \n       \
        \     aggr_type = \"Standard deviation\"\n        elif file_type == \"hashed_soundscape.parquet\"\
        :\n            metadata_name = \"soundscape_metadata.json\" \n           \
        \ aggr_type = \"None\"\n        elif \".png\" in file_type and (file_type\
        \ not in [\"sequence.png\", \"mean_soundscape.png\", \"std_soundscape.png\"\
        ]):\n            metadata_name = file_type.split(\".\")[0] + \"_spectrogram_metadata.json\"\
        \n            aggr_type = \"Null\"\n        elif \".mp4\" in file_type and\
        \ (file_type not in [\"sequence.png\", \"mean_soundscape.png\", \"std_soundscape.png\"\
        ]):\n            metadata_name = file_type.split(\".\")[0] + \"_spectrogram_video_metadata.json\"\
        \n            aggr_type = \"Null\"\n\n        try:\n            semi_path\
        \ = path.split(\"soundscapes/\")[-1]\n            semi_path_file = os.path.join(semi_path,\
        \ file_type)\n            local_path_file_metadata = os.path.join(path, metadata_name)\n\
        \            print(f\"Changing type for {os.path.join(semi_path)}\")\n   \
        \         alfresco_path = os.path.join(\"/Company Home/Sites/sipecam-soundscape/documentLibrary/\"\
        , semi_path)\n\n            response = session.get(\n                os.getenv(\"\
        ALFRESCO_URL\")\n                + BASE_ENDPOINT\n                + \"/nodes/\"\
        \n                + root_folder_id\n                + \"/children?relativePath=\"\
        +semi_path+\"&include=aspectNames&skipCount=0\"\n            )        \n \
        \           # if request is successful then continue\n            if response.status_code\
        \ == 200:\n\n                data_file = open(local_path_file_metadata)\n\
        \                data_json = json.load(data_file)\n                response_entries\
        \ = response.json()[\"list\"][\"entries\"]\n\n                for entry in\
        \ response_entries:\n                    if entry['entry']['name']==file_type\
        \ and entry['entry']['isFile']:\n                        prop_dict = {}\n\n\
        \                        if entry['entry']['name']==file_type:\n\n       \
        \                     if entry['entry']['name'] in [\"sequence.png\", \"mean_soundscape.png\"\
        , \"std_soundscape.png\"]:\n                                prop_dict[\"soundscape:CumulusName\"\
        ] = str(data_json[\"CumulusName\"])\n                                prop_dict[\"\
        soundscape:DateDeployment\"] = data_json[\"DateDeployment\"]\n           \
        \                     prop_dict[\"soundscape:NodeCategoryIntegrity\"] = str(data_json[\"\
        NodeCategoryIntegrity\"])\n                                prop_dict[\"soundscape:NomenclatureNode\"\
        ] = str(data_json[\"NomenclatureNode\"])\n                               \
        \ prop_dict[\"soundscape:SerialNumber\"] = str(data_json[\"SerialNumber\"\
        ])\n                                prop_dict[\"soundscape:aggr\"] = str(aggr_type)\n\
        \                                prop_dict[\"soundscape:cycle_config_aware_start\"\
        ] = str(data_json[\"product_configs\"]['hasher_config']['kwargs']['aware_start'])\n\
        \                                prop_dict[\"soundscape:cycle_config_start_format\"\
        ] = str(data_json[\"product_configs\"]['hasher_config']['kwargs']['start_format'])\n\
        \                                prop_dict[\"soundscape:cycle_config_start_time\"\
        ] =  datetime.datetime.strptime(data_json[\"product_configs\"]['hasher_config']['kwargs']['start_time'],\
        \ \n                                                                     \
        \                                   \"%Y-%m-%d %H:%M:%S\").strftime(\"%Y-%m-%dT%H:%M:%S.%f%z\"\
        )\n                                prop_dict[\"soundscape:cycle_config_start_tzone\"\
        ] = str(data_json[\"product_configs\"]['hasher_config']['kwargs']['start_tzone'])\n\
        \                                prop_dict[\"soundscape:cycle_config_time_module\"\
        ] = int(data_json[\"product_configs\"]['hasher_config']['kwargs']['time_module'])\n\
        \                                prop_dict[\"soundscape:cycle_config_time_unit\"\
        ] = str(data_json[\"product_configs\"]['hasher_config']['kwargs']['time_unit'])\n\
        \                                prop_dict[\"soundscape:cycle_config_time_utc_column\"\
        ] = str(data_json[\"product_configs\"]['hasher_config']['kwargs']['time_utc_column'])\n\
        \                                prop_dict[\"soundscape:frequency_bins\"]\
        \ = int(data_json[\"product_configs\"][\"slice_config\"][\"frequency_bins\"\
        ])\n                                prop_dict[\"soundscape:frequency_hop\"\
        ] = int(data_json[\"product_configs\"][\"slice_config\"][\"frequency_hop\"\
        ])\n                                prop_dict[\"soundscape:frequency_limits\"\
        ] = str(data_json[\"product_configs\"][\"slice_config\"][\"frequency_limits\"\
        ])\n                                prop_dict[\"soundscape:hash_name\"] =\
        \ str(data_json[\"product_configs\"][\"hash_name\"])\n                   \
        \             prop_dict[\"soundscape:hop_length\"] = int(data_json[\"product_configs\"\
        ][\"slice_config\"][\"feature_config\"][\"hop_length\"])\n               \
        \                 prop_dict[\"soundscape:indices\"] =  \", \".join(map(str,\
        \ data_json['product_configs']['indices']))\n                            \
        \    prop_dict[\"soundscape:n_fft\"] = int(data_json[\"product_configs\"][\"\
        slice_config\"][\"feature_config\"][\"n_fft\"])\n                        \
        \        prop_dict[\"soundscape:npartitions\"] = int(data_json[\"product_configs\"\
        ]['npartitions'])\n                                prop_dict[\"soundscape:product_name\"\
        ] = str(data_json[\"product_name\"])\n                                prop_dict[\"\
        soundscape:product_parent\"] = str(data_json[\"product_parent\"])\n      \
        \                          prop_dict[\"soundscape:product_path\"] = str(alfresco_path)\n\
        \                                prop_dict[\"soundscape:product_spectrum\"\
        ] = str(data_json[\"product_spectrum\"])\n                               \
        \ prop_dict[\"soundscape:slice_config_feature_type\"] = str(data_json[\"product_configs\"\
        ][\"slice_config\"][\"feature_type\"])\n                                prop_dict[\"\
        soundscape:slice_config_frequency_bins\"] = int(data_json[\"product_configs\"\
        ][\"slice_config\"][\"frequency_bins\"])\n                               \
        \ prop_dict[\"soundscape:slice_config_time_unit\"] = int(data_json[\"product_configs\"\
        ][\"slice_config\"][\"time_unit\"])\n                                prop_dict[\"\
        soundscape:time_hop\"] = int(data_json[\"product_configs\"][\"slice_config\"\
        ][\"time_hop\"])\n                                prop_dict[\"soundscape:window_function\"\
        ] = str(data_json[\"product_configs\"][\"slice_config\"][\"feature_config\"\
        ][\"window_function\"])  \n\n                            elif (\"spectrogram\"\
        \ or \"video\") in entry['entry']['name']:\n                             \
        \   prop_dict[\"soundscape:product_name\"] = str(data_json[\"product_name\"\
        ])\n                                prop_dict[\"soundscape:product_parent\"\
        ] = str(data_json[\"product_parent\"])\n                                prop_dict[\"\
        soundscape:product_path\"] = str(alfresco_path)\n                        \
        \        prop_dict[\"soundscape:product_spectrum\"] = str(data_json[\"product_spectrum\"\
        ])\n                                prop_dict[\"soundscape:CumulusName\"]\
        \ = str(data_json[\"CumulusName\"])\n                                prop_dict[\"\
        soundscape:NodeCategoryIntegrity\"] = str(data_json[\"NodeCategoryIntegrity\"\
        ])\n                                prop_dict[\"soundscape:NomenclatureNode\"\
        ] = str(data_json[\"NomenclatureNode\"])\n                               \
        \ prop_dict[\"soundscape:SerialNumber\"] = str(data_json[\"SerialNumber\"\
        ])\n                                prop_dict[\"soundscape:DateDeployment\"\
        ] = data_json[\"DateDeployment\"]\n                                prop_dict[\"\
        soundscape:AudioID\"] = data_json[\"AudioID\"]\n\n                       \
        \ aspects = entry['entry']['aspectNames']\n                        data =\
        \ {\"aspectNames\": aspects, \"nodeType\": node_type, \"properties\": prop_dict}\n\
        \                        # update properties request\n                   \
        \     update = session.put(\n                            os.getenv(\"ALFRESCO_URL\"\
        )\n                            + BASE_ENDPOINT\n                         \
        \   + \"/nodes/\"\n                            + entry['entry']['id'],\n \
        \                           data=json.dumps(data),\n                     \
        \   )\n\n                        if update.status_code == 200:\n         \
        \                   print(\"Updated \" + entry['entry']['id'])           \
        \         \n\n        except Exception as e:\n            print(\"Could not\
        \ add any aspect to this file: \", e)\n\n    def create_results_folder_str(results_dir,\
        \ cumulo, nodes_list, rec_list, dep_list): \n        # results directory\n\
        \        os.makedirs(results_dir, exist_ok=True)\n        # cumulus subdir\n\
        \        cum_subdir = os.path.join(results_dir, str(cumulo))\n        os.makedirs(cum_subdir,\
        \ exist_ok=True)\n        # node subdirs\n        for node in nodes_list:\n\
        \            node_subdir = os.path.join(cum_subdir, node)\n            os.makedirs(node_subdir,\
        \ exist_ok=True)\n            # recorder subdirs\n            for rec in rec_list:\n\
        \                rec_subdir = os.path.join(node_subdir, rec)\n           \
        \     os.makedirs(rec_subdir, exist_ok=True)\n                # deployment\
        \ subdirs\n                for dep in dep_list:\n                    dep_subdir\
        \ = os.path.join(rec_subdir, dep)\n                    os.makedirs(dep_subdir,\
        \ exist_ok=True)\n\n    def distance_to_mean(vector, mean):\n        \\'\\\
        '\\'Return euclidean distance to mean\\'\\'\\'\n        return np.sqrt(np.sum(np.square(mean\
        \ - vector)))\n\n    def find_subfolders(path_abs):\n        subdir_list =\
        \ []\n        walk = list(os.walk(path_abs))\n        for path, _, _ in walk[::-1]:\n\
        \            len_path = path.split(\"/\")\n            if len(len_path) ==\
        \ 8:\n                subdir_list.append(path)  \n\n        return subdir_list\n\
        \n    def get_audio_ids(soundscape_path, indices, nsamples):\n        df =\
        \ pd.read_parquet(os.path.join(soundscape_path, \"hashed_soundscape.parquet\"\
        ))\n\n        df[\"time_raw_hour\"] = df[\"time_raw\"].apply(lambda x: datetime.datetime.strptime(x,'%H:%M:%S\
        \ %d/%m/%Y (%z)').strftime(\"%H\"))\n        hours_list = list(df.time_raw_hour.unique())\n\
        \        hours_list.sort(key = int)\n\n        with open(os.path.join(soundscape_path,\
        \ \"soundscape_metadata.json\")) as f:\n            metadata = json.load(f)\n\
        \            f.close()\n\n        # indices = metadata[\"product_configs\"\
        ][\"indices\"]\n        # indices = [\"EXAG\", \"ICOMPLEXITY\", \"CORE\"]\n\
        \        hash_name = metadata[\"product_configs\"][\"hash_name\"]\n      \
        \  cycle_config = metadata[\"product_configs\"][\"hasher_config\"][\"kwargs\"\
        ]\n        time_unit = cycle_config[\"time_unit\"]\n        zero_t = aware_time(cycle_config[\"\
        start_time\"], cycle_config[\"start_tzone\"], cycle_config[\"start_format\"\
        ]) \n\n        # iterate over hours\n        audio_id_list = []\n        for\
        \ hour in hours_list:\n            subdf = df.query(f\"time_raw_hour == '{hour}'\"\
        )\n            # sample\n            samples_df = get_recording_samples(subdf,\
        \ hash_name, indices, time_unit, zero_t, nsamples=3)\n            unique_crono_hash_list\
        \ = list(samples_df.crono_hash_30m.unique())\n            sub_df = samples_df[samples_df.crono_hash_30m\
        \ == min(unique_crono_hash_list)]\n            audio_id_list += list(sub_df.id.tolist())\n\
        \n        return audio_id_list\n\n    def get_recording_samples(df, hash_name,\
        \ indices, time_unit, zero_t, nsamples=5):\n        \\'\\'\\'Return dataframe\
        \ of 'nsamples' samples for each tag in 'hash_name' column that are closest\
        \ to the mean vector by tag\\'\\'\\'\n        proj_df = df[(df.max_freq <=\
        \ 10000)]\n        crono_tags = proj_df.crono_hash_30m.unique()\n        proj_df.loc[:\
        \ , f\"{hash_name}_time\"] = proj_df[hash_name].apply(lambda x: zero_t + datetime.timedelta(seconds=float(x*time_unit)))\n\
        \        vectors = vectorize_soundscape(proj_df, hash_name, indices)\n   \
        \     min_index_vector = np.amin(np.stack(list(vectors.index_vector.values)),\
        \ axis=(0,1))\n        max_index_vector = np.amax(np.stack(list(vectors.index_vector.values)),\
        \ axis=(0,1))\n        index_range = (max_index_vector - min_index_vector)\n\
        \        vectors.loc[:, \"normalized_index_vector\"] = vectors.index_vector.apply(lambda\
        \ x: (x-min_index_vector)/index_range)\n        all_samples = []\n\n     \
        \   for crono_tag in crono_tags:\n            unit_vectors = vectors[vectors[hash_name]\
        \ == crono_tag]\n            mean_unit_vector = unit_vectors.normalized_index_vector.mean()\n\
        \            unit_vectors.loc[:, \"distance\"] = unit_vectors.normalized_index_vector.apply(lambda\
        \ x: distance_to_mean(x, mean_unit_vector))\n            all_samples.append(unit_vectors.sort_values(by=\"\
        distance\").head(nsamples))\n        return pd.concat(all_samples)\n\n   \
        \ def get_vectors(group, indices):\n        \\'\\'\\'Return array of indices\
        \ by frequency\\'\\'\\'\n        return group.sort_values(by=\"max_freq\"\
        )[indices].values\n\n    def login():\n        \"\"\"\n        Tries a login\
        \ to alfresco api and returns a session\n        object with credentials \n\
        \        Returns: \n            session (Session):  A session object to make\
        \ \n                                requests to zendro.\n        \"\"\"\n\
        \        try:\n            auth = {\n                \"userId\": os.getenv(\"\
        ALFRESCO_USER\"),\n                \"password\": os.getenv(\"ALFRESCO_PASSWORD\"\
        ),\n            }\n\n            login = requests.post(os.getenv(\"ALFRESCO_URL\"\
        ) + AUTH_ENDPOINT + \"/tickets\",data=json.dumps(auth))\n\n            base64_login\
        \ = base64.b64encode(bytes(login.json()[\"entry\"][\"id\"], 'utf-8')).decode()\n\
        \n            # se crea un objeto de Session para hacer requests\n       \
        \     session = requests.Session()\n            # se establece bearer token\n\
        \            session.headers.update({'Authorization': 'Basic ' + base64_login})\n\
        \n            return session\n        except Exception as e:\n           \
        \ print(\"Login failed: \", e)\n\n    def plot_spectrogram(audio_id, audio_df,\
        \ save_path_folder, spectrum, cumulus):\n        sub_audio_df = audio_df[audio_df[\"\
        id\"]==audio_id]\n        node = sub_audio_df['node'].values[0]\n        recorder\
        \ = sub_audio_df['recorder'].values[0]\n        deployment = sub_audio_df['deployment'].values[0]\n\
        \        # plot\n        fig, ax = plt.subplots(2,1,figsize=(20,10), sharex=True)\n\
        \        sub_audio_df.audio[0].plot(ax=ax[0], color='grey')\n        sub_audio_df.audio[0].features.db_spectrogram().plot(ax=ax[1])\n\
        \        ax[0].set_ylabel('Amplitude')\n        ax[0].grid(False)\n      \
        \  ax[1].set_ylabel('F (KHz)')\n        ax[1].set_xlabel('Time (seconds)')\n\
        \        fig.text(0.75, 0.04, f\"Cumulus: {cumulus} - Node: {node} - Recorder:\
        \ {recorder}\", va='center')\n        plt.tight_layout()\n        if save_path_folder:\n\
        \            file_path = os.path.join(save_path_folder, f\"{audio_id}.png\"\
        )\n            fig.savefig(file_path)\n        plt.show()\n\n        save_metadata_spectrogram(audio_id,\
        \ spectrum, save_path_folder, \n                                  cumulus,\
        \ node, recorder, deployment, parent=\"Null\")\n\n    def plot_soundscape(soundscape,\
        \ product_type, product_spectrum, sc_config, path, \n                    \
        \    cumulus, node, recorder, deployment, parent, indices, min_freq=None,\n\
        \                      figsize=(20,15), plt_style='ggplot'):\n\n        if\
        \ min_freq:\n            soundscape = soundscape[soundscape['min_freq']<=min_freq]\n\
        \n        if product_type == \"sequence\":\n            file_path = os.path.join(path,\
        \ \"sequence.png\")\n            # product_id = hashlib.md5(file_path.encode('utf-8')).hexdigest()\n\
        \n            plt.style.use(plt_style)\n            fig, ax = plt.subplots(figsize=figsize)\n\
        \            soundscape.sndscape.plot_sequence(rgb=indices, time_format='%Y-%m\
        \ %H:%M', ax=ax)\n            plt.xticks(rotation = 90)\n            ax.grid(False)\n\
        \            plt.tight_layout()\n            plt.savefig(file_path) \n   \
        \         plt.show()\n            # save metadata\n            save_metadata_sc(product_type,\
        \ product_spectrum, sc_config,\n                      path, cumulus, node,\
        \ recorder, deployment, parent=parent)\n\n        elif product_type == \"\
        standard_deviation\":\n            file_path = os.path.join(path, \"std_soundscape.png\"\
        )\n            # product_id = hashlib.md5(file_path.encode('utf-8')).hexdigest()\n\
        \n            plt.style.use(plt_style)\n            fig, ax = plt.subplots(figsize=figsize)\n\
        \            soundscape.sndscape.plot_cycle(rgb=indices, aggr=\"std\", time_format='%H:%M',\
        \ \n                                           xticks=24, ax=ax)\n       \
        \     plt.xticks(rotation = 90)\n            ax.grid(False)\n            plt.tight_layout()\
        \ \n            plt.savefig(file_path)\n            plt.show()\n\n       \
        \     # save metadata\n            save_metadata_sc(product_type, product_spectrum,\
        \ sc_config,\n                      path, cumulus, node, recorder, deployment,\
        \ parent)     \n\n        elif product_type == \"mean\": \n            file_path\
        \ = os.path.join(path, \"mean_soundscape.png\")\n            # product_id\
        \ = hashlib.md5(file_path.encode('utf-8')).hexdigest()\n\n            plt.style.use(plt_style)\n\
        \            fig, ax = plt.subplots(figsize=figsize)\n            soundscape.sndscape.plot_cycle(rgb=indices,\
        \ aggr=\"mean\", time_format='%H:%M', \n                                 \
        \          xticks=24, ax=ax)\n            plt.xticks(rotation = 90)\n    \
        \        ax.grid(False)\n            plt.tight_layout()\n            plt.savefig(file_path)\n\
        \            plt.show()\n\n            # save metadata\n            save_metadata_sc(product_type,\
        \ product_spectrum, sc_config,\n                      path, cumulus, node,\
        \ recorder, deployment, parent)    \n\n        print(f\"File saved at {file_path}\"\
        )\n\n    def produce_clip(spec, frame_duration, min_freq, max_freq, start,\
        \ stop, step, abs_start=None, \n                     colormap=cm.get_cmap(\"\
        Greys\"), min_spec=0, spec_range=1.0, figsize=(5, 4), \n                 \
        \    dpi=100, bands=None):\n        \\'\\'\\'Takes an individual frame and\
        \ produces an image with references\\'\\'\\'\n        frame = spec.cut_array(start_time=start,\
        \ end_time=stop, min_freq=min_freq, max_freq=max_freq, pad=True)\n       \
        \ plt.style.use('dark_background')\n        frame = np.flip((frame - min_spec)/spec_range,\
        \ axis=0)\n        fig, ax = plt.subplots(figsize=figsize)\n        ax.imshow(frame,\
        \ cmap=colormap, extent=[0, frame_duration, min_freq/1000, max_freq/1000],\
        \ \n                  aspect=\"auto\", vmin = 0, vmax = 1.0)\n\n        if\
        \ bands is not None:\n            band_arr = np.flip(resize(np.expand_dims(bands,\
        \ axis=1), (frame.shape[0], frame.shape[1])), axis=0)\n            ax.imshow(band_arr,\
        \ extent=[0, frame_duration, min_freq/1000, max_freq/1000], aspect=\"auto\"\
        , vmin = 0, \n                      vmax = 1.0, alpha=0.5)\n\n        ax.tick_params(axis='both',\
        \ which='major', labelsize=8)\n        ax.tick_params(axis='both', which='minor',\
        \ labelsize=8)\n        mid = frame_duration/2.0\n        ax.axvline(x=mid,\
        \ color=\"red\")\n        ax.set_ylabel('F (kHz)')\n        ax.set_xticks([])\n\
        \        ax.set_xticks([], minor=True)\n\n        if abs_start is not None:\n\
        \            time_text = (abs_start + datetime.timedelta(seconds=start+mid)).strftime('%H:%M:%S.%f').strip()[:-4]\n\
        \            ax.text(mid-0.3, -0.6, time_text)\n\n        buf = io.BytesIO()\n\
        \        fig.tight_layout()\n        fig.savefig(buf, dpi=dpi)\n        buf.seek(0)\n\
        \        im = Image.open(buf)\n        im.format = \"PNG\"\n        plt.close(fig)\n\
        \n        return ImageClip(np.asarray(im),\n                         duration=step)\n\
        \n    def remove_empty_folders(path_abs):\n        walk = list(os.walk(path_abs))\n\
        \        for path, _, _ in walk[::-1]:\n            if len(os.listdir(path))\
        \ == 0:\n                os.rmdir(path)            \n\n    def save_metadata_sc(product_type,\
        \ product_spectrum, sc_config,\n                      path, cumulus, node,\
        \ recorder, deployment, parent=\"Null\"):\n        if product_type == \"soundscape\"\
        :\n            product_name = \"Soundscape\"\n            file_path = os.path.join(path,\
        \ \"hashed_soundscape.parquet\")\n            metadata_filename = os.path.join(path,\
        \ \"soundscape_metadata.json\")\n        elif product_type == \"sequence\"\
        :\n            product_name = \"Soundscape sequential plot\"\n           \
        \ file_path = os.path.join(path, \"soundscape_seq.png\")\n            metadata_filename\
        \ = os.path.join(path, \"soundscape_seq_metadata.json\")\n        elif product_type\
        \ == \"standard_deviation\":\n            product_name = \"Soundscape standard\
        \ deviation plot\"\n            file_path = os.path.join(path, \"std_soundscape.png\"\
        )\n            metadata_filename = os.path.join(path, \"std_soundscape_metadata.json\"\
        )\n        elif product_type == \"mean\":\n            product_name = \"Soundscape\
        \ mean plot\"\n            file_path = os.path.join(path, \"mean_soundscape.png\"\
        )\n            metadata_filename = os.path.join(path, \"mean_soundscape_metadata.json\"\
        )\n\n        if int(node.split(\"_\")[2]) == 0:\n            node_category\
        \ = \"Degradado\"\n        elif int(node.split(\"_\")[2]) == 1:\n        \
        \    node_category = \"Integro\"\n\n        metadata = {\n            \"product_parent\"\
        : parent,\n            \"product_name\": product_name,\n            \"product_configs\"\
        : sc_config,\n            \"product_path\": file_path,\n            \"product_spectrum\"\
        : product_spectrum,\n            \"CumulusName\": cumulus,\n            \"\
        NodeCategoryIntegrity\": node_category,\n            \"NomenclatureNode\"\
        : node,\n            \"SerialNumber\": recorder,\n            \"DateDeployment\"\
        : deployment\n        }\n\n        with open(metadata_filename, 'w', encoding='utf-8')\
        \ as f:\n            json.dump(metadata, f, ensure_ascii=False, indent=4)\n\
        \n    def save_metadata_spectrogram(audio_id, product_spectrum,\n        \
        \              path, cumulus, node, recorder, deployment, parent=\"Null\"\
        ):\n        # identifier is being used as audio_id in alfresco\n        product_name\
        \ = \"Spectrogram\"\n        file_path = os.path.join(path, f\"{audio_id}.png\"\
        )\n        metadata_filename = os.path.join(path, f\"{audio_id}_spectrogram_metadata.json\"\
        )\n\n        if int(node.split(\"_\")[2]) == 0:\n            node_category\
        \ = \"Degradado\"\n        elif int(node.split(\"_\")[2]) == 1:\n        \
        \    node_category = \"Integro\"\n\n        metadata = {\n            \"product_parent\"\
        : parent,\n            \"product_name\": product_name,\n            \"product_path\"\
        : file_path,\n            \"product_spectrum\": product_spectrum,\n      \
        \      \"CumulusName\": cumulus,\n            \"NodeCategoryIntegrity\": node_category,\n\
        \            \"NomenclatureNode\": node,\n            \"SerialNumber\": recorder,\n\
        \            \"DateDeployment\": deployment,\n            \"AudioID\": audio_id\n\
        \        }\n        with open(metadata_filename, 'w', encoding='utf-8') as\
        \ f:\n            json.dump(metadata, f, ensure_ascii=False, indent=4)\n\n\
        \        print(f\"{file_path} saved.\")\n        print(f\"{metadata_filename}\
        \ saved.\")\n\n    def save_metadata_videoclip(audio_id, product_spectrum,\
        \ path, cumulus, node, recorder, \n                                deployment,\
        \ clip_start, clip_end, parent=\"Null\"):\n        # identifier is being used\
        \ as audio_id in alfresco\n        product_name = \"spectrogram_video\"\n\
        \        file_path = os.path.join(path, f\"{audio_id}.mp4\")\n        metadata_filename\
        \ = os.path.join(path, f\"{audio_id}_spectrogram_video_metadata.json\")\n\n\
        \        if int(node.split(\"_\")[2]) == 0:\n            node_category = \"\
        Degradado\"\n        elif int(node.split(\"_\")[2]) == 1:\n            node_category\
        \ = \"Integro\"\n\n        metadata = {\n            \"product_parent\": parent,\n\
        \            \"product_name\": product_name,\n            \"product_description\"\
        : \"Spectrogram Video. Time is show in local timezone\",\n            \"product_path\"\
        : file_path,\n            \"product_spectrum\": product_spectrum,\n      \
        \      \"CumulusName\": cumulus,\n            \"NodeCategoryIntegrity\": node_category,\n\
        \            \"NomenclatureNode\": node,\n            \"SerialNumber\": recorder,\n\
        \            \"DateDeployment\": deployment,\n            \"ClipStart\": clip_start,\n\
        \            \"ClipEnd\": clip_end,\n            \"AudioID\": audio_id\n \
        \       }\n\n        with open(metadata_filename, 'w', encoding='utf-8') as\
        \ f:\n            json.dump(metadata, f, ensure_ascii=False, indent=4)\n\n\
        \        print(f\"{file_path} saved.\")\n        print(f\"{metadata_filename}\
        \ saved.\")\n\n    def upload(session, node_id, data, file):\n        \"\"\
        \"\n        Uploads a file to a specific folder.\n        Parameters:\n  \
        \          session (Session):          A session object to make\n        \
        \                                requests to alfresco.\n            node_id\
        \ (string):           Node id to which the file is going to be created\n \
        \           data (dict):                Dict that contains file options\n\
        \            file (object):              File to upload\n\n        Returns:\n\
        \            (list):     A list containing status code and status data\n \
        \       \"\"\"\n\n        try:\n            response = session.post(os.getenv(\"\
        ALFRESCO_URL\")\n                        + BASE_ENDPOINT + \"/nodes/\" + node_id\
        \ + \"/children\",\n                        data = data,\n               \
        \         files = file\n                        )\n\n            return [response.json(),\
        \ response.status_code];\n        except Exception as e: \n            print(\"\
        File \" + data[\"name\"] + \" could not be uploaded: \", e)\n\n    def upload_files(file_patterns,\
        \ session, node_id, dir_path, recursive, file_identifier=\"\"):\n        \"\
        \"\"\n        Uploads the files stored in a specific dir\n        to alfresco\n\
        \        Parameters:\n            session (Session):          A session object\
        \ to make\n                                        requests to alfresco.\n\
        \            node_id (string):           Node id to which the file is going\
        \ to be created\n            dir_path (string):          The name and path\
        \ of the dir where files are stored\n            recursive (boolean):    \
        \    A boolean to know if upload  must be recursive\n                    \
        \                    in the specifed dir, and should preserve the\n      \
        \                                  structure of dirs inside.\n           \
        \ file_identifier (string):   File identifier for all files inside a dir\n\
        \        Returns:\n            (string):           Returns the info of recent\
        \ created site.\n        \"\"\"\n\n        if recursive:\n            expression\
        \ = \"/**/*\"\n        else:\n            expression = \"/*\"\n\n        files_in_dir\
        \ = list(\n            itertools.chain.from_iterable(\n                glob.iglob(dir_path\
        \ + expression + pattern, recursive=recursive)\n                for pattern\
        \ in file_patterns\n            )\n        )\n        filename = \"logs/upload_log\"\
        \ + dir_path.replace('/','-') + '.txt'\n\n        os.makedirs(os.path.dirname(filename),\
        \ exist_ok=True)\n\n        total_files = len(files_in_dir)\n        starttime\
        \ = time.time()\n\n        try:\n            files_uploaded = []\n       \
        \     for idx, file_with_path in enumerate(files_in_dir):\n\n            \
        \    # total time since last login or script start\n                total_time\
        \ = round((time.time() - starttime), 2)\n\n                if total_time >\
        \ 2400:\n                    \"\"\"\n                    if total time is\
        \ bigger than 2400\n                    or 40 minutes relogin to avoid ticket\n\
        \                    expiration\n                    \"\"\"\n            \
        \        time.sleep(5)\n\n                    print(\"Re-logging in to alfresco...\"\
        )\n\n                    session = login.login()\n                    # restart\
        \ time\n                    starttime = time.time()\n                    time.sleep(5)\n\
        \                    print(\"Login sucessful, continuing upload\\\\n\")\n\n\
        \                len_of_path = len(file_with_path.split(\"/\"))\n        \
        \        name_of_file = file_with_path.split(\"/\")[len_of_path - 1]\n   \
        \             root_dir_path = file_with_path.replace(dir_path, \"\").replace(\n\
        \                    file_with_path.split(\"/\")[len_of_path - 1], \"\"\n\
        \                )\n\n                data = {\n                    \"name\"\
        : (\n                        name_of_file[0 : len(name_of_file) - 4]\n   \
        \                     + file_identifier\n                        + name_of_file[len(name_of_file)\
        \ - 4 : len(name_of_file)]\n                    ),\n                    \"\
        nodeType\": \"cm:content\",\n                }\n\n                data[\"\
        relativePath\"] = root_dir_path\n\n                data[\"properties\"] =\
        \ {\n                    \"cm:title\": (\n                        name_of_file[0\
        \ : len(name_of_file) - 4]\n                        + file_identifier\n  \
        \                      + name_of_file[len(name_of_file) - 4 : len(name_of_file)]\n\
        \                    )\n                }\n\n                print(\"Uploading\
        \ \" + data[\"name\"] + \" file...\")\n\n                files = {\"filedata\"\
        : open(file_with_path, \"rb\")}\n                upload_response = upload(session,\
        \ node_id, data, files)\n                if upload_response[1] and upload_response[1]\
        \ == 201:\n                    files_uploaded.append(upload_response[0])\n\
        \                    print(\"Uploaded \" + data[\"name\"])\n\n           \
        \         filename = \"logs/upload_log\" + dir_path.replace('/','-') + '.txt'\n\
        \                    with open(filename, 'a') as log_file:\n             \
        \           log_file.writelines(\"%s\\\\n\" % file_with_path)\n\n        \
        \        elif upload_response[1] and upload_response[1] == 409:\n        \
        \            if \"already exists\" in upload_response[0][\"error\"][\"errorKey\"\
        ]:\n                        print(\"File \" + data[\"name\"] + \" already\
        \ uploaded\")\n\n                else:\n                    print(\"An error\
        \ ocurred, file \" + data[\"name\"] + \" cannot be uploaded\")\n\n       \
        \         print(\"Uploaded file \" + str(idx + 1) + \" of \" + str(total_files))\n\
        \                print(\"\\\\n\\\\n\")\n\n            return files_uploaded\n\
        \        except Exception as e:\n            print(\"An error ocurred in file\
        \ upload: \", e)\n\n    def vectorize_soundscape(df, hash_name, indices):\n\
        \        \\'\\'\\'Return dataframe with array column containing indices by\
        \ frequency\\'\\'\\'\n        return (df\n                .groupby(by=[\"\
        id\", hash_name, \"start_time\", \"end_time\"])\n                .apply(get_vectors,\
        \ indices)\n                .reset_index()\n                .rename(columns={0:\"\
        index_vector\"}))\n    '''\n\n    _kale_block3 = '''\n    # hasher config\
        \ \n    hasher_config = {'module': {'object_name': 'yuntu.soundscape.hashers.crono.CronoHasher'},\n\
        \                     'kwargs': {'time_utc_column': 'abs_start_time'}}\n\n\
        \    hasher_config[\"kwargs\"][\"time_unit\"] = HASHER_TIME_UNIT\n    hasher_config[\"\
        kwargs\"][\"time_module\"] = HASHER_TIME_MODULE\n    hasher_config[\"kwargs\"\
        ][\"start_tzone\"] = \"America/Mexico_City\"\n    hasher_config[\"kwargs\"\
        ][\"start_time\"] = DEFAULT_HASHER_CONFIG[\"start_time\"]\n    hasher_config[\"\
        kwargs\"][\"start_format\"] = DEFAULT_HASHER_CONFIG[\"start_format\"]\n  \
        \  hasher_config[\"kwargs\"][\"aware_start\"] = None\n\n    # soundscape config\
        \ \n    slice_config  = dict(CronoSoundscape()[\"slice_config\"].data)\n \
        \   slice_config[\"time_unit\"] = TIME_UNIT\n    slice_config[\"frequency_bins\"\
        ] = FREQUENCY_BINS\n    slice_config[\"frequency_limits\"] = (FREQUENCY_LIMITS_LB,\
        \ FREQUENCY_LIMITS_UB)\n\n    # FED configuration [\"TOTAL\", \"CORE\", \"\
        TAIL\", \"INFORMATION\", \"ICOMPLEXITY\", \"EXAG\"]\n    indices = CronoSoundscape()[\"\
        indices\"].data + [ICOMPLEXITY()]  + [TAIL()]\n\n    # dask local cluster\n\
        \    n_workers = int(0.95 * multiprocessing .cpu_count()) \n    cluster =\
        \ LocalCluster(n_workers = n_workers, \n                           threads_per_worker\
        \ = THREADS_PER_WORKER)\n    client = Client(cluster)\n    npartitions = len(client.ncores())\n\
        \n    # FEED\n    FEED = {\n        \"slice_config\": slice_config,\n    \
        \    \"indices\": indices,\n        \"hash_name\": HASH_NAME,\n        \"\
        hasher_config\": hasher_config,\n        \"npartitions\": npartitions\n  \
        \  }\n\n    # adjust for metadata\n    indexes_computed = [\"TOTAL\", \"CORE\"\
        , \"TAIL\", \"INFORMATION\", \"ICOMPLEXITY\", \"EXAG\"]\n    FEED_metadata\
        \ = FEED.copy()\n    FEED_metadata[\"indices\"] = indexes_computed\n\n   \
        \ plot_indices = [RED_IDX, GREEN_IDX, BLUE_IDX] # rgb order\n\n    # soundscape\
        \ per unit (cumulus-node-recorder-deployment_date)\n    proc_units = recs.proc_unit.unique()\n\
        \n    for proc_unit in proc_units:\n        try: \n            start_soundscape\
        \ = time.monotonic()\n            node, recorder, deployment = proc_unit\n\
        \            print(f\"* Processing: Cumulus {CUMULO} | node {node} | recorder\
        \ {recorder} | deployment date {deployment}\")\n            file_path = os.path.join(RESULTS_DIR,\
        \ str(CUMULO), str(node), recorder, deployment)\n            parent_id = hashlib.md5(file_path.encode('utf-8')).hexdigest()\n\
        \            # soundscape = recs[recs.proc_unit == proc_unit].audio.get_soundscape(client=client,\
        \ npartitions=n_workers, **soundscape_config)\n            soundscape_data\
        \ = recs[recs.proc_unit == proc_unit]\n            pipeline = CronoSoundscape(name\
        \ = \"soundscape\", work_dir = WORK_DIR_PIPELINE, recordings = soundscape_data)\n\
        \            soundscape = pipeline[\"hashed_soundscape\"].compute(client=client,\
        \ feed=FEED)\n\n            # sequence\n            plot_soundscape(soundscape,\
        \ \"sequence\", SPECTRUM, FEED_metadata, file_path,\n                    \
        \        CUMULO, node, recorder, deployment, parent_id, plot_indices, MIN_FREQ_SC)\
        \    \n            # mean\n            plot_soundscape(soundscape, \"mean\"\
        , SPECTRUM, FEED_metadata, file_path, \n                            CUMULO,\
        \ node, recorder, deployment, parent_id, plot_indices, MIN_FREQ_SC)\n\n  \
        \          # standard deviation\n            plot_soundscape(soundscape, \"\
        standard_deviation\", SPECTRUM, FEED_metadata, file_path, \n             \
        \               CUMULO, node, recorder, deployment, parent_id, plot_indices,\
        \ MIN_FREQ_SC)\n\n            # save soundscape vector\n            soundscape_path\
        \ = os.path.join(file_path, \"hashed_soundscape.parquet\")\n            #\
        \ soundscape_orig_path = os.path.join(RESULTS_DIR, \"get_soundscape/persist/hashed_soundscape.parquet\"\
        ) \n            soundscape_orig_path = '/shared_volume/audio/soundscape/persist/hashed_soundscape.parquet'\n\
        \            shutil.move(soundscape_orig_path,soundscape_path)\n         \
        \   save_metadata_sc(\"soundscape\", SPECTRUM, FEED_metadata, file_path,\n\
        \                          CUMULO, node, recorder, deployment)\n         \
        \   shutil.rmtree('/shared_volume/audio/soundscape')\n\n        except:\n\
        \            pass\n        # restart client\n        client.restart()\n\n\
        \    client.close()\n    cluster.close()\n\n    # remove empty subdirectories\n\
        \    remove_empty_folders(RESULTS_DIR)\n    '''\n\n    _kale_data_saving_block\
        \ = '''\n    # -----------------------DATA SAVING START---------------------------------\n\
        \    from kale import marshal as _kale_marshal\n    _kale_marshal.set_data_dir(\"\
        /shared_volume/audio/.sndscs_spec_specvid-sipecam-cumulus-node-recorder-deployment-aws.ipynb.kale.marshal.dir\"\
        )\n    _kale_marshal.save(recs, \"recs\")\n    # -----------------------DATA\
        \ SAVING END-----------------------------------\n    '''\n\n    # run the\
        \ code blocks inside a jupyter kernel\n    from kale.common.jputils import\
        \ run_code as _kale_run_code\n    from kale.common.kfputils import \\\n  \
        \      update_uimetadata as _kale_update_uimetadata\n    _kale_blocks = (_kale_pipeline_parameters_block,\
        \ _kale_data_loading_block,\n                    _kale_block1,\n         \
        \           _kale_block2,\n                    _kale_block3,\n           \
        \         _kale_data_saving_block)\n    _kale_html_artifact = _kale_run_code(_kale_blocks)\n\
        \    with open(\"/compute_soundscapes.html\", \"w\") as f:\n        f.write(_kale_html_artifact)\n\
        \    _kale_update_uimetadata('compute_soundscapes')\n\n    _kale_mlmdutils.call(\"\
        mark_execution_complete\")\n\nimport argparse\n_parser = argparse.ArgumentParser(prog='Compute\
        \ soundscapes', description='')\n_parser.add_argument(\"--AUTH-ENDPOINT\"\
        , dest=\"AUTH_ENDPOINT\", type=str, required=True, default=argparse.SUPPRESS)\n\
        _parser.add_argument(\"--BASE-ENDPOINT\", dest=\"BASE_ENDPOINT\", type=str,\
        \ required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"--BLUE-IDX\"\
        , dest=\"BLUE_IDX\", type=str, required=True, default=argparse.SUPPRESS)\n\
        _parser.add_argument(\"--CUMULO\", dest=\"CUMULO\", type=int, required=True,\
        \ default=argparse.SUPPRESS)\n_parser.add_argument(\"--FREQUENCY-BINS\", dest=\"\
        FREQUENCY_BINS\", type=int, required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"\
        --FREQUENCY-LIMITS-LB\", dest=\"FREQUENCY_LIMITS_LB\", type=int, required=True,\
        \ default=argparse.SUPPRESS)\n_parser.add_argument(\"--FREQUENCY-LIMITS-UB\"\
        , dest=\"FREQUENCY_LIMITS_UB\", type=int, required=True, default=argparse.SUPPRESS)\n\
        _parser.add_argument(\"--GREEN-IDX\", dest=\"GREEN_IDX\", type=str, required=True,\
        \ default=argparse.SUPPRESS)\n_parser.add_argument(\"--HASHER-TIME-MODULE\"\
        , dest=\"HASHER_TIME_MODULE\", type=int, required=True, default=argparse.SUPPRESS)\n\
        _parser.add_argument(\"--HASHER-TIME-UNIT\", dest=\"HASHER_TIME_UNIT\", type=int,\
        \ required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"--HASH-NAME\"\
        , dest=\"HASH_NAME\", type=str, required=True, default=argparse.SUPPRESS)\n\
        _parser.add_argument(\"--MIN-FREQ-SC\", dest=\"MIN_FREQ_SC\", type=int, required=True,\
        \ default=argparse.SUPPRESS)\n_parser.add_argument(\"--RED-IDX\", dest=\"\
        RED_IDX\", type=str, required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"\
        --RESULTS-DIR\", dest=\"RESULTS_DIR\", type=str, required=True, default=argparse.SUPPRESS)\n\
        _parser.add_argument(\"--SPECTRUM\", dest=\"SPECTRUM\", type=str, required=True,\
        \ default=argparse.SUPPRESS)\n_parser.add_argument(\"--THREADS-PER-WORKER\"\
        , dest=\"THREADS_PER_WORKER\", type=int, required=True, default=argparse.SUPPRESS)\n\
        _parser.add_argument(\"--TIME-UNIT\", dest=\"TIME_UNIT\", type=int, required=True,\
        \ default=argparse.SUPPRESS)\n_parser.add_argument(\"--WORK-DIR-PIPELINE\"\
        , dest=\"WORK_DIR_PIPELINE\", type=str, required=True, default=argparse.SUPPRESS)\n\
        _parsed_args = vars(_parser.parse_args())\n\n_outputs = compute_soundscapes(**_parsed_args)\n"
      image: sipecam/audio-dgpi-kale-tensorflow-yuntu-dask-cert:0.6.1_dev
      securityContext: {runAsUser: 0}
      volumeMounts:
      - {mountPath: /shared_volume, name: pvolume-ef6fe65091618f865041935b363277953274adf6b420fd4a7b8277d}
      workingDir: //shared_volume/audio
    inputs:
      parameters:
      - {name: AUTH_ENDPOINT}
      - {name: BASE_ENDPOINT}
      - {name: BLUE_IDX}
      - {name: CUMULO}
      - {name: FREQUENCY_BINS}
      - {name: FREQUENCY_LIMITS_LB}
      - {name: FREQUENCY_LIMITS_UB}
      - {name: GREEN_IDX}
      - {name: HASHER_TIME_MODULE}
      - {name: HASHER_TIME_UNIT}
      - {name: HASH_NAME}
      - {name: MIN_FREQ_SC}
      - {name: RED_IDX}
      - {name: RESULTS_DIR}
      - {name: SPECTRUM}
      - {name: THREADS_PER_WORKER}
      - {name: TIME_UNIT}
      - {name: WORK_DIR_PIPELINE}
      - {name: vol_shared_volume}
    outputs:
      artifacts:
      - {name: mlpipeline-ui-metadata, path: /tmp/mlpipeline-ui-metadata.json}
      - {name: compute_soundscapes, path: /compute_soundscapes.html}
    metadata:
      annotations: {kubeflow-kale.org/dependent-templates: '["create-results-dirstruct",
          "get-audio-df"]', pipelines.kubeflow.org/component_spec: '{"implementation":
          {"container": {"args": ["--AUTH-ENDPOINT", {"inputValue": "AUTH_ENDPOINT"},
          "--BASE-ENDPOINT", {"inputValue": "BASE_ENDPOINT"}, "--BLUE-IDX", {"inputValue":
          "BLUE_IDX"}, "--CUMULO", {"inputValue": "CUMULO"}, "--FREQUENCY-BINS", {"inputValue":
          "FREQUENCY_BINS"}, "--FREQUENCY-LIMITS-LB", {"inputValue": "FREQUENCY_LIMITS_LB"},
          "--FREQUENCY-LIMITS-UB", {"inputValue": "FREQUENCY_LIMITS_UB"}, "--GREEN-IDX",
          {"inputValue": "GREEN_IDX"}, "--HASHER-TIME-MODULE", {"inputValue": "HASHER_TIME_MODULE"},
          "--HASHER-TIME-UNIT", {"inputValue": "HASHER_TIME_UNIT"}, "--HASH-NAME",
          {"inputValue": "HASH_NAME"}, "--MIN-FREQ-SC", {"inputValue": "MIN_FREQ_SC"},
          "--RED-IDX", {"inputValue": "RED_IDX"}, "--RESULTS-DIR", {"inputValue":
          "RESULTS_DIR"}, "--SPECTRUM", {"inputValue": "SPECTRUM"}, "--THREADS-PER-WORKER",
          {"inputValue": "THREADS_PER_WORKER"}, "--TIME-UNIT", {"inputValue": "TIME_UNIT"},
          "--WORK-DIR-PIPELINE", {"inputValue": "WORK_DIR_PIPELINE"}], "command":
          ["sh", "-ec", "program_path=$(mktemp)\nprintf \"%s\" \"$0\" > \"$program_path\"\npython3
          -u \"$program_path\" \"$@\"\n", "def compute_soundscapes(AUTH_ENDPOINT,
          BASE_ENDPOINT, BLUE_IDX, CUMULO, FREQUENCY_BINS, FREQUENCY_LIMITS_LB, FREQUENCY_LIMITS_UB,
          GREEN_IDX, HASHER_TIME_MODULE, HASHER_TIME_UNIT, HASH_NAME, MIN_FREQ_SC,
          RED_IDX, RESULTS_DIR, SPECTRUM, THREADS_PER_WORKER, TIME_UNIT, WORK_DIR_PIPELINE):\n    _kale_pipeline_parameters_block
          = ''''''\n    AUTH_ENDPOINT = \"{}\"\n    BASE_ENDPOINT = \"{}\"\n    BLUE_IDX
          = \"{}\"\n    CUMULO = {}\n    FREQUENCY_BINS = {}\n    FREQUENCY_LIMITS_LB
          = {}\n    FREQUENCY_LIMITS_UB = {}\n    GREEN_IDX = \"{}\"\n    HASHER_TIME_MODULE
          = {}\n    HASHER_TIME_UNIT = {}\n    HASH_NAME = \"{}\"\n    MIN_FREQ_SC
          = {}\n    RED_IDX = \"{}\"\n    RESULTS_DIR = \"{}\"\n    SPECTRUM = \"{}\"\n    THREADS_PER_WORKER
          = {}\n    TIME_UNIT = {}\n    WORK_DIR_PIPELINE = \"{}\"\n    ''''''.format(AUTH_ENDPOINT,
          BASE_ENDPOINT, BLUE_IDX, CUMULO, FREQUENCY_BINS, FREQUENCY_LIMITS_LB, FREQUENCY_LIMITS_UB,
          GREEN_IDX, HASHER_TIME_MODULE, HASHER_TIME_UNIT, HASH_NAME, MIN_FREQ_SC,
          RED_IDX, RESULTS_DIR, SPECTRUM, THREADS_PER_WORKER, TIME_UNIT, WORK_DIR_PIPELINE)\n\n    from
          kale.common import mlmdutils as _kale_mlmdutils\n    _kale_mlmdutils.init_metadata()\n\n    _kale_data_loading_block
          = ''''''\n    # -----------------------DATA LOADING START--------------------------------\n    from
          kale import marshal as _kale_marshal\n    _kale_marshal.set_data_dir(\"/shared_volume/audio/.sndscs_spec_specvid-sipecam-cumulus-node-recorder-deployment-aws.ipynb.kale.marshal.dir\")\n    recs
          = _kale_marshal.load(\"recs\")\n    # -----------------------DATA LOADING
          END----------------------------------\n    ''''''\n\n    _kale_block1 =
          ''''''\n    import base64\n    import datetime\n    import glob\n    import
          hashlib\n    import io\n    import itertools\n    import json\n    import
          matplotlib.pyplot as plt\n    import multiprocessing \n    import numpy
          as np\n    import os\n    import pandas as pd\n    import psutil\n    import
          requests\n    import shutil\n    import subprocess\n    import time\n    import
          warnings\n\n    from dask.distributed import Client, LocalCluster\n    from
          datetime import timedelta\n    from dotenv import load_dotenv\n    from
          matplotlib import cm\n    from moviepy.editor import concatenate, VideoFileClip,
          AudioFileClip\n    from moviepy.audio.AudioClip import AudioArrayClip\n    from
          moviepy.video.VideoClip import ImageClip\n    from os.path import exists
          as file_exists\n    from PIL import Image\n    from skimage.transform import
          resize\n\n    from yuntu import Audio\n    from yuntu.soundscape.utils import
          aware_time\n    from yuntu.collection.methods import collection\n    from
          yuntu.soundscape.hashers.crono import DEFAULT_HASHER_CONFIG\n    from yuntu.soundscape.processors.indices.direct
          import ICOMPLEXITY, TAIL\n    from yuntu.soundscape.pipelines.build_soundscape
          import CronoSoundscape, HASHER_CONFIG\n    ''''''\n\n    _kale_block2 =
          ''''''\n    def audio2video(audio_id,\n                    audio_df,\n                    save_path_folder,\n                    product_spectrum,\n                    cumulus,\n                    abs_start=None,\n                    fps=60,\n                    spec_configs={''hop_length'':
          512, ''n_fft'': 1024, ''window_function'': ''hann''},\n                    rate=24,\n                    frame_duration=3.0,\n                    min_freq=0,\n                    max_freq=None,\n                    cmap=\"Greys\",\n                    figsize=(5,
          8),\n                    dpi=100,\n                    bands=None):\n        \\''\\''\\''Takes
          and audio object and produces a mp4 video of the spectrogram with audio\\''\\''\\''\n\n        sub_audio_df
          = audio_df[audio_df[\"id\"]==audio_id]\n        id_audio = sub_audio_df[''id''].values[0]\n        node
          = sub_audio_df[''node''].values[0]\n        recorder = sub_audio_df[''recorder''].values[0]\n        deployment
          = sub_audio_df[''deployment''].values[0]\n        audio = sub_audio_df.audio[0]\n\n        colormap
          = cm.get_cmap(cmap)\n        duration = audio.duration\n        step = 1/rate\n        start
          = -(frame_duration/2.0)\n        stop = start + frame_duration\n        clips
          = []\n        last_stop = None\n\n        if max_freq is None:\n            max_freq
          = audio.samplerate / 2.0\n\n        if min_freq is None:\n            min_freq
          = 0\n\n        with audio.features.db_spectrogram(**spec_configs) as spec:\n            min_spec
          = np.amin(spec)\n            max_spec = np.amax(spec)\n            spec_range
          = (max_spec-min_spec)\n\n            while stop <= duration+(frame_duration/2.0):\n                clip
          = produce_clip(spec, frame_duration, min_freq, max_freq, start, stop, step,
          abs_start, colormap,\n                                    min_spec, spec_range,
          figsize, dpi, bands=bands)\n                clips.append(clip)\n\n                if
          start + step + frame_duration > duration:\n                    last_stop
          = stop\n\n                start = start + step\n                stop = start
          + frame_duration\n\n        video = concatenate(clips)\n        # edaudio
          = AudioArrayClip(audio_array, fps=audio.samplerate)\n        edaudio = AudioFileClip(audio.path).set_end(audio.duration)\n        video
          = video.set_audio(edaudio)\n        file_path = os.path.join(save_path_folder,
          f\"{audio_id}.mp4\")\n        video.write_videofile(file_path, fps=fps)\n\n        save_metadata_videoclip(audio_id,
          product_spectrum,\n                      save_path_folder, cumulus, node,
          recorder, deployment, 0.0, audio.duration)\n        video.close()\n        edaudio.close()\n\n        for
          c in clips:\n            c.close()\n\n    def change_type_sipecam_sc(session,
          root_folder_id, path, file_type, node_type):\n        if file_type == \"sequence.png\":\n            metadata_name
          = \"soundscape_seq_metadata.json\"\n            aggr_type = \"None\"\n        elif
          file_type == \"mean_soundscape.png\":\n            metadata_name = \"mean_soundscape_metadata.json\"\n            aggr_type
          = \"Mean\"\n        elif file_type ==  \"std_soundscape.png\":\n            metadata_name
          = \"std_soundscape_metadata.json\" \n            aggr_type = \"Standard
          deviation\"\n        elif file_type == \"hashed_soundscape.parquet\":\n            metadata_name
          = \"soundscape_metadata.json\" \n            aggr_type = \"None\"\n        elif
          \".png\" in file_type and (file_type not in [\"sequence.png\", \"mean_soundscape.png\",
          \"std_soundscape.png\"]):\n            metadata_name = file_type.split(\".\")[0]
          + \"_spectrogram_metadata.json\"\n            aggr_type = \"Null\"\n        elif
          \".mp4\" in file_type and (file_type not in [\"sequence.png\", \"mean_soundscape.png\",
          \"std_soundscape.png\"]):\n            metadata_name = file_type.split(\".\")[0]
          + \"_spectrogram_video_metadata.json\"\n            aggr_type = \"Null\"\n\n        try:\n            semi_path
          = path.split(\"soundscapes/\")[-1]\n            semi_path_file = os.path.join(semi_path,
          file_type)\n            local_path_file_metadata = os.path.join(path, metadata_name)\n            print(f\"Changing
          type for {os.path.join(semi_path)}\")\n            alfresco_path = os.path.join(\"/Company
          Home/Sites/sipecam-soundscape/documentLibrary/\", semi_path)\n\n            response
          = session.get(\n                os.getenv(\"ALFRESCO_URL\")\n                +
          BASE_ENDPOINT\n                + \"/nodes/\"\n                + root_folder_id\n                +
          \"/children?relativePath=\"+semi_path+\"&include=aspectNames&skipCount=0\"\n            )        \n            #
          if request is successful then continue\n            if response.status_code
          == 200:\n\n                data_file = open(local_path_file_metadata)\n                data_json
          = json.load(data_file)\n                response_entries = response.json()[\"list\"][\"entries\"]\n\n                for
          entry in response_entries:\n                    if entry[''entry''][''name'']==file_type
          and entry[''entry''][''isFile'']:\n                        prop_dict = {}\n\n                        if
          entry[''entry''][''name'']==file_type:\n\n                            if
          entry[''entry''][''name''] in [\"sequence.png\", \"mean_soundscape.png\",
          \"std_soundscape.png\"]:\n                                prop_dict[\"soundscape:CumulusName\"]
          = str(data_json[\"CumulusName\"])\n                                prop_dict[\"soundscape:DateDeployment\"]
          = data_json[\"DateDeployment\"]\n                                prop_dict[\"soundscape:NodeCategoryIntegrity\"]
          = str(data_json[\"NodeCategoryIntegrity\"])\n                                prop_dict[\"soundscape:NomenclatureNode\"]
          = str(data_json[\"NomenclatureNode\"])\n                                prop_dict[\"soundscape:SerialNumber\"]
          = str(data_json[\"SerialNumber\"])\n                                prop_dict[\"soundscape:aggr\"]
          = str(aggr_type)\n                                prop_dict[\"soundscape:cycle_config_aware_start\"]
          = str(data_json[\"product_configs\"][''hasher_config''][''kwargs''][''aware_start''])\n                                prop_dict[\"soundscape:cycle_config_start_format\"]
          = str(data_json[\"product_configs\"][''hasher_config''][''kwargs''][''start_format''])\n                                prop_dict[\"soundscape:cycle_config_start_time\"]
          =  datetime.datetime.strptime(data_json[\"product_configs\"][''hasher_config''][''kwargs''][''start_time''],
          \n                                                                                                        \"%Y-%m-%d
          %H:%M:%S\").strftime(\"%Y-%m-%dT%H:%M:%S.%f%z\")\n                                prop_dict[\"soundscape:cycle_config_start_tzone\"]
          = str(data_json[\"product_configs\"][''hasher_config''][''kwargs''][''start_tzone''])\n                                prop_dict[\"soundscape:cycle_config_time_module\"]
          = int(data_json[\"product_configs\"][''hasher_config''][''kwargs''][''time_module''])\n                                prop_dict[\"soundscape:cycle_config_time_unit\"]
          = str(data_json[\"product_configs\"][''hasher_config''][''kwargs''][''time_unit''])\n                                prop_dict[\"soundscape:cycle_config_time_utc_column\"]
          = str(data_json[\"product_configs\"][''hasher_config''][''kwargs''][''time_utc_column''])\n                                prop_dict[\"soundscape:frequency_bins\"]
          = int(data_json[\"product_configs\"][\"slice_config\"][\"frequency_bins\"])\n                                prop_dict[\"soundscape:frequency_hop\"]
          = int(data_json[\"product_configs\"][\"slice_config\"][\"frequency_hop\"])\n                                prop_dict[\"soundscape:frequency_limits\"]
          = str(data_json[\"product_configs\"][\"slice_config\"][\"frequency_limits\"])\n                                prop_dict[\"soundscape:hash_name\"]
          = str(data_json[\"product_configs\"][\"hash_name\"])\n                                prop_dict[\"soundscape:hop_length\"]
          = int(data_json[\"product_configs\"][\"slice_config\"][\"feature_config\"][\"hop_length\"])\n                                prop_dict[\"soundscape:indices\"]
          =  \", \".join(map(str, data_json[''product_configs''][''indices'']))\n                                prop_dict[\"soundscape:n_fft\"]
          = int(data_json[\"product_configs\"][\"slice_config\"][\"feature_config\"][\"n_fft\"])\n                                prop_dict[\"soundscape:npartitions\"]
          = int(data_json[\"product_configs\"][''npartitions''])\n                                prop_dict[\"soundscape:product_name\"]
          = str(data_json[\"product_name\"])\n                                prop_dict[\"soundscape:product_parent\"]
          = str(data_json[\"product_parent\"])\n                                prop_dict[\"soundscape:product_path\"]
          = str(alfresco_path)\n                                prop_dict[\"soundscape:product_spectrum\"]
          = str(data_json[\"product_spectrum\"])\n                                prop_dict[\"soundscape:slice_config_feature_type\"]
          = str(data_json[\"product_configs\"][\"slice_config\"][\"feature_type\"])\n                                prop_dict[\"soundscape:slice_config_frequency_bins\"]
          = int(data_json[\"product_configs\"][\"slice_config\"][\"frequency_bins\"])\n                                prop_dict[\"soundscape:slice_config_time_unit\"]
          = int(data_json[\"product_configs\"][\"slice_config\"][\"time_unit\"])\n                                prop_dict[\"soundscape:time_hop\"]
          = int(data_json[\"product_configs\"][\"slice_config\"][\"time_hop\"])\n                                prop_dict[\"soundscape:window_function\"]
          = str(data_json[\"product_configs\"][\"slice_config\"][\"feature_config\"][\"window_function\"])  \n\n                            elif
          (\"spectrogram\" or \"video\") in entry[''entry''][''name'']:\n                                prop_dict[\"soundscape:product_name\"]
          = str(data_json[\"product_name\"])\n                                prop_dict[\"soundscape:product_parent\"]
          = str(data_json[\"product_parent\"])\n                                prop_dict[\"soundscape:product_path\"]
          = str(alfresco_path)\n                                prop_dict[\"soundscape:product_spectrum\"]
          = str(data_json[\"product_spectrum\"])\n                                prop_dict[\"soundscape:CumulusName\"]
          = str(data_json[\"CumulusName\"])\n                                prop_dict[\"soundscape:NodeCategoryIntegrity\"]
          = str(data_json[\"NodeCategoryIntegrity\"])\n                                prop_dict[\"soundscape:NomenclatureNode\"]
          = str(data_json[\"NomenclatureNode\"])\n                                prop_dict[\"soundscape:SerialNumber\"]
          = str(data_json[\"SerialNumber\"])\n                                prop_dict[\"soundscape:DateDeployment\"]
          = data_json[\"DateDeployment\"]\n                                prop_dict[\"soundscape:AudioID\"]
          = data_json[\"AudioID\"]\n\n                        aspects = entry[''entry''][''aspectNames'']\n                        data
          = {\"aspectNames\": aspects, \"nodeType\": node_type, \"properties\": prop_dict}\n                        #
          update properties request\n                        update = session.put(\n                            os.getenv(\"ALFRESCO_URL\")\n                            +
          BASE_ENDPOINT\n                            + \"/nodes/\"\n                            +
          entry[''entry''][''id''],\n                            data=json.dumps(data),\n                        )\n\n                        if
          update.status_code == 200:\n                            print(\"Updated
          \" + entry[''entry''][''id''])                    \n\n        except Exception
          as e:\n            print(\"Could not add any aspect to this file: \", e)\n\n    def
          create_results_folder_str(results_dir, cumulo, nodes_list, rec_list, dep_list):
          \n        # results directory\n        os.makedirs(results_dir, exist_ok=True)\n        #
          cumulus subdir\n        cum_subdir = os.path.join(results_dir, str(cumulo))\n        os.makedirs(cum_subdir,
          exist_ok=True)\n        # node subdirs\n        for node in nodes_list:\n            node_subdir
          = os.path.join(cum_subdir, node)\n            os.makedirs(node_subdir, exist_ok=True)\n            #
          recorder subdirs\n            for rec in rec_list:\n                rec_subdir
          = os.path.join(node_subdir, rec)\n                os.makedirs(rec_subdir,
          exist_ok=True)\n                # deployment subdirs\n                for
          dep in dep_list:\n                    dep_subdir = os.path.join(rec_subdir,
          dep)\n                    os.makedirs(dep_subdir, exist_ok=True)\n\n    def
          distance_to_mean(vector, mean):\n        \\''\\''\\''Return euclidean distance
          to mean\\''\\''\\''\n        return np.sqrt(np.sum(np.square(mean - vector)))\n\n    def
          find_subfolders(path_abs):\n        subdir_list = []\n        walk = list(os.walk(path_abs))\n        for
          path, _, _ in walk[::-1]:\n            len_path = path.split(\"/\")\n            if
          len(len_path) == 8:\n                subdir_list.append(path)  \n\n        return
          subdir_list\n\n    def get_audio_ids(soundscape_path, indices, nsamples):\n        df
          = pd.read_parquet(os.path.join(soundscape_path, \"hashed_soundscape.parquet\"))\n\n        df[\"time_raw_hour\"]
          = df[\"time_raw\"].apply(lambda x: datetime.datetime.strptime(x,''%H:%M:%S
          %d/%m/%Y (%z)'').strftime(\"%H\"))\n        hours_list = list(df.time_raw_hour.unique())\n        hours_list.sort(key
          = int)\n\n        with open(os.path.join(soundscape_path, \"soundscape_metadata.json\"))
          as f:\n            metadata = json.load(f)\n            f.close()\n\n        #
          indices = metadata[\"product_configs\"][\"indices\"]\n        # indices
          = [\"EXAG\", \"ICOMPLEXITY\", \"CORE\"]\n        hash_name = metadata[\"product_configs\"][\"hash_name\"]\n        cycle_config
          = metadata[\"product_configs\"][\"hasher_config\"][\"kwargs\"]\n        time_unit
          = cycle_config[\"time_unit\"]\n        zero_t = aware_time(cycle_config[\"start_time\"],
          cycle_config[\"start_tzone\"], cycle_config[\"start_format\"]) \n\n        #
          iterate over hours\n        audio_id_list = []\n        for hour in hours_list:\n            subdf
          = df.query(f\"time_raw_hour == ''{hour}''\")\n            # sample\n            samples_df
          = get_recording_samples(subdf, hash_name, indices, time_unit, zero_t, nsamples=3)\n            unique_crono_hash_list
          = list(samples_df.crono_hash_30m.unique())\n            sub_df = samples_df[samples_df.crono_hash_30m
          == min(unique_crono_hash_list)]\n            audio_id_list += list(sub_df.id.tolist())\n\n        return
          audio_id_list\n\n    def get_recording_samples(df, hash_name, indices, time_unit,
          zero_t, nsamples=5):\n        \\''\\''\\''Return dataframe of ''nsamples''
          samples for each tag in ''hash_name'' column that are closest to the mean
          vector by tag\\''\\''\\''\n        proj_df = df[(df.max_freq <= 10000)]\n        crono_tags
          = proj_df.crono_hash_30m.unique()\n        proj_df.loc[: , f\"{hash_name}_time\"]
          = proj_df[hash_name].apply(lambda x: zero_t + datetime.timedelta(seconds=float(x*time_unit)))\n        vectors
          = vectorize_soundscape(proj_df, hash_name, indices)\n        min_index_vector
          = np.amin(np.stack(list(vectors.index_vector.values)), axis=(0,1))\n        max_index_vector
          = np.amax(np.stack(list(vectors.index_vector.values)), axis=(0,1))\n        index_range
          = (max_index_vector - min_index_vector)\n        vectors.loc[:, \"normalized_index_vector\"]
          = vectors.index_vector.apply(lambda x: (x-min_index_vector)/index_range)\n        all_samples
          = []\n\n        for crono_tag in crono_tags:\n            unit_vectors =
          vectors[vectors[hash_name] == crono_tag]\n            mean_unit_vector =
          unit_vectors.normalized_index_vector.mean()\n            unit_vectors.loc[:,
          \"distance\"] = unit_vectors.normalized_index_vector.apply(lambda x: distance_to_mean(x,
          mean_unit_vector))\n            all_samples.append(unit_vectors.sort_values(by=\"distance\").head(nsamples))\n        return
          pd.concat(all_samples)\n\n    def get_vectors(group, indices):\n        \\''\\''\\''Return
          array of indices by frequency\\''\\''\\''\n        return group.sort_values(by=\"max_freq\")[indices].values\n\n    def
          login():\n        \"\"\"\n        Tries a login to alfresco api and returns
          a session\n        object with credentials \n        Returns: \n            session
          (Session):  A session object to make \n                                requests
          to zendro.\n        \"\"\"\n        try:\n            auth = {\n                \"userId\":
          os.getenv(\"ALFRESCO_USER\"),\n                \"password\": os.getenv(\"ALFRESCO_PASSWORD\"),\n            }\n\n            login
          = requests.post(os.getenv(\"ALFRESCO_URL\") + AUTH_ENDPOINT + \"/tickets\",data=json.dumps(auth))\n\n            base64_login
          = base64.b64encode(bytes(login.json()[\"entry\"][\"id\"], ''utf-8'')).decode()\n\n            #
          se crea un objeto de Session para hacer requests\n            session =
          requests.Session()\n            # se establece bearer token\n            session.headers.update({''Authorization'':
          ''Basic '' + base64_login})\n\n            return session\n        except
          Exception as e:\n            print(\"Login failed: \", e)\n\n    def plot_spectrogram(audio_id,
          audio_df, save_path_folder, spectrum, cumulus):\n        sub_audio_df =
          audio_df[audio_df[\"id\"]==audio_id]\n        node = sub_audio_df[''node''].values[0]\n        recorder
          = sub_audio_df[''recorder''].values[0]\n        deployment = sub_audio_df[''deployment''].values[0]\n        #
          plot\n        fig, ax = plt.subplots(2,1,figsize=(20,10), sharex=True)\n        sub_audio_df.audio[0].plot(ax=ax[0],
          color=''grey'')\n        sub_audio_df.audio[0].features.db_spectrogram().plot(ax=ax[1])\n        ax[0].set_ylabel(''Amplitude'')\n        ax[0].grid(False)\n        ax[1].set_ylabel(''F
          (KHz)'')\n        ax[1].set_xlabel(''Time (seconds)'')\n        fig.text(0.75,
          0.04, f\"Cumulus: {cumulus} - Node: {node} - Recorder: {recorder}\", va=''center'')\n        plt.tight_layout()\n        if
          save_path_folder:\n            file_path = os.path.join(save_path_folder,
          f\"{audio_id}.png\")\n            fig.savefig(file_path)\n        plt.show()\n\n        save_metadata_spectrogram(audio_id,
          spectrum, save_path_folder, \n                                  cumulus,
          node, recorder, deployment, parent=\"Null\")\n\n    def plot_soundscape(soundscape,
          product_type, product_spectrum, sc_config, path, \n                        cumulus,
          node, recorder, deployment, parent, indices, min_freq=None,\n                      figsize=(20,15),
          plt_style=''ggplot''):\n\n        if min_freq:\n            soundscape =
          soundscape[soundscape[''min_freq'']<=min_freq]\n\n        if product_type
          == \"sequence\":\n            file_path = os.path.join(path, \"sequence.png\")\n            #
          product_id = hashlib.md5(file_path.encode(''utf-8'')).hexdigest()\n\n            plt.style.use(plt_style)\n            fig,
          ax = plt.subplots(figsize=figsize)\n            soundscape.sndscape.plot_sequence(rgb=indices,
          time_format=''%Y-%m %H:%M'', ax=ax)\n            plt.xticks(rotation = 90)\n            ax.grid(False)\n            plt.tight_layout()\n            plt.savefig(file_path)
          \n            plt.show()\n            # save metadata\n            save_metadata_sc(product_type,
          product_spectrum, sc_config,\n                      path, cumulus, node,
          recorder, deployment, parent=parent)\n\n        elif product_type == \"standard_deviation\":\n            file_path
          = os.path.join(path, \"std_soundscape.png\")\n            # product_id =
          hashlib.md5(file_path.encode(''utf-8'')).hexdigest()\n\n            plt.style.use(plt_style)\n            fig,
          ax = plt.subplots(figsize=figsize)\n            soundscape.sndscape.plot_cycle(rgb=indices,
          aggr=\"std\", time_format=''%H:%M'', \n                                           xticks=24,
          ax=ax)\n            plt.xticks(rotation = 90)\n            ax.grid(False)\n            plt.tight_layout()
          \n            plt.savefig(file_path)\n            plt.show()\n\n            #
          save metadata\n            save_metadata_sc(product_type, product_spectrum,
          sc_config,\n                      path, cumulus, node, recorder, deployment,
          parent)     \n\n        elif product_type == \"mean\": \n            file_path
          = os.path.join(path, \"mean_soundscape.png\")\n            # product_id
          = hashlib.md5(file_path.encode(''utf-8'')).hexdigest()\n\n            plt.style.use(plt_style)\n            fig,
          ax = plt.subplots(figsize=figsize)\n            soundscape.sndscape.plot_cycle(rgb=indices,
          aggr=\"mean\", time_format=''%H:%M'', \n                                           xticks=24,
          ax=ax)\n            plt.xticks(rotation = 90)\n            ax.grid(False)\n            plt.tight_layout()\n            plt.savefig(file_path)\n            plt.show()\n\n            #
          save metadata\n            save_metadata_sc(product_type, product_spectrum,
          sc_config,\n                      path, cumulus, node, recorder, deployment,
          parent)    \n\n        print(f\"File saved at {file_path}\")\n\n    def
          produce_clip(spec, frame_duration, min_freq, max_freq, start, stop, step,
          abs_start=None, \n                     colormap=cm.get_cmap(\"Greys\"),
          min_spec=0, spec_range=1.0, figsize=(5, 4), \n                     dpi=100,
          bands=None):\n        \\''\\''\\''Takes an individual frame and produces
          an image with references\\''\\''\\''\n        frame = spec.cut_array(start_time=start,
          end_time=stop, min_freq=min_freq, max_freq=max_freq, pad=True)\n        plt.style.use(''dark_background'')\n        frame
          = np.flip((frame - min_spec)/spec_range, axis=0)\n        fig, ax = plt.subplots(figsize=figsize)\n        ax.imshow(frame,
          cmap=colormap, extent=[0, frame_duration, min_freq/1000, max_freq/1000],
          \n                  aspect=\"auto\", vmin = 0, vmax = 1.0)\n\n        if
          bands is not None:\n            band_arr = np.flip(resize(np.expand_dims(bands,
          axis=1), (frame.shape[0], frame.shape[1])), axis=0)\n            ax.imshow(band_arr,
          extent=[0, frame_duration, min_freq/1000, max_freq/1000], aspect=\"auto\",
          vmin = 0, \n                      vmax = 1.0, alpha=0.5)\n\n        ax.tick_params(axis=''both'',
          which=''major'', labelsize=8)\n        ax.tick_params(axis=''both'', which=''minor'',
          labelsize=8)\n        mid = frame_duration/2.0\n        ax.axvline(x=mid,
          color=\"red\")\n        ax.set_ylabel(''F (kHz)'')\n        ax.set_xticks([])\n        ax.set_xticks([],
          minor=True)\n\n        if abs_start is not None:\n            time_text
          = (abs_start + datetime.timedelta(seconds=start+mid)).strftime(''%H:%M:%S.%f'').strip()[:-4]\n            ax.text(mid-0.3,
          -0.6, time_text)\n\n        buf = io.BytesIO()\n        fig.tight_layout()\n        fig.savefig(buf,
          dpi=dpi)\n        buf.seek(0)\n        im = Image.open(buf)\n        im.format
          = \"PNG\"\n        plt.close(fig)\n\n        return ImageClip(np.asarray(im),\n                         duration=step)\n\n    def
          remove_empty_folders(path_abs):\n        walk = list(os.walk(path_abs))\n        for
          path, _, _ in walk[::-1]:\n            if len(os.listdir(path)) == 0:\n                os.rmdir(path)            \n\n    def
          save_metadata_sc(product_type, product_spectrum, sc_config,\n                      path,
          cumulus, node, recorder, deployment, parent=\"Null\"):\n        if product_type
          == \"soundscape\":\n            product_name = \"Soundscape\"\n            file_path
          = os.path.join(path, \"hashed_soundscape.parquet\")\n            metadata_filename
          = os.path.join(path, \"soundscape_metadata.json\")\n        elif product_type
          == \"sequence\":\n            product_name = \"Soundscape sequential plot\"\n            file_path
          = os.path.join(path, \"soundscape_seq.png\")\n            metadata_filename
          = os.path.join(path, \"soundscape_seq_metadata.json\")\n        elif product_type
          == \"standard_deviation\":\n            product_name = \"Soundscape standard
          deviation plot\"\n            file_path = os.path.join(path, \"std_soundscape.png\")\n            metadata_filename
          = os.path.join(path, \"std_soundscape_metadata.json\")\n        elif product_type
          == \"mean\":\n            product_name = \"Soundscape mean plot\"\n            file_path
          = os.path.join(path, \"mean_soundscape.png\")\n            metadata_filename
          = os.path.join(path, \"mean_soundscape_metadata.json\")\n\n        if int(node.split(\"_\")[2])
          == 0:\n            node_category = \"Degradado\"\n        elif int(node.split(\"_\")[2])
          == 1:\n            node_category = \"Integro\"\n\n        metadata = {\n            \"product_parent\":
          parent,\n            \"product_name\": product_name,\n            \"product_configs\":
          sc_config,\n            \"product_path\": file_path,\n            \"product_spectrum\":
          product_spectrum,\n            \"CumulusName\": cumulus,\n            \"NodeCategoryIntegrity\":
          node_category,\n            \"NomenclatureNode\": node,\n            \"SerialNumber\":
          recorder,\n            \"DateDeployment\": deployment\n        }\n\n        with
          open(metadata_filename, ''w'', encoding=''utf-8'') as f:\n            json.dump(metadata,
          f, ensure_ascii=False, indent=4)\n\n    def save_metadata_spectrogram(audio_id,
          product_spectrum,\n                      path, cumulus, node, recorder,
          deployment, parent=\"Null\"):\n        # identifier is being used as audio_id
          in alfresco\n        product_name = \"Spectrogram\"\n        file_path =
          os.path.join(path, f\"{audio_id}.png\")\n        metadata_filename = os.path.join(path,
          f\"{audio_id}_spectrogram_metadata.json\")\n\n        if int(node.split(\"_\")[2])
          == 0:\n            node_category = \"Degradado\"\n        elif int(node.split(\"_\")[2])
          == 1:\n            node_category = \"Integro\"\n\n        metadata = {\n            \"product_parent\":
          parent,\n            \"product_name\": product_name,\n            \"product_path\":
          file_path,\n            \"product_spectrum\": product_spectrum,\n            \"CumulusName\":
          cumulus,\n            \"NodeCategoryIntegrity\": node_category,\n            \"NomenclatureNode\":
          node,\n            \"SerialNumber\": recorder,\n            \"DateDeployment\":
          deployment,\n            \"AudioID\": audio_id\n        }\n        with
          open(metadata_filename, ''w'', encoding=''utf-8'') as f:\n            json.dump(metadata,
          f, ensure_ascii=False, indent=4)\n\n        print(f\"{file_path} saved.\")\n        print(f\"{metadata_filename}
          saved.\")\n\n    def save_metadata_videoclip(audio_id, product_spectrum,
          path, cumulus, node, recorder, \n                                deployment,
          clip_start, clip_end, parent=\"Null\"):\n        # identifier is being used
          as audio_id in alfresco\n        product_name = \"spectrogram_video\"\n        file_path
          = os.path.join(path, f\"{audio_id}.mp4\")\n        metadata_filename = os.path.join(path,
          f\"{audio_id}_spectrogram_video_metadata.json\")\n\n        if int(node.split(\"_\")[2])
          == 0:\n            node_category = \"Degradado\"\n        elif int(node.split(\"_\")[2])
          == 1:\n            node_category = \"Integro\"\n\n        metadata = {\n            \"product_parent\":
          parent,\n            \"product_name\": product_name,\n            \"product_description\":
          \"Spectrogram Video. Time is show in local timezone\",\n            \"product_path\":
          file_path,\n            \"product_spectrum\": product_spectrum,\n            \"CumulusName\":
          cumulus,\n            \"NodeCategoryIntegrity\": node_category,\n            \"NomenclatureNode\":
          node,\n            \"SerialNumber\": recorder,\n            \"DateDeployment\":
          deployment,\n            \"ClipStart\": clip_start,\n            \"ClipEnd\":
          clip_end,\n            \"AudioID\": audio_id\n        }\n\n        with
          open(metadata_filename, ''w'', encoding=''utf-8'') as f:\n            json.dump(metadata,
          f, ensure_ascii=False, indent=4)\n\n        print(f\"{file_path} saved.\")\n        print(f\"{metadata_filename}
          saved.\")\n\n    def upload(session, node_id, data, file):\n        \"\"\"\n        Uploads
          a file to a specific folder.\n        Parameters:\n            session (Session):          A
          session object to make\n                                        requests
          to alfresco.\n            node_id (string):           Node id to which the
          file is going to be created\n            data (dict):                Dict
          that contains file options\n            file (object):              File
          to upload\n\n        Returns:\n            (list):     A list containing
          status code and status data\n        \"\"\"\n\n        try:\n            response
          = session.post(os.getenv(\"ALFRESCO_URL\")\n                        + BASE_ENDPOINT
          + \"/nodes/\" + node_id + \"/children\",\n                        data =
          data,\n                        files = file\n                        )\n\n            return
          [response.json(), response.status_code];\n        except Exception as e:
          \n            print(\"File \" + data[\"name\"] + \" could not be uploaded:
          \", e)\n\n    def upload_files(file_patterns, session, node_id, dir_path,
          recursive, file_identifier=\"\"):\n        \"\"\"\n        Uploads the files
          stored in a specific dir\n        to alfresco\n        Parameters:\n            session
          (Session):          A session object to make\n                                        requests
          to alfresco.\n            node_id (string):           Node id to which the
          file is going to be created\n            dir_path (string):          The
          name and path of the dir where files are stored\n            recursive (boolean):        A
          boolean to know if upload  must be recursive\n                                        in
          the specifed dir, and should preserve the\n                                        structure
          of dirs inside.\n            file_identifier (string):   File identifier
          for all files inside a dir\n        Returns:\n            (string):           Returns
          the info of recent created site.\n        \"\"\"\n\n        if recursive:\n            expression
          = \"/**/*\"\n        else:\n            expression = \"/*\"\n\n        files_in_dir
          = list(\n            itertools.chain.from_iterable(\n                glob.iglob(dir_path
          + expression + pattern, recursive=recursive)\n                for pattern
          in file_patterns\n            )\n        )\n        filename = \"logs/upload_log\"
          + dir_path.replace(''/'',''-'') + ''.txt''\n\n        os.makedirs(os.path.dirname(filename),
          exist_ok=True)\n\n        total_files = len(files_in_dir)\n        starttime
          = time.time()\n\n        try:\n            files_uploaded = []\n            for
          idx, file_with_path in enumerate(files_in_dir):\n\n                # total
          time since last login or script start\n                total_time = round((time.time()
          - starttime), 2)\n\n                if total_time > 2400:\n                    \"\"\"\n                    if
          total time is bigger than 2400\n                    or 40 minutes relogin
          to avoid ticket\n                    expiration\n                    \"\"\"\n                    time.sleep(5)\n\n                    print(\"Re-logging
          in to alfresco...\")\n\n                    session = login.login()\n                    #
          restart time\n                    starttime = time.time()\n                    time.sleep(5)\n                    print(\"Login
          sucessful, continuing upload\\\\n\")\n\n                len_of_path = len(file_with_path.split(\"/\"))\n                name_of_file
          = file_with_path.split(\"/\")[len_of_path - 1]\n                root_dir_path
          = file_with_path.replace(dir_path, \"\").replace(\n                    file_with_path.split(\"/\")[len_of_path
          - 1], \"\"\n                )\n\n                data = {\n                    \"name\":
          (\n                        name_of_file[0 : len(name_of_file) - 4]\n                        +
          file_identifier\n                        + name_of_file[len(name_of_file)
          - 4 : len(name_of_file)]\n                    ),\n                    \"nodeType\":
          \"cm:content\",\n                }\n\n                data[\"relativePath\"]
          = root_dir_path\n\n                data[\"properties\"] = {\n                    \"cm:title\":
          (\n                        name_of_file[0 : len(name_of_file) - 4]\n                        +
          file_identifier\n                        + name_of_file[len(name_of_file)
          - 4 : len(name_of_file)]\n                    )\n                }\n\n                print(\"Uploading
          \" + data[\"name\"] + \" file...\")\n\n                files = {\"filedata\":
          open(file_with_path, \"rb\")}\n                upload_response = upload(session,
          node_id, data, files)\n                if upload_response[1] and upload_response[1]
          == 201:\n                    files_uploaded.append(upload_response[0])\n                    print(\"Uploaded
          \" + data[\"name\"])\n\n                    filename = \"logs/upload_log\"
          + dir_path.replace(''/'',''-'') + ''.txt''\n                    with open(filename,
          ''a'') as log_file:\n                        log_file.writelines(\"%s\\\\n\"
          % file_with_path)\n\n                elif upload_response[1] and upload_response[1]
          == 409:\n                    if \"already exists\" in upload_response[0][\"error\"][\"errorKey\"]:\n                        print(\"File
          \" + data[\"name\"] + \" already uploaded\")\n\n                else:\n                    print(\"An
          error ocurred, file \" + data[\"name\"] + \" cannot be uploaded\")\n\n                print(\"Uploaded
          file \" + str(idx + 1) + \" of \" + str(total_files))\n                print(\"\\\\n\\\\n\")\n\n            return
          files_uploaded\n        except Exception as e:\n            print(\"An error
          ocurred in file upload: \", e)\n\n    def vectorize_soundscape(df, hash_name,
          indices):\n        \\''\\''\\''Return dataframe with array column containing
          indices by frequency\\''\\''\\''\n        return (df\n                .groupby(by=[\"id\",
          hash_name, \"start_time\", \"end_time\"])\n                .apply(get_vectors,
          indices)\n                .reset_index()\n                .rename(columns={0:\"index_vector\"}))\n    ''''''\n\n    _kale_block3
          = ''''''\n    # hasher config \n    hasher_config = {''module'': {''object_name'':
          ''yuntu.soundscape.hashers.crono.CronoHasher''},\n                     ''kwargs'':
          {''time_utc_column'': ''abs_start_time''}}\n\n    hasher_config[\"kwargs\"][\"time_unit\"]
          = HASHER_TIME_UNIT\n    hasher_config[\"kwargs\"][\"time_module\"] = HASHER_TIME_MODULE\n    hasher_config[\"kwargs\"][\"start_tzone\"]
          = \"America/Mexico_City\"\n    hasher_config[\"kwargs\"][\"start_time\"]
          = DEFAULT_HASHER_CONFIG[\"start_time\"]\n    hasher_config[\"kwargs\"][\"start_format\"]
          = DEFAULT_HASHER_CONFIG[\"start_format\"]\n    hasher_config[\"kwargs\"][\"aware_start\"]
          = None\n\n    # soundscape config \n    slice_config  = dict(CronoSoundscape()[\"slice_config\"].data)\n    slice_config[\"time_unit\"]
          = TIME_UNIT\n    slice_config[\"frequency_bins\"] = FREQUENCY_BINS\n    slice_config[\"frequency_limits\"]
          = (FREQUENCY_LIMITS_LB, FREQUENCY_LIMITS_UB)\n\n    # FED configuration
          [\"TOTAL\", \"CORE\", \"TAIL\", \"INFORMATION\", \"ICOMPLEXITY\", \"EXAG\"]\n    indices
          = CronoSoundscape()[\"indices\"].data + [ICOMPLEXITY()]  + [TAIL()]\n\n    #
          dask local cluster\n    n_workers = int(0.95 * multiprocessing .cpu_count())
          \n    cluster = LocalCluster(n_workers = n_workers, \n                           threads_per_worker
          = THREADS_PER_WORKER)\n    client = Client(cluster)\n    npartitions = len(client.ncores())\n\n    #
          FEED\n    FEED = {\n        \"slice_config\": slice_config,\n        \"indices\":
          indices,\n        \"hash_name\": HASH_NAME,\n        \"hasher_config\":
          hasher_config,\n        \"npartitions\": npartitions\n    }\n\n    # adjust
          for metadata\n    indexes_computed = [\"TOTAL\", \"CORE\", \"TAIL\", \"INFORMATION\",
          \"ICOMPLEXITY\", \"EXAG\"]\n    FEED_metadata = FEED.copy()\n    FEED_metadata[\"indices\"]
          = indexes_computed\n\n    plot_indices = [RED_IDX, GREEN_IDX, BLUE_IDX]
          # rgb order\n\n    # soundscape per unit (cumulus-node-recorder-deployment_date)\n    proc_units
          = recs.proc_unit.unique()\n\n    for proc_unit in proc_units:\n        try:
          \n            start_soundscape = time.monotonic()\n            node, recorder,
          deployment = proc_unit\n            print(f\"* Processing: Cumulus {CUMULO}
          | node {node} | recorder {recorder} | deployment date {deployment}\")\n            file_path
          = os.path.join(RESULTS_DIR, str(CUMULO), str(node), recorder, deployment)\n            parent_id
          = hashlib.md5(file_path.encode(''utf-8'')).hexdigest()\n            # soundscape
          = recs[recs.proc_unit == proc_unit].audio.get_soundscape(client=client,
          npartitions=n_workers, **soundscape_config)\n            soundscape_data
          = recs[recs.proc_unit == proc_unit]\n            pipeline = CronoSoundscape(name
          = \"soundscape\", work_dir = WORK_DIR_PIPELINE, recordings = soundscape_data)\n            soundscape
          = pipeline[\"hashed_soundscape\"].compute(client=client, feed=FEED)\n\n            #
          sequence\n            plot_soundscape(soundscape, \"sequence\", SPECTRUM,
          FEED_metadata, file_path,\n                            CUMULO, node, recorder,
          deployment, parent_id, plot_indices, MIN_FREQ_SC)    \n            # mean\n            plot_soundscape(soundscape,
          \"mean\", SPECTRUM, FEED_metadata, file_path, \n                            CUMULO,
          node, recorder, deployment, parent_id, plot_indices, MIN_FREQ_SC)\n\n            #
          standard deviation\n            plot_soundscape(soundscape, \"standard_deviation\",
          SPECTRUM, FEED_metadata, file_path, \n                            CUMULO,
          node, recorder, deployment, parent_id, plot_indices, MIN_FREQ_SC)\n\n            #
          save soundscape vector\n            soundscape_path = os.path.join(file_path,
          \"hashed_soundscape.parquet\")\n            # soundscape_orig_path = os.path.join(RESULTS_DIR,
          \"get_soundscape/persist/hashed_soundscape.parquet\") \n            soundscape_orig_path
          = ''/shared_volume/audio/soundscape/persist/hashed_soundscape.parquet''\n            shutil.move(soundscape_orig_path,soundscape_path)\n            save_metadata_sc(\"soundscape\",
          SPECTRUM, FEED_metadata, file_path,\n                          CUMULO, node,
          recorder, deployment)\n            shutil.rmtree(''/shared_volume/audio/soundscape'')\n\n        except:\n            pass\n        #
          restart client\n        client.restart()\n\n    client.close()\n    cluster.close()\n\n    #
          remove empty subdirectories\n    remove_empty_folders(RESULTS_DIR)\n    ''''''\n\n    _kale_data_saving_block
          = ''''''\n    # -----------------------DATA SAVING START---------------------------------\n    from
          kale import marshal as _kale_marshal\n    _kale_marshal.set_data_dir(\"/shared_volume/audio/.sndscs_spec_specvid-sipecam-cumulus-node-recorder-deployment-aws.ipynb.kale.marshal.dir\")\n    _kale_marshal.save(recs,
          \"recs\")\n    # -----------------------DATA SAVING END-----------------------------------\n    ''''''\n\n    #
          run the code blocks inside a jupyter kernel\n    from kale.common.jputils
          import run_code as _kale_run_code\n    from kale.common.kfputils import
          \\\n        update_uimetadata as _kale_update_uimetadata\n    _kale_blocks
          = (_kale_pipeline_parameters_block, _kale_data_loading_block,\n                    _kale_block1,\n                    _kale_block2,\n                    _kale_block3,\n                    _kale_data_saving_block)\n    _kale_html_artifact
          = _kale_run_code(_kale_blocks)\n    with open(\"/compute_soundscapes.html\",
          \"w\") as f:\n        f.write(_kale_html_artifact)\n    _kale_update_uimetadata(''compute_soundscapes'')\n\n    _kale_mlmdutils.call(\"mark_execution_complete\")\n\nimport
          argparse\n_parser = argparse.ArgumentParser(prog=''Compute soundscapes'',
          description='''')\n_parser.add_argument(\"--AUTH-ENDPOINT\", dest=\"AUTH_ENDPOINT\",
          type=str, required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"--BASE-ENDPOINT\",
          dest=\"BASE_ENDPOINT\", type=str, required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"--BLUE-IDX\",
          dest=\"BLUE_IDX\", type=str, required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"--CUMULO\",
          dest=\"CUMULO\", type=int, required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"--FREQUENCY-BINS\",
          dest=\"FREQUENCY_BINS\", type=int, required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"--FREQUENCY-LIMITS-LB\",
          dest=\"FREQUENCY_LIMITS_LB\", type=int, required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"--FREQUENCY-LIMITS-UB\",
          dest=\"FREQUENCY_LIMITS_UB\", type=int, required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"--GREEN-IDX\",
          dest=\"GREEN_IDX\", type=str, required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"--HASHER-TIME-MODULE\",
          dest=\"HASHER_TIME_MODULE\", type=int, required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"--HASHER-TIME-UNIT\",
          dest=\"HASHER_TIME_UNIT\", type=int, required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"--HASH-NAME\",
          dest=\"HASH_NAME\", type=str, required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"--MIN-FREQ-SC\",
          dest=\"MIN_FREQ_SC\", type=int, required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"--RED-IDX\",
          dest=\"RED_IDX\", type=str, required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"--RESULTS-DIR\",
          dest=\"RESULTS_DIR\", type=str, required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"--SPECTRUM\",
          dest=\"SPECTRUM\", type=str, required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"--THREADS-PER-WORKER\",
          dest=\"THREADS_PER_WORKER\", type=int, required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"--TIME-UNIT\",
          dest=\"TIME_UNIT\", type=int, required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"--WORK-DIR-PIPELINE\",
          dest=\"WORK_DIR_PIPELINE\", type=str, required=True, default=argparse.SUPPRESS)\n_parsed_args
          = vars(_parser.parse_args())\n\n_outputs = compute_soundscapes(**_parsed_args)\n"],
          "image": "sipecam/audio-dgpi-kale-tensorflow-yuntu-dask-cert:0.6.1_dev"}},
          "inputs": [{"name": "AUTH_ENDPOINT", "type": "String"}, {"name": "BASE_ENDPOINT",
          "type": "String"}, {"name": "BLUE_IDX", "type": "String"}, {"name": "CUMULO",
          "type": "Integer"}, {"name": "FREQUENCY_BINS", "type": "Integer"}, {"name":
          "FREQUENCY_LIMITS_LB", "type": "Integer"}, {"name": "FREQUENCY_LIMITS_UB",
          "type": "Integer"}, {"name": "GREEN_IDX", "type": "String"}, {"name": "HASHER_TIME_MODULE",
          "type": "Integer"}, {"name": "HASHER_TIME_UNIT", "type": "Integer"}, {"name":
          "HASH_NAME", "type": "String"}, {"name": "MIN_FREQ_SC", "type": "Integer"},
          {"name": "RED_IDX", "type": "String"}, {"name": "RESULTS_DIR", "type": "String"},
          {"name": "SPECTRUM", "type": "String"}, {"name": "THREADS_PER_WORKER", "type":
          "Integer"}, {"name": "TIME_UNIT", "type": "Integer"}, {"name": "WORK_DIR_PIPELINE",
          "type": "String"}], "name": "Compute soundscapes"}', pipelines.kubeflow.org/component_ref: '{}',
        pipelines.kubeflow.org/arguments.parameters: '{"AUTH_ENDPOINT": "{{inputs.parameters.AUTH_ENDPOINT}}",
          "BASE_ENDPOINT": "{{inputs.parameters.BASE_ENDPOINT}}", "BLUE_IDX": "{{inputs.parameters.BLUE_IDX}}",
          "CUMULO": "{{inputs.parameters.CUMULO}}", "FREQUENCY_BINS": "{{inputs.parameters.FREQUENCY_BINS}}",
          "FREQUENCY_LIMITS_LB": "{{inputs.parameters.FREQUENCY_LIMITS_LB}}", "FREQUENCY_LIMITS_UB":
          "{{inputs.parameters.FREQUENCY_LIMITS_UB}}", "GREEN_IDX": "{{inputs.parameters.GREEN_IDX}}",
          "HASHER_TIME_MODULE": "{{inputs.parameters.HASHER_TIME_MODULE}}", "HASHER_TIME_UNIT":
          "{{inputs.parameters.HASHER_TIME_UNIT}}", "HASH_NAME": "{{inputs.parameters.HASH_NAME}}",
          "MIN_FREQ_SC": "{{inputs.parameters.MIN_FREQ_SC}}", "RED_IDX": "{{inputs.parameters.RED_IDX}}",
          "RESULTS_DIR": "{{inputs.parameters.RESULTS_DIR}}", "SPECTRUM": "{{inputs.parameters.SPECTRUM}}",
          "THREADS_PER_WORKER": "{{inputs.parameters.THREADS_PER_WORKER}}", "TIME_UNIT":
          "{{inputs.parameters.TIME_UNIT}}", "WORK_DIR_PIPELINE": "{{inputs.parameters.WORK_DIR_PIPELINE}}"}'}
      labels:
        pipelines.kubeflow.org/metadata_written: "true"
        pipelines.kubeflow.org/kfp_sdk_version: 1.8.11
        pipelines.kubeflow.org/pipeline-sdk-type: kfp
        pipelines.kubeflow.org/enable_caching: "true"
    volumes:
    - name: pvolume-ef6fe65091618f865041935b363277953274adf6b420fd4a7b8277d
      persistentVolumeClaim: {claimName: '{{inputs.parameters.vol_shared_volume}}'}
  - name: create-results-dirstruct
    container:
      args: [--AUTH-ENDPOINT, '{{inputs.parameters.AUTH_ENDPOINT}}', --BASE-ENDPOINT,
        '{{inputs.parameters.BASE_ENDPOINT}}', --CUMULO, '{{inputs.parameters.CUMULO}}',
        --RESULTS-DIR, '{{inputs.parameters.RESULTS_DIR}}']
      command:
      - sh
      - -ec
      - |
        program_path=$(mktemp)
        printf "%s" "$0" > "$program_path"
        python3 -u "$program_path" "$@"
      - "def create_results_dirstruct(AUTH_ENDPOINT, BASE_ENDPOINT, CUMULO, RESULTS_DIR):\n\
        \    _kale_pipeline_parameters_block = '''\n    AUTH_ENDPOINT = \"{}\"\n \
        \   BASE_ENDPOINT = \"{}\"\n    CUMULO = {}\n    RESULTS_DIR = \"{}\"\n  \
        \  '''.format(AUTH_ENDPOINT, BASE_ENDPOINT, CUMULO, RESULTS_DIR)\n\n    from\
        \ kale.common import mlmdutils as _kale_mlmdutils\n    _kale_mlmdutils.init_metadata()\n\
        \n    _kale_data_loading_block = '''\n    # -----------------------DATA LOADING\
        \ START--------------------------------\n    from kale import marshal as _kale_marshal\n\
        \    _kale_marshal.set_data_dir(\"/shared_volume/audio/.sndscs_spec_specvid-sipecam-cumulus-node-recorder-deployment-aws.ipynb.kale.marshal.dir\"\
        )\n    recs = _kale_marshal.load(\"recs\")\n    # -----------------------DATA\
        \ LOADING END----------------------------------\n    '''\n\n    _kale_block1\
        \ = '''\n    import base64\n    import datetime\n    import glob\n    import\
        \ hashlib\n    import io\n    import itertools\n    import json\n    import\
        \ matplotlib.pyplot as plt\n    import multiprocessing \n    import numpy\
        \ as np\n    import os\n    import pandas as pd\n    import psutil\n    import\
        \ requests\n    import shutil\n    import subprocess\n    import time\n  \
        \  import warnings\n\n    from dask.distributed import Client, LocalCluster\n\
        \    from datetime import timedelta\n    from dotenv import load_dotenv\n\
        \    from matplotlib import cm\n    from moviepy.editor import concatenate,\
        \ VideoFileClip, AudioFileClip\n    from moviepy.audio.AudioClip import AudioArrayClip\n\
        \    from moviepy.video.VideoClip import ImageClip\n    from os.path import\
        \ exists as file_exists\n    from PIL import Image\n    from skimage.transform\
        \ import resize\n\n    from yuntu import Audio\n    from yuntu.soundscape.utils\
        \ import aware_time\n    from yuntu.collection.methods import collection\n\
        \    from yuntu.soundscape.hashers.crono import DEFAULT_HASHER_CONFIG\n  \
        \  from yuntu.soundscape.processors.indices.direct import ICOMPLEXITY, TAIL\n\
        \    from yuntu.soundscape.pipelines.build_soundscape import CronoSoundscape,\
        \ HASHER_CONFIG\n    '''\n\n    _kale_block2 = '''\n    def audio2video(audio_id,\n\
        \                    audio_df,\n                    save_path_folder,\n  \
        \                  product_spectrum,\n                    cumulus,\n     \
        \               abs_start=None,\n                    fps=60,\n           \
        \         spec_configs={'hop_length': 512, 'n_fft': 1024, 'window_function':\
        \ 'hann'},\n                    rate=24,\n                    frame_duration=3.0,\n\
        \                    min_freq=0,\n                    max_freq=None,\n   \
        \                 cmap=\"Greys\",\n                    figsize=(5, 8),\n \
        \                   dpi=100,\n                    bands=None):\n        \\\
        '\\'\\'Takes and audio object and produces a mp4 video of the spectrogram\
        \ with audio\\'\\'\\'\n\n        sub_audio_df = audio_df[audio_df[\"id\"]==audio_id]\n\
        \        id_audio = sub_audio_df['id'].values[0]\n        node = sub_audio_df['node'].values[0]\n\
        \        recorder = sub_audio_df['recorder'].values[0]\n        deployment\
        \ = sub_audio_df['deployment'].values[0]\n        audio = sub_audio_df.audio[0]\n\
        \n        colormap = cm.get_cmap(cmap)\n        duration = audio.duration\n\
        \        step = 1/rate\n        start = -(frame_duration/2.0)\n        stop\
        \ = start + frame_duration\n        clips = []\n        last_stop = None\n\
        \n        if max_freq is None:\n            max_freq = audio.samplerate /\
        \ 2.0\n\n        if min_freq is None:\n            min_freq = 0\n\n      \
        \  with audio.features.db_spectrogram(**spec_configs) as spec:\n         \
        \   min_spec = np.amin(spec)\n            max_spec = np.amax(spec)\n     \
        \       spec_range = (max_spec-min_spec)\n\n            while stop <= duration+(frame_duration/2.0):\n\
        \                clip = produce_clip(spec, frame_duration, min_freq, max_freq,\
        \ start, stop, step, abs_start, colormap,\n                              \
        \      min_spec, spec_range, figsize, dpi, bands=bands)\n                clips.append(clip)\n\
        \n                if start + step + frame_duration > duration:\n         \
        \           last_stop = stop\n\n                start = start + step\n   \
        \             stop = start + frame_duration\n\n        video = concatenate(clips)\n\
        \        # edaudio = AudioArrayClip(audio_array, fps=audio.samplerate)\n \
        \       edaudio = AudioFileClip(audio.path).set_end(audio.duration)\n    \
        \    video = video.set_audio(edaudio)\n        file_path = os.path.join(save_path_folder,\
        \ f\"{audio_id}.mp4\")\n        video.write_videofile(file_path, fps=fps)\n\
        \n        save_metadata_videoclip(audio_id, product_spectrum,\n          \
        \            save_path_folder, cumulus, node, recorder, deployment, 0.0, audio.duration)\n\
        \        video.close()\n        edaudio.close()\n\n        for c in clips:\n\
        \            c.close()\n\n    def change_type_sipecam_sc(session, root_folder_id,\
        \ path, file_type, node_type):\n        if file_type == \"sequence.png\":\n\
        \            metadata_name = \"soundscape_seq_metadata.json\"\n          \
        \  aggr_type = \"None\"\n        elif file_type == \"mean_soundscape.png\"\
        :\n            metadata_name = \"mean_soundscape_metadata.json\"\n       \
        \     aggr_type = \"Mean\"\n        elif file_type ==  \"std_soundscape.png\"\
        :\n            metadata_name = \"std_soundscape_metadata.json\" \n       \
        \     aggr_type = \"Standard deviation\"\n        elif file_type == \"hashed_soundscape.parquet\"\
        :\n            metadata_name = \"soundscape_metadata.json\" \n           \
        \ aggr_type = \"None\"\n        elif \".png\" in file_type and (file_type\
        \ not in [\"sequence.png\", \"mean_soundscape.png\", \"std_soundscape.png\"\
        ]):\n            metadata_name = file_type.split(\".\")[0] + \"_spectrogram_metadata.json\"\
        \n            aggr_type = \"Null\"\n        elif \".mp4\" in file_type and\
        \ (file_type not in [\"sequence.png\", \"mean_soundscape.png\", \"std_soundscape.png\"\
        ]):\n            metadata_name = file_type.split(\".\")[0] + \"_spectrogram_video_metadata.json\"\
        \n            aggr_type = \"Null\"\n\n        try:\n            semi_path\
        \ = path.split(\"soundscapes/\")[-1]\n            semi_path_file = os.path.join(semi_path,\
        \ file_type)\n            local_path_file_metadata = os.path.join(path, metadata_name)\n\
        \            print(f\"Changing type for {os.path.join(semi_path)}\")\n   \
        \         alfresco_path = os.path.join(\"/Company Home/Sites/sipecam-soundscape/documentLibrary/\"\
        , semi_path)\n\n            response = session.get(\n                os.getenv(\"\
        ALFRESCO_URL\")\n                + BASE_ENDPOINT\n                + \"/nodes/\"\
        \n                + root_folder_id\n                + \"/children?relativePath=\"\
        +semi_path+\"&include=aspectNames&skipCount=0\"\n            )        \n \
        \           # if request is successful then continue\n            if response.status_code\
        \ == 200:\n\n                data_file = open(local_path_file_metadata)\n\
        \                data_json = json.load(data_file)\n                response_entries\
        \ = response.json()[\"list\"][\"entries\"]\n\n                for entry in\
        \ response_entries:\n                    if entry['entry']['name']==file_type\
        \ and entry['entry']['isFile']:\n                        prop_dict = {}\n\n\
        \                        if entry['entry']['name']==file_type:\n\n       \
        \                     if entry['entry']['name'] in [\"sequence.png\", \"mean_soundscape.png\"\
        , \"std_soundscape.png\"]:\n                                prop_dict[\"soundscape:CumulusName\"\
        ] = str(data_json[\"CumulusName\"])\n                                prop_dict[\"\
        soundscape:DateDeployment\"] = data_json[\"DateDeployment\"]\n           \
        \                     prop_dict[\"soundscape:NodeCategoryIntegrity\"] = str(data_json[\"\
        NodeCategoryIntegrity\"])\n                                prop_dict[\"soundscape:NomenclatureNode\"\
        ] = str(data_json[\"NomenclatureNode\"])\n                               \
        \ prop_dict[\"soundscape:SerialNumber\"] = str(data_json[\"SerialNumber\"\
        ])\n                                prop_dict[\"soundscape:aggr\"] = str(aggr_type)\n\
        \                                prop_dict[\"soundscape:cycle_config_aware_start\"\
        ] = str(data_json[\"product_configs\"]['hasher_config']['kwargs']['aware_start'])\n\
        \                                prop_dict[\"soundscape:cycle_config_start_format\"\
        ] = str(data_json[\"product_configs\"]['hasher_config']['kwargs']['start_format'])\n\
        \                                prop_dict[\"soundscape:cycle_config_start_time\"\
        ] =  datetime.datetime.strptime(data_json[\"product_configs\"]['hasher_config']['kwargs']['start_time'],\
        \ \n                                                                     \
        \                                   \"%Y-%m-%d %H:%M:%S\").strftime(\"%Y-%m-%dT%H:%M:%S.%f%z\"\
        )\n                                prop_dict[\"soundscape:cycle_config_start_tzone\"\
        ] = str(data_json[\"product_configs\"]['hasher_config']['kwargs']['start_tzone'])\n\
        \                                prop_dict[\"soundscape:cycle_config_time_module\"\
        ] = int(data_json[\"product_configs\"]['hasher_config']['kwargs']['time_module'])\n\
        \                                prop_dict[\"soundscape:cycle_config_time_unit\"\
        ] = str(data_json[\"product_configs\"]['hasher_config']['kwargs']['time_unit'])\n\
        \                                prop_dict[\"soundscape:cycle_config_time_utc_column\"\
        ] = str(data_json[\"product_configs\"]['hasher_config']['kwargs']['time_utc_column'])\n\
        \                                prop_dict[\"soundscape:frequency_bins\"]\
        \ = int(data_json[\"product_configs\"][\"slice_config\"][\"frequency_bins\"\
        ])\n                                prop_dict[\"soundscape:frequency_hop\"\
        ] = int(data_json[\"product_configs\"][\"slice_config\"][\"frequency_hop\"\
        ])\n                                prop_dict[\"soundscape:frequency_limits\"\
        ] = str(data_json[\"product_configs\"][\"slice_config\"][\"frequency_limits\"\
        ])\n                                prop_dict[\"soundscape:hash_name\"] =\
        \ str(data_json[\"product_configs\"][\"hash_name\"])\n                   \
        \             prop_dict[\"soundscape:hop_length\"] = int(data_json[\"product_configs\"\
        ][\"slice_config\"][\"feature_config\"][\"hop_length\"])\n               \
        \                 prop_dict[\"soundscape:indices\"] =  \", \".join(map(str,\
        \ data_json['product_configs']['indices']))\n                            \
        \    prop_dict[\"soundscape:n_fft\"] = int(data_json[\"product_configs\"][\"\
        slice_config\"][\"feature_config\"][\"n_fft\"])\n                        \
        \        prop_dict[\"soundscape:npartitions\"] = int(data_json[\"product_configs\"\
        ]['npartitions'])\n                                prop_dict[\"soundscape:product_name\"\
        ] = str(data_json[\"product_name\"])\n                                prop_dict[\"\
        soundscape:product_parent\"] = str(data_json[\"product_parent\"])\n      \
        \                          prop_dict[\"soundscape:product_path\"] = str(alfresco_path)\n\
        \                                prop_dict[\"soundscape:product_spectrum\"\
        ] = str(data_json[\"product_spectrum\"])\n                               \
        \ prop_dict[\"soundscape:slice_config_feature_type\"] = str(data_json[\"product_configs\"\
        ][\"slice_config\"][\"feature_type\"])\n                                prop_dict[\"\
        soundscape:slice_config_frequency_bins\"] = int(data_json[\"product_configs\"\
        ][\"slice_config\"][\"frequency_bins\"])\n                               \
        \ prop_dict[\"soundscape:slice_config_time_unit\"] = int(data_json[\"product_configs\"\
        ][\"slice_config\"][\"time_unit\"])\n                                prop_dict[\"\
        soundscape:time_hop\"] = int(data_json[\"product_configs\"][\"slice_config\"\
        ][\"time_hop\"])\n                                prop_dict[\"soundscape:window_function\"\
        ] = str(data_json[\"product_configs\"][\"slice_config\"][\"feature_config\"\
        ][\"window_function\"])  \n\n                            elif (\"spectrogram\"\
        \ or \"video\") in entry['entry']['name']:\n                             \
        \   prop_dict[\"soundscape:product_name\"] = str(data_json[\"product_name\"\
        ])\n                                prop_dict[\"soundscape:product_parent\"\
        ] = str(data_json[\"product_parent\"])\n                                prop_dict[\"\
        soundscape:product_path\"] = str(alfresco_path)\n                        \
        \        prop_dict[\"soundscape:product_spectrum\"] = str(data_json[\"product_spectrum\"\
        ])\n                                prop_dict[\"soundscape:CumulusName\"]\
        \ = str(data_json[\"CumulusName\"])\n                                prop_dict[\"\
        soundscape:NodeCategoryIntegrity\"] = str(data_json[\"NodeCategoryIntegrity\"\
        ])\n                                prop_dict[\"soundscape:NomenclatureNode\"\
        ] = str(data_json[\"NomenclatureNode\"])\n                               \
        \ prop_dict[\"soundscape:SerialNumber\"] = str(data_json[\"SerialNumber\"\
        ])\n                                prop_dict[\"soundscape:DateDeployment\"\
        ] = data_json[\"DateDeployment\"]\n                                prop_dict[\"\
        soundscape:AudioID\"] = data_json[\"AudioID\"]\n\n                       \
        \ aspects = entry['entry']['aspectNames']\n                        data =\
        \ {\"aspectNames\": aspects, \"nodeType\": node_type, \"properties\": prop_dict}\n\
        \                        # update properties request\n                   \
        \     update = session.put(\n                            os.getenv(\"ALFRESCO_URL\"\
        )\n                            + BASE_ENDPOINT\n                         \
        \   + \"/nodes/\"\n                            + entry['entry']['id'],\n \
        \                           data=json.dumps(data),\n                     \
        \   )\n\n                        if update.status_code == 200:\n         \
        \                   print(\"Updated \" + entry['entry']['id'])           \
        \         \n\n        except Exception as e:\n            print(\"Could not\
        \ add any aspect to this file: \", e)\n\n    def create_results_folder_str(results_dir,\
        \ cumulo, nodes_list, rec_list, dep_list): \n        # results directory\n\
        \        os.makedirs(results_dir, exist_ok=True)\n        # cumulus subdir\n\
        \        cum_subdir = os.path.join(results_dir, str(cumulo))\n        os.makedirs(cum_subdir,\
        \ exist_ok=True)\n        # node subdirs\n        for node in nodes_list:\n\
        \            node_subdir = os.path.join(cum_subdir, node)\n            os.makedirs(node_subdir,\
        \ exist_ok=True)\n            # recorder subdirs\n            for rec in rec_list:\n\
        \                rec_subdir = os.path.join(node_subdir, rec)\n           \
        \     os.makedirs(rec_subdir, exist_ok=True)\n                # deployment\
        \ subdirs\n                for dep in dep_list:\n                    dep_subdir\
        \ = os.path.join(rec_subdir, dep)\n                    os.makedirs(dep_subdir,\
        \ exist_ok=True)\n\n    def distance_to_mean(vector, mean):\n        \\'\\\
        '\\'Return euclidean distance to mean\\'\\'\\'\n        return np.sqrt(np.sum(np.square(mean\
        \ - vector)))\n\n    def find_subfolders(path_abs):\n        subdir_list =\
        \ []\n        walk = list(os.walk(path_abs))\n        for path, _, _ in walk[::-1]:\n\
        \            len_path = path.split(\"/\")\n            if len(len_path) ==\
        \ 8:\n                subdir_list.append(path)  \n\n        return subdir_list\n\
        \n    def get_audio_ids(soundscape_path, indices, nsamples):\n        df =\
        \ pd.read_parquet(os.path.join(soundscape_path, \"hashed_soundscape.parquet\"\
        ))\n\n        df[\"time_raw_hour\"] = df[\"time_raw\"].apply(lambda x: datetime.datetime.strptime(x,'%H:%M:%S\
        \ %d/%m/%Y (%z)').strftime(\"%H\"))\n        hours_list = list(df.time_raw_hour.unique())\n\
        \        hours_list.sort(key = int)\n\n        with open(os.path.join(soundscape_path,\
        \ \"soundscape_metadata.json\")) as f:\n            metadata = json.load(f)\n\
        \            f.close()\n\n        # indices = metadata[\"product_configs\"\
        ][\"indices\"]\n        # indices = [\"EXAG\", \"ICOMPLEXITY\", \"CORE\"]\n\
        \        hash_name = metadata[\"product_configs\"][\"hash_name\"]\n      \
        \  cycle_config = metadata[\"product_configs\"][\"hasher_config\"][\"kwargs\"\
        ]\n        time_unit = cycle_config[\"time_unit\"]\n        zero_t = aware_time(cycle_config[\"\
        start_time\"], cycle_config[\"start_tzone\"], cycle_config[\"start_format\"\
        ]) \n\n        # iterate over hours\n        audio_id_list = []\n        for\
        \ hour in hours_list:\n            subdf = df.query(f\"time_raw_hour == '{hour}'\"\
        )\n            # sample\n            samples_df = get_recording_samples(subdf,\
        \ hash_name, indices, time_unit, zero_t, nsamples=3)\n            unique_crono_hash_list\
        \ = list(samples_df.crono_hash_30m.unique())\n            sub_df = samples_df[samples_df.crono_hash_30m\
        \ == min(unique_crono_hash_list)]\n            audio_id_list += list(sub_df.id.tolist())\n\
        \n        return audio_id_list\n\n    def get_recording_samples(df, hash_name,\
        \ indices, time_unit, zero_t, nsamples=5):\n        \\'\\'\\'Return dataframe\
        \ of 'nsamples' samples for each tag in 'hash_name' column that are closest\
        \ to the mean vector by tag\\'\\'\\'\n        proj_df = df[(df.max_freq <=\
        \ 10000)]\n        crono_tags = proj_df.crono_hash_30m.unique()\n        proj_df.loc[:\
        \ , f\"{hash_name}_time\"] = proj_df[hash_name].apply(lambda x: zero_t + datetime.timedelta(seconds=float(x*time_unit)))\n\
        \        vectors = vectorize_soundscape(proj_df, hash_name, indices)\n   \
        \     min_index_vector = np.amin(np.stack(list(vectors.index_vector.values)),\
        \ axis=(0,1))\n        max_index_vector = np.amax(np.stack(list(vectors.index_vector.values)),\
        \ axis=(0,1))\n        index_range = (max_index_vector - min_index_vector)\n\
        \        vectors.loc[:, \"normalized_index_vector\"] = vectors.index_vector.apply(lambda\
        \ x: (x-min_index_vector)/index_range)\n        all_samples = []\n\n     \
        \   for crono_tag in crono_tags:\n            unit_vectors = vectors[vectors[hash_name]\
        \ == crono_tag]\n            mean_unit_vector = unit_vectors.normalized_index_vector.mean()\n\
        \            unit_vectors.loc[:, \"distance\"] = unit_vectors.normalized_index_vector.apply(lambda\
        \ x: distance_to_mean(x, mean_unit_vector))\n            all_samples.append(unit_vectors.sort_values(by=\"\
        distance\").head(nsamples))\n        return pd.concat(all_samples)\n\n   \
        \ def get_vectors(group, indices):\n        \\'\\'\\'Return array of indices\
        \ by frequency\\'\\'\\'\n        return group.sort_values(by=\"max_freq\"\
        )[indices].values\n\n    def login():\n        \"\"\"\n        Tries a login\
        \ to alfresco api and returns a session\n        object with credentials \n\
        \        Returns: \n            session (Session):  A session object to make\
        \ \n                                requests to zendro.\n        \"\"\"\n\
        \        try:\n            auth = {\n                \"userId\": os.getenv(\"\
        ALFRESCO_USER\"),\n                \"password\": os.getenv(\"ALFRESCO_PASSWORD\"\
        ),\n            }\n\n            login = requests.post(os.getenv(\"ALFRESCO_URL\"\
        ) + AUTH_ENDPOINT + \"/tickets\",data=json.dumps(auth))\n\n            base64_login\
        \ = base64.b64encode(bytes(login.json()[\"entry\"][\"id\"], 'utf-8')).decode()\n\
        \n            # se crea un objeto de Session para hacer requests\n       \
        \     session = requests.Session()\n            # se establece bearer token\n\
        \            session.headers.update({'Authorization': 'Basic ' + base64_login})\n\
        \n            return session\n        except Exception as e:\n           \
        \ print(\"Login failed: \", e)\n\n    def plot_spectrogram(audio_id, audio_df,\
        \ save_path_folder, spectrum, cumulus):\n        sub_audio_df = audio_df[audio_df[\"\
        id\"]==audio_id]\n        node = sub_audio_df['node'].values[0]\n        recorder\
        \ = sub_audio_df['recorder'].values[0]\n        deployment = sub_audio_df['deployment'].values[0]\n\
        \        # plot\n        fig, ax = plt.subplots(2,1,figsize=(20,10), sharex=True)\n\
        \        sub_audio_df.audio[0].plot(ax=ax[0], color='grey')\n        sub_audio_df.audio[0].features.db_spectrogram().plot(ax=ax[1])\n\
        \        ax[0].set_ylabel('Amplitude')\n        ax[0].grid(False)\n      \
        \  ax[1].set_ylabel('F (KHz)')\n        ax[1].set_xlabel('Time (seconds)')\n\
        \        fig.text(0.75, 0.04, f\"Cumulus: {cumulus} - Node: {node} - Recorder:\
        \ {recorder}\", va='center')\n        plt.tight_layout()\n        if save_path_folder:\n\
        \            file_path = os.path.join(save_path_folder, f\"{audio_id}.png\"\
        )\n            fig.savefig(file_path)\n        plt.show()\n\n        save_metadata_spectrogram(audio_id,\
        \ spectrum, save_path_folder, \n                                  cumulus,\
        \ node, recorder, deployment, parent=\"Null\")\n\n    def plot_soundscape(soundscape,\
        \ product_type, product_spectrum, sc_config, path, \n                    \
        \    cumulus, node, recorder, deployment, parent, indices, min_freq=None,\n\
        \                      figsize=(20,15), plt_style='ggplot'):\n\n        if\
        \ min_freq:\n            soundscape = soundscape[soundscape['min_freq']<=min_freq]\n\
        \n        if product_type == \"sequence\":\n            file_path = os.path.join(path,\
        \ \"sequence.png\")\n            # product_id = hashlib.md5(file_path.encode('utf-8')).hexdigest()\n\
        \n            plt.style.use(plt_style)\n            fig, ax = plt.subplots(figsize=figsize)\n\
        \            soundscape.sndscape.plot_sequence(rgb=indices, time_format='%Y-%m\
        \ %H:%M', ax=ax)\n            plt.xticks(rotation = 90)\n            ax.grid(False)\n\
        \            plt.tight_layout()\n            plt.savefig(file_path) \n   \
        \         plt.show()\n            # save metadata\n            save_metadata_sc(product_type,\
        \ product_spectrum, sc_config,\n                      path, cumulus, node,\
        \ recorder, deployment, parent=parent)\n\n        elif product_type == \"\
        standard_deviation\":\n            file_path = os.path.join(path, \"std_soundscape.png\"\
        )\n            # product_id = hashlib.md5(file_path.encode('utf-8')).hexdigest()\n\
        \n            plt.style.use(plt_style)\n            fig, ax = plt.subplots(figsize=figsize)\n\
        \            soundscape.sndscape.plot_cycle(rgb=indices, aggr=\"std\", time_format='%H:%M',\
        \ \n                                           xticks=24, ax=ax)\n       \
        \     plt.xticks(rotation = 90)\n            ax.grid(False)\n            plt.tight_layout()\
        \ \n            plt.savefig(file_path)\n            plt.show()\n\n       \
        \     # save metadata\n            save_metadata_sc(product_type, product_spectrum,\
        \ sc_config,\n                      path, cumulus, node, recorder, deployment,\
        \ parent)     \n\n        elif product_type == \"mean\": \n            file_path\
        \ = os.path.join(path, \"mean_soundscape.png\")\n            # product_id\
        \ = hashlib.md5(file_path.encode('utf-8')).hexdigest()\n\n            plt.style.use(plt_style)\n\
        \            fig, ax = plt.subplots(figsize=figsize)\n            soundscape.sndscape.plot_cycle(rgb=indices,\
        \ aggr=\"mean\", time_format='%H:%M', \n                                 \
        \          xticks=24, ax=ax)\n            plt.xticks(rotation = 90)\n    \
        \        ax.grid(False)\n            plt.tight_layout()\n            plt.savefig(file_path)\n\
        \            plt.show()\n\n            # save metadata\n            save_metadata_sc(product_type,\
        \ product_spectrum, sc_config,\n                      path, cumulus, node,\
        \ recorder, deployment, parent)    \n\n        print(f\"File saved at {file_path}\"\
        )\n\n    def produce_clip(spec, frame_duration, min_freq, max_freq, start,\
        \ stop, step, abs_start=None, \n                     colormap=cm.get_cmap(\"\
        Greys\"), min_spec=0, spec_range=1.0, figsize=(5, 4), \n                 \
        \    dpi=100, bands=None):\n        \\'\\'\\'Takes an individual frame and\
        \ produces an image with references\\'\\'\\'\n        frame = spec.cut_array(start_time=start,\
        \ end_time=stop, min_freq=min_freq, max_freq=max_freq, pad=True)\n       \
        \ plt.style.use('dark_background')\n        frame = np.flip((frame - min_spec)/spec_range,\
        \ axis=0)\n        fig, ax = plt.subplots(figsize=figsize)\n        ax.imshow(frame,\
        \ cmap=colormap, extent=[0, frame_duration, min_freq/1000, max_freq/1000],\
        \ \n                  aspect=\"auto\", vmin = 0, vmax = 1.0)\n\n        if\
        \ bands is not None:\n            band_arr = np.flip(resize(np.expand_dims(bands,\
        \ axis=1), (frame.shape[0], frame.shape[1])), axis=0)\n            ax.imshow(band_arr,\
        \ extent=[0, frame_duration, min_freq/1000, max_freq/1000], aspect=\"auto\"\
        , vmin = 0, \n                      vmax = 1.0, alpha=0.5)\n\n        ax.tick_params(axis='both',\
        \ which='major', labelsize=8)\n        ax.tick_params(axis='both', which='minor',\
        \ labelsize=8)\n        mid = frame_duration/2.0\n        ax.axvline(x=mid,\
        \ color=\"red\")\n        ax.set_ylabel('F (kHz)')\n        ax.set_xticks([])\n\
        \        ax.set_xticks([], minor=True)\n\n        if abs_start is not None:\n\
        \            time_text = (abs_start + datetime.timedelta(seconds=start+mid)).strftime('%H:%M:%S.%f').strip()[:-4]\n\
        \            ax.text(mid-0.3, -0.6, time_text)\n\n        buf = io.BytesIO()\n\
        \        fig.tight_layout()\n        fig.savefig(buf, dpi=dpi)\n        buf.seek(0)\n\
        \        im = Image.open(buf)\n        im.format = \"PNG\"\n        plt.close(fig)\n\
        \n        return ImageClip(np.asarray(im),\n                         duration=step)\n\
        \n    def remove_empty_folders(path_abs):\n        walk = list(os.walk(path_abs))\n\
        \        for path, _, _ in walk[::-1]:\n            if len(os.listdir(path))\
        \ == 0:\n                os.rmdir(path)            \n\n    def save_metadata_sc(product_type,\
        \ product_spectrum, sc_config,\n                      path, cumulus, node,\
        \ recorder, deployment, parent=\"Null\"):\n        if product_type == \"soundscape\"\
        :\n            product_name = \"Soundscape\"\n            file_path = os.path.join(path,\
        \ \"hashed_soundscape.parquet\")\n            metadata_filename = os.path.join(path,\
        \ \"soundscape_metadata.json\")\n        elif product_type == \"sequence\"\
        :\n            product_name = \"Soundscape sequential plot\"\n           \
        \ file_path = os.path.join(path, \"soundscape_seq.png\")\n            metadata_filename\
        \ = os.path.join(path, \"soundscape_seq_metadata.json\")\n        elif product_type\
        \ == \"standard_deviation\":\n            product_name = \"Soundscape standard\
        \ deviation plot\"\n            file_path = os.path.join(path, \"std_soundscape.png\"\
        )\n            metadata_filename = os.path.join(path, \"std_soundscape_metadata.json\"\
        )\n        elif product_type == \"mean\":\n            product_name = \"Soundscape\
        \ mean plot\"\n            file_path = os.path.join(path, \"mean_soundscape.png\"\
        )\n            metadata_filename = os.path.join(path, \"mean_soundscape_metadata.json\"\
        )\n\n        if int(node.split(\"_\")[2]) == 0:\n            node_category\
        \ = \"Degradado\"\n        elif int(node.split(\"_\")[2]) == 1:\n        \
        \    node_category = \"Integro\"\n\n        metadata = {\n            \"product_parent\"\
        : parent,\n            \"product_name\": product_name,\n            \"product_configs\"\
        : sc_config,\n            \"product_path\": file_path,\n            \"product_spectrum\"\
        : product_spectrum,\n            \"CumulusName\": cumulus,\n            \"\
        NodeCategoryIntegrity\": node_category,\n            \"NomenclatureNode\"\
        : node,\n            \"SerialNumber\": recorder,\n            \"DateDeployment\"\
        : deployment\n        }\n\n        with open(metadata_filename, 'w', encoding='utf-8')\
        \ as f:\n            json.dump(metadata, f, ensure_ascii=False, indent=4)\n\
        \n    def save_metadata_spectrogram(audio_id, product_spectrum,\n        \
        \              path, cumulus, node, recorder, deployment, parent=\"Null\"\
        ):\n        # identifier is being used as audio_id in alfresco\n        product_name\
        \ = \"Spectrogram\"\n        file_path = os.path.join(path, f\"{audio_id}.png\"\
        )\n        metadata_filename = os.path.join(path, f\"{audio_id}_spectrogram_metadata.json\"\
        )\n\n        if int(node.split(\"_\")[2]) == 0:\n            node_category\
        \ = \"Degradado\"\n        elif int(node.split(\"_\")[2]) == 1:\n        \
        \    node_category = \"Integro\"\n\n        metadata = {\n            \"product_parent\"\
        : parent,\n            \"product_name\": product_name,\n            \"product_path\"\
        : file_path,\n            \"product_spectrum\": product_spectrum,\n      \
        \      \"CumulusName\": cumulus,\n            \"NodeCategoryIntegrity\": node_category,\n\
        \            \"NomenclatureNode\": node,\n            \"SerialNumber\": recorder,\n\
        \            \"DateDeployment\": deployment,\n            \"AudioID\": audio_id\n\
        \        }\n        with open(metadata_filename, 'w', encoding='utf-8') as\
        \ f:\n            json.dump(metadata, f, ensure_ascii=False, indent=4)\n\n\
        \        print(f\"{file_path} saved.\")\n        print(f\"{metadata_filename}\
        \ saved.\")\n\n    def save_metadata_videoclip(audio_id, product_spectrum,\
        \ path, cumulus, node, recorder, \n                                deployment,\
        \ clip_start, clip_end, parent=\"Null\"):\n        # identifier is being used\
        \ as audio_id in alfresco\n        product_name = \"spectrogram_video\"\n\
        \        file_path = os.path.join(path, f\"{audio_id}.mp4\")\n        metadata_filename\
        \ = os.path.join(path, f\"{audio_id}_spectrogram_video_metadata.json\")\n\n\
        \        if int(node.split(\"_\")[2]) == 0:\n            node_category = \"\
        Degradado\"\n        elif int(node.split(\"_\")[2]) == 1:\n            node_category\
        \ = \"Integro\"\n\n        metadata = {\n            \"product_parent\": parent,\n\
        \            \"product_name\": product_name,\n            \"product_description\"\
        : \"Spectrogram Video. Time is show in local timezone\",\n            \"product_path\"\
        : file_path,\n            \"product_spectrum\": product_spectrum,\n      \
        \      \"CumulusName\": cumulus,\n            \"NodeCategoryIntegrity\": node_category,\n\
        \            \"NomenclatureNode\": node,\n            \"SerialNumber\": recorder,\n\
        \            \"DateDeployment\": deployment,\n            \"ClipStart\": clip_start,\n\
        \            \"ClipEnd\": clip_end,\n            \"AudioID\": audio_id\n \
        \       }\n\n        with open(metadata_filename, 'w', encoding='utf-8') as\
        \ f:\n            json.dump(metadata, f, ensure_ascii=False, indent=4)\n\n\
        \        print(f\"{file_path} saved.\")\n        print(f\"{metadata_filename}\
        \ saved.\")\n\n    def upload(session, node_id, data, file):\n        \"\"\
        \"\n        Uploads a file to a specific folder.\n        Parameters:\n  \
        \          session (Session):          A session object to make\n        \
        \                                requests to alfresco.\n            node_id\
        \ (string):           Node id to which the file is going to be created\n \
        \           data (dict):                Dict that contains file options\n\
        \            file (object):              File to upload\n\n        Returns:\n\
        \            (list):     A list containing status code and status data\n \
        \       \"\"\"\n\n        try:\n            response = session.post(os.getenv(\"\
        ALFRESCO_URL\")\n                        + BASE_ENDPOINT + \"/nodes/\" + node_id\
        \ + \"/children\",\n                        data = data,\n               \
        \         files = file\n                        )\n\n            return [response.json(),\
        \ response.status_code];\n        except Exception as e: \n            print(\"\
        File \" + data[\"name\"] + \" could not be uploaded: \", e)\n\n    def upload_files(file_patterns,\
        \ session, node_id, dir_path, recursive, file_identifier=\"\"):\n        \"\
        \"\"\n        Uploads the files stored in a specific dir\n        to alfresco\n\
        \        Parameters:\n            session (Session):          A session object\
        \ to make\n                                        requests to alfresco.\n\
        \            node_id (string):           Node id to which the file is going\
        \ to be created\n            dir_path (string):          The name and path\
        \ of the dir where files are stored\n            recursive (boolean):    \
        \    A boolean to know if upload  must be recursive\n                    \
        \                    in the specifed dir, and should preserve the\n      \
        \                                  structure of dirs inside.\n           \
        \ file_identifier (string):   File identifier for all files inside a dir\n\
        \        Returns:\n            (string):           Returns the info of recent\
        \ created site.\n        \"\"\"\n\n        if recursive:\n            expression\
        \ = \"/**/*\"\n        else:\n            expression = \"/*\"\n\n        files_in_dir\
        \ = list(\n            itertools.chain.from_iterable(\n                glob.iglob(dir_path\
        \ + expression + pattern, recursive=recursive)\n                for pattern\
        \ in file_patterns\n            )\n        )\n        filename = \"logs/upload_log\"\
        \ + dir_path.replace('/','-') + '.txt'\n\n        os.makedirs(os.path.dirname(filename),\
        \ exist_ok=True)\n\n        total_files = len(files_in_dir)\n        starttime\
        \ = time.time()\n\n        try:\n            files_uploaded = []\n       \
        \     for idx, file_with_path in enumerate(files_in_dir):\n\n            \
        \    # total time since last login or script start\n                total_time\
        \ = round((time.time() - starttime), 2)\n\n                if total_time >\
        \ 2400:\n                    \"\"\"\n                    if total time is\
        \ bigger than 2400\n                    or 40 minutes relogin to avoid ticket\n\
        \                    expiration\n                    \"\"\"\n            \
        \        time.sleep(5)\n\n                    print(\"Re-logging in to alfresco...\"\
        )\n\n                    session = login.login()\n                    # restart\
        \ time\n                    starttime = time.time()\n                    time.sleep(5)\n\
        \                    print(\"Login sucessful, continuing upload\\\\n\")\n\n\
        \                len_of_path = len(file_with_path.split(\"/\"))\n        \
        \        name_of_file = file_with_path.split(\"/\")[len_of_path - 1]\n   \
        \             root_dir_path = file_with_path.replace(dir_path, \"\").replace(\n\
        \                    file_with_path.split(\"/\")[len_of_path - 1], \"\"\n\
        \                )\n\n                data = {\n                    \"name\"\
        : (\n                        name_of_file[0 : len(name_of_file) - 4]\n   \
        \                     + file_identifier\n                        + name_of_file[len(name_of_file)\
        \ - 4 : len(name_of_file)]\n                    ),\n                    \"\
        nodeType\": \"cm:content\",\n                }\n\n                data[\"\
        relativePath\"] = root_dir_path\n\n                data[\"properties\"] =\
        \ {\n                    \"cm:title\": (\n                        name_of_file[0\
        \ : len(name_of_file) - 4]\n                        + file_identifier\n  \
        \                      + name_of_file[len(name_of_file) - 4 : len(name_of_file)]\n\
        \                    )\n                }\n\n                print(\"Uploading\
        \ \" + data[\"name\"] + \" file...\")\n\n                files = {\"filedata\"\
        : open(file_with_path, \"rb\")}\n                upload_response = upload(session,\
        \ node_id, data, files)\n                if upload_response[1] and upload_response[1]\
        \ == 201:\n                    files_uploaded.append(upload_response[0])\n\
        \                    print(\"Uploaded \" + data[\"name\"])\n\n           \
        \         filename = \"logs/upload_log\" + dir_path.replace('/','-') + '.txt'\n\
        \                    with open(filename, 'a') as log_file:\n             \
        \           log_file.writelines(\"%s\\\\n\" % file_with_path)\n\n        \
        \        elif upload_response[1] and upload_response[1] == 409:\n        \
        \            if \"already exists\" in upload_response[0][\"error\"][\"errorKey\"\
        ]:\n                        print(\"File \" + data[\"name\"] + \" already\
        \ uploaded\")\n\n                else:\n                    print(\"An error\
        \ ocurred, file \" + data[\"name\"] + \" cannot be uploaded\")\n\n       \
        \         print(\"Uploaded file \" + str(idx + 1) + \" of \" + str(total_files))\n\
        \                print(\"\\\\n\\\\n\")\n\n            return files_uploaded\n\
        \        except Exception as e:\n            print(\"An error ocurred in file\
        \ upload: \", e)\n\n    def vectorize_soundscape(df, hash_name, indices):\n\
        \        \\'\\'\\'Return dataframe with array column containing indices by\
        \ frequency\\'\\'\\'\n        return (df\n                .groupby(by=[\"\
        id\", hash_name, \"start_time\", \"end_time\"])\n                .apply(get_vectors,\
        \ indices)\n                .reset_index()\n                .rename(columns={0:\"\
        index_vector\"}))\n    '''\n\n    _kale_block3 = '''\n    # create results\
        \ folder structure\n    nodes_list = recs.node.unique()\n    recorders_list\
        \ = recs.recorder.unique()\n    deployments_list = recs.deployment.unique()\n\
        \    if os.path.isdir(RESULTS_DIR):\n        shutil.rmtree(RESULTS_DIR)\n\
        \    create_results_folder_str(RESULTS_DIR, CUMULO, nodes_list, recorders_list,\
        \ deployments_list)\n    '''\n\n    _kale_data_saving_block = '''\n    # -----------------------DATA\
        \ SAVING START---------------------------------\n    from kale import marshal\
        \ as _kale_marshal\n    _kale_marshal.set_data_dir(\"/shared_volume/audio/.sndscs_spec_specvid-sipecam-cumulus-node-recorder-deployment-aws.ipynb.kale.marshal.dir\"\
        )\n    _kale_marshal.save(recs, \"recs\")\n    # -----------------------DATA\
        \ SAVING END-----------------------------------\n    '''\n\n    # run the\
        \ code blocks inside a jupyter kernel\n    from kale.common.jputils import\
        \ run_code as _kale_run_code\n    from kale.common.kfputils import \\\n  \
        \      update_uimetadata as _kale_update_uimetadata\n    _kale_blocks = (_kale_pipeline_parameters_block,\
        \ _kale_data_loading_block,\n                    _kale_block1,\n         \
        \           _kale_block2,\n                    _kale_block3,\n           \
        \         _kale_data_saving_block)\n    _kale_html_artifact = _kale_run_code(_kale_blocks)\n\
        \    with open(\"/create_results_dirstruct.html\", \"w\") as f:\n        f.write(_kale_html_artifact)\n\
        \    _kale_update_uimetadata('create_results_dirstruct')\n\n    _kale_mlmdutils.call(\"\
        mark_execution_complete\")\n\nimport argparse\n_parser = argparse.ArgumentParser(prog='Create\
        \ results dirstruct', description='')\n_parser.add_argument(\"--AUTH-ENDPOINT\"\
        , dest=\"AUTH_ENDPOINT\", type=str, required=True, default=argparse.SUPPRESS)\n\
        _parser.add_argument(\"--BASE-ENDPOINT\", dest=\"BASE_ENDPOINT\", type=str,\
        \ required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"--CUMULO\"\
        , dest=\"CUMULO\", type=int, required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"\
        --RESULTS-DIR\", dest=\"RESULTS_DIR\", type=str, required=True, default=argparse.SUPPRESS)\n\
        _parsed_args = vars(_parser.parse_args())\n\n_outputs = create_results_dirstruct(**_parsed_args)\n"
      image: sipecam/audio-dgpi-kale-tensorflow-yuntu-dask-cert:0.6.1_dev
      securityContext: {runAsUser: 0}
      volumeMounts:
      - {mountPath: /shared_volume, name: pvolume-ef6fe65091618f865041935b363277953274adf6b420fd4a7b8277d}
      workingDir: //shared_volume/audio
    inputs:
      parameters:
      - {name: AUTH_ENDPOINT}
      - {name: BASE_ENDPOINT}
      - {name: CUMULO}
      - {name: RESULTS_DIR}
      - {name: vol_shared_volume}
    outputs:
      artifacts:
      - {name: mlpipeline-ui-metadata, path: /tmp/mlpipeline-ui-metadata.json}
      - {name: create_results_dirstruct, path: /create_results_dirstruct.html}
    metadata:
      annotations: {kubeflow-kale.org/dependent-templates: '["get-audio-df"]', pipelines.kubeflow.org/component_spec: '{"implementation":
          {"container": {"args": ["--AUTH-ENDPOINT", {"inputValue": "AUTH_ENDPOINT"},
          "--BASE-ENDPOINT", {"inputValue": "BASE_ENDPOINT"}, "--CUMULO", {"inputValue":
          "CUMULO"}, "--RESULTS-DIR", {"inputValue": "RESULTS_DIR"}], "command": ["sh",
          "-ec", "program_path=$(mktemp)\nprintf \"%s\" \"$0\" > \"$program_path\"\npython3
          -u \"$program_path\" \"$@\"\n", "def create_results_dirstruct(AUTH_ENDPOINT,
          BASE_ENDPOINT, CUMULO, RESULTS_DIR):\n    _kale_pipeline_parameters_block
          = ''''''\n    AUTH_ENDPOINT = \"{}\"\n    BASE_ENDPOINT = \"{}\"\n    CUMULO
          = {}\n    RESULTS_DIR = \"{}\"\n    ''''''.format(AUTH_ENDPOINT, BASE_ENDPOINT,
          CUMULO, RESULTS_DIR)\n\n    from kale.common import mlmdutils as _kale_mlmdutils\n    _kale_mlmdutils.init_metadata()\n\n    _kale_data_loading_block
          = ''''''\n    # -----------------------DATA LOADING START--------------------------------\n    from
          kale import marshal as _kale_marshal\n    _kale_marshal.set_data_dir(\"/shared_volume/audio/.sndscs_spec_specvid-sipecam-cumulus-node-recorder-deployment-aws.ipynb.kale.marshal.dir\")\n    recs
          = _kale_marshal.load(\"recs\")\n    # -----------------------DATA LOADING
          END----------------------------------\n    ''''''\n\n    _kale_block1 =
          ''''''\n    import base64\n    import datetime\n    import glob\n    import
          hashlib\n    import io\n    import itertools\n    import json\n    import
          matplotlib.pyplot as plt\n    import multiprocessing \n    import numpy
          as np\n    import os\n    import pandas as pd\n    import psutil\n    import
          requests\n    import shutil\n    import subprocess\n    import time\n    import
          warnings\n\n    from dask.distributed import Client, LocalCluster\n    from
          datetime import timedelta\n    from dotenv import load_dotenv\n    from
          matplotlib import cm\n    from moviepy.editor import concatenate, VideoFileClip,
          AudioFileClip\n    from moviepy.audio.AudioClip import AudioArrayClip\n    from
          moviepy.video.VideoClip import ImageClip\n    from os.path import exists
          as file_exists\n    from PIL import Image\n    from skimage.transform import
          resize\n\n    from yuntu import Audio\n    from yuntu.soundscape.utils import
          aware_time\n    from yuntu.collection.methods import collection\n    from
          yuntu.soundscape.hashers.crono import DEFAULT_HASHER_CONFIG\n    from yuntu.soundscape.processors.indices.direct
          import ICOMPLEXITY, TAIL\n    from yuntu.soundscape.pipelines.build_soundscape
          import CronoSoundscape, HASHER_CONFIG\n    ''''''\n\n    _kale_block2 =
          ''''''\n    def audio2video(audio_id,\n                    audio_df,\n                    save_path_folder,\n                    product_spectrum,\n                    cumulus,\n                    abs_start=None,\n                    fps=60,\n                    spec_configs={''hop_length'':
          512, ''n_fft'': 1024, ''window_function'': ''hann''},\n                    rate=24,\n                    frame_duration=3.0,\n                    min_freq=0,\n                    max_freq=None,\n                    cmap=\"Greys\",\n                    figsize=(5,
          8),\n                    dpi=100,\n                    bands=None):\n        \\''\\''\\''Takes
          and audio object and produces a mp4 video of the spectrogram with audio\\''\\''\\''\n\n        sub_audio_df
          = audio_df[audio_df[\"id\"]==audio_id]\n        id_audio = sub_audio_df[''id''].values[0]\n        node
          = sub_audio_df[''node''].values[0]\n        recorder = sub_audio_df[''recorder''].values[0]\n        deployment
          = sub_audio_df[''deployment''].values[0]\n        audio = sub_audio_df.audio[0]\n\n        colormap
          = cm.get_cmap(cmap)\n        duration = audio.duration\n        step = 1/rate\n        start
          = -(frame_duration/2.0)\n        stop = start + frame_duration\n        clips
          = []\n        last_stop = None\n\n        if max_freq is None:\n            max_freq
          = audio.samplerate / 2.0\n\n        if min_freq is None:\n            min_freq
          = 0\n\n        with audio.features.db_spectrogram(**spec_configs) as spec:\n            min_spec
          = np.amin(spec)\n            max_spec = np.amax(spec)\n            spec_range
          = (max_spec-min_spec)\n\n            while stop <= duration+(frame_duration/2.0):\n                clip
          = produce_clip(spec, frame_duration, min_freq, max_freq, start, stop, step,
          abs_start, colormap,\n                                    min_spec, spec_range,
          figsize, dpi, bands=bands)\n                clips.append(clip)\n\n                if
          start + step + frame_duration > duration:\n                    last_stop
          = stop\n\n                start = start + step\n                stop = start
          + frame_duration\n\n        video = concatenate(clips)\n        # edaudio
          = AudioArrayClip(audio_array, fps=audio.samplerate)\n        edaudio = AudioFileClip(audio.path).set_end(audio.duration)\n        video
          = video.set_audio(edaudio)\n        file_path = os.path.join(save_path_folder,
          f\"{audio_id}.mp4\")\n        video.write_videofile(file_path, fps=fps)\n\n        save_metadata_videoclip(audio_id,
          product_spectrum,\n                      save_path_folder, cumulus, node,
          recorder, deployment, 0.0, audio.duration)\n        video.close()\n        edaudio.close()\n\n        for
          c in clips:\n            c.close()\n\n    def change_type_sipecam_sc(session,
          root_folder_id, path, file_type, node_type):\n        if file_type == \"sequence.png\":\n            metadata_name
          = \"soundscape_seq_metadata.json\"\n            aggr_type = \"None\"\n        elif
          file_type == \"mean_soundscape.png\":\n            metadata_name = \"mean_soundscape_metadata.json\"\n            aggr_type
          = \"Mean\"\n        elif file_type ==  \"std_soundscape.png\":\n            metadata_name
          = \"std_soundscape_metadata.json\" \n            aggr_type = \"Standard
          deviation\"\n        elif file_type == \"hashed_soundscape.parquet\":\n            metadata_name
          = \"soundscape_metadata.json\" \n            aggr_type = \"None\"\n        elif
          \".png\" in file_type and (file_type not in [\"sequence.png\", \"mean_soundscape.png\",
          \"std_soundscape.png\"]):\n            metadata_name = file_type.split(\".\")[0]
          + \"_spectrogram_metadata.json\"\n            aggr_type = \"Null\"\n        elif
          \".mp4\" in file_type and (file_type not in [\"sequence.png\", \"mean_soundscape.png\",
          \"std_soundscape.png\"]):\n            metadata_name = file_type.split(\".\")[0]
          + \"_spectrogram_video_metadata.json\"\n            aggr_type = \"Null\"\n\n        try:\n            semi_path
          = path.split(\"soundscapes/\")[-1]\n            semi_path_file = os.path.join(semi_path,
          file_type)\n            local_path_file_metadata = os.path.join(path, metadata_name)\n            print(f\"Changing
          type for {os.path.join(semi_path)}\")\n            alfresco_path = os.path.join(\"/Company
          Home/Sites/sipecam-soundscape/documentLibrary/\", semi_path)\n\n            response
          = session.get(\n                os.getenv(\"ALFRESCO_URL\")\n                +
          BASE_ENDPOINT\n                + \"/nodes/\"\n                + root_folder_id\n                +
          \"/children?relativePath=\"+semi_path+\"&include=aspectNames&skipCount=0\"\n            )        \n            #
          if request is successful then continue\n            if response.status_code
          == 200:\n\n                data_file = open(local_path_file_metadata)\n                data_json
          = json.load(data_file)\n                response_entries = response.json()[\"list\"][\"entries\"]\n\n                for
          entry in response_entries:\n                    if entry[''entry''][''name'']==file_type
          and entry[''entry''][''isFile'']:\n                        prop_dict = {}\n\n                        if
          entry[''entry''][''name'']==file_type:\n\n                            if
          entry[''entry''][''name''] in [\"sequence.png\", \"mean_soundscape.png\",
          \"std_soundscape.png\"]:\n                                prop_dict[\"soundscape:CumulusName\"]
          = str(data_json[\"CumulusName\"])\n                                prop_dict[\"soundscape:DateDeployment\"]
          = data_json[\"DateDeployment\"]\n                                prop_dict[\"soundscape:NodeCategoryIntegrity\"]
          = str(data_json[\"NodeCategoryIntegrity\"])\n                                prop_dict[\"soundscape:NomenclatureNode\"]
          = str(data_json[\"NomenclatureNode\"])\n                                prop_dict[\"soundscape:SerialNumber\"]
          = str(data_json[\"SerialNumber\"])\n                                prop_dict[\"soundscape:aggr\"]
          = str(aggr_type)\n                                prop_dict[\"soundscape:cycle_config_aware_start\"]
          = str(data_json[\"product_configs\"][''hasher_config''][''kwargs''][''aware_start''])\n                                prop_dict[\"soundscape:cycle_config_start_format\"]
          = str(data_json[\"product_configs\"][''hasher_config''][''kwargs''][''start_format''])\n                                prop_dict[\"soundscape:cycle_config_start_time\"]
          =  datetime.datetime.strptime(data_json[\"product_configs\"][''hasher_config''][''kwargs''][''start_time''],
          \n                                                                                                        \"%Y-%m-%d
          %H:%M:%S\").strftime(\"%Y-%m-%dT%H:%M:%S.%f%z\")\n                                prop_dict[\"soundscape:cycle_config_start_tzone\"]
          = str(data_json[\"product_configs\"][''hasher_config''][''kwargs''][''start_tzone''])\n                                prop_dict[\"soundscape:cycle_config_time_module\"]
          = int(data_json[\"product_configs\"][''hasher_config''][''kwargs''][''time_module''])\n                                prop_dict[\"soundscape:cycle_config_time_unit\"]
          = str(data_json[\"product_configs\"][''hasher_config''][''kwargs''][''time_unit''])\n                                prop_dict[\"soundscape:cycle_config_time_utc_column\"]
          = str(data_json[\"product_configs\"][''hasher_config''][''kwargs''][''time_utc_column''])\n                                prop_dict[\"soundscape:frequency_bins\"]
          = int(data_json[\"product_configs\"][\"slice_config\"][\"frequency_bins\"])\n                                prop_dict[\"soundscape:frequency_hop\"]
          = int(data_json[\"product_configs\"][\"slice_config\"][\"frequency_hop\"])\n                                prop_dict[\"soundscape:frequency_limits\"]
          = str(data_json[\"product_configs\"][\"slice_config\"][\"frequency_limits\"])\n                                prop_dict[\"soundscape:hash_name\"]
          = str(data_json[\"product_configs\"][\"hash_name\"])\n                                prop_dict[\"soundscape:hop_length\"]
          = int(data_json[\"product_configs\"][\"slice_config\"][\"feature_config\"][\"hop_length\"])\n                                prop_dict[\"soundscape:indices\"]
          =  \", \".join(map(str, data_json[''product_configs''][''indices'']))\n                                prop_dict[\"soundscape:n_fft\"]
          = int(data_json[\"product_configs\"][\"slice_config\"][\"feature_config\"][\"n_fft\"])\n                                prop_dict[\"soundscape:npartitions\"]
          = int(data_json[\"product_configs\"][''npartitions''])\n                                prop_dict[\"soundscape:product_name\"]
          = str(data_json[\"product_name\"])\n                                prop_dict[\"soundscape:product_parent\"]
          = str(data_json[\"product_parent\"])\n                                prop_dict[\"soundscape:product_path\"]
          = str(alfresco_path)\n                                prop_dict[\"soundscape:product_spectrum\"]
          = str(data_json[\"product_spectrum\"])\n                                prop_dict[\"soundscape:slice_config_feature_type\"]
          = str(data_json[\"product_configs\"][\"slice_config\"][\"feature_type\"])\n                                prop_dict[\"soundscape:slice_config_frequency_bins\"]
          = int(data_json[\"product_configs\"][\"slice_config\"][\"frequency_bins\"])\n                                prop_dict[\"soundscape:slice_config_time_unit\"]
          = int(data_json[\"product_configs\"][\"slice_config\"][\"time_unit\"])\n                                prop_dict[\"soundscape:time_hop\"]
          = int(data_json[\"product_configs\"][\"slice_config\"][\"time_hop\"])\n                                prop_dict[\"soundscape:window_function\"]
          = str(data_json[\"product_configs\"][\"slice_config\"][\"feature_config\"][\"window_function\"])  \n\n                            elif
          (\"spectrogram\" or \"video\") in entry[''entry''][''name'']:\n                                prop_dict[\"soundscape:product_name\"]
          = str(data_json[\"product_name\"])\n                                prop_dict[\"soundscape:product_parent\"]
          = str(data_json[\"product_parent\"])\n                                prop_dict[\"soundscape:product_path\"]
          = str(alfresco_path)\n                                prop_dict[\"soundscape:product_spectrum\"]
          = str(data_json[\"product_spectrum\"])\n                                prop_dict[\"soundscape:CumulusName\"]
          = str(data_json[\"CumulusName\"])\n                                prop_dict[\"soundscape:NodeCategoryIntegrity\"]
          = str(data_json[\"NodeCategoryIntegrity\"])\n                                prop_dict[\"soundscape:NomenclatureNode\"]
          = str(data_json[\"NomenclatureNode\"])\n                                prop_dict[\"soundscape:SerialNumber\"]
          = str(data_json[\"SerialNumber\"])\n                                prop_dict[\"soundscape:DateDeployment\"]
          = data_json[\"DateDeployment\"]\n                                prop_dict[\"soundscape:AudioID\"]
          = data_json[\"AudioID\"]\n\n                        aspects = entry[''entry''][''aspectNames'']\n                        data
          = {\"aspectNames\": aspects, \"nodeType\": node_type, \"properties\": prop_dict}\n                        #
          update properties request\n                        update = session.put(\n                            os.getenv(\"ALFRESCO_URL\")\n                            +
          BASE_ENDPOINT\n                            + \"/nodes/\"\n                            +
          entry[''entry''][''id''],\n                            data=json.dumps(data),\n                        )\n\n                        if
          update.status_code == 200:\n                            print(\"Updated
          \" + entry[''entry''][''id''])                    \n\n        except Exception
          as e:\n            print(\"Could not add any aspect to this file: \", e)\n\n    def
          create_results_folder_str(results_dir, cumulo, nodes_list, rec_list, dep_list):
          \n        # results directory\n        os.makedirs(results_dir, exist_ok=True)\n        #
          cumulus subdir\n        cum_subdir = os.path.join(results_dir, str(cumulo))\n        os.makedirs(cum_subdir,
          exist_ok=True)\n        # node subdirs\n        for node in nodes_list:\n            node_subdir
          = os.path.join(cum_subdir, node)\n            os.makedirs(node_subdir, exist_ok=True)\n            #
          recorder subdirs\n            for rec in rec_list:\n                rec_subdir
          = os.path.join(node_subdir, rec)\n                os.makedirs(rec_subdir,
          exist_ok=True)\n                # deployment subdirs\n                for
          dep in dep_list:\n                    dep_subdir = os.path.join(rec_subdir,
          dep)\n                    os.makedirs(dep_subdir, exist_ok=True)\n\n    def
          distance_to_mean(vector, mean):\n        \\''\\''\\''Return euclidean distance
          to mean\\''\\''\\''\n        return np.sqrt(np.sum(np.square(mean - vector)))\n\n    def
          find_subfolders(path_abs):\n        subdir_list = []\n        walk = list(os.walk(path_abs))\n        for
          path, _, _ in walk[::-1]:\n            len_path = path.split(\"/\")\n            if
          len(len_path) == 8:\n                subdir_list.append(path)  \n\n        return
          subdir_list\n\n    def get_audio_ids(soundscape_path, indices, nsamples):\n        df
          = pd.read_parquet(os.path.join(soundscape_path, \"hashed_soundscape.parquet\"))\n\n        df[\"time_raw_hour\"]
          = df[\"time_raw\"].apply(lambda x: datetime.datetime.strptime(x,''%H:%M:%S
          %d/%m/%Y (%z)'').strftime(\"%H\"))\n        hours_list = list(df.time_raw_hour.unique())\n        hours_list.sort(key
          = int)\n\n        with open(os.path.join(soundscape_path, \"soundscape_metadata.json\"))
          as f:\n            metadata = json.load(f)\n            f.close()\n\n        #
          indices = metadata[\"product_configs\"][\"indices\"]\n        # indices
          = [\"EXAG\", \"ICOMPLEXITY\", \"CORE\"]\n        hash_name = metadata[\"product_configs\"][\"hash_name\"]\n        cycle_config
          = metadata[\"product_configs\"][\"hasher_config\"][\"kwargs\"]\n        time_unit
          = cycle_config[\"time_unit\"]\n        zero_t = aware_time(cycle_config[\"start_time\"],
          cycle_config[\"start_tzone\"], cycle_config[\"start_format\"]) \n\n        #
          iterate over hours\n        audio_id_list = []\n        for hour in hours_list:\n            subdf
          = df.query(f\"time_raw_hour == ''{hour}''\")\n            # sample\n            samples_df
          = get_recording_samples(subdf, hash_name, indices, time_unit, zero_t, nsamples=3)\n            unique_crono_hash_list
          = list(samples_df.crono_hash_30m.unique())\n            sub_df = samples_df[samples_df.crono_hash_30m
          == min(unique_crono_hash_list)]\n            audio_id_list += list(sub_df.id.tolist())\n\n        return
          audio_id_list\n\n    def get_recording_samples(df, hash_name, indices, time_unit,
          zero_t, nsamples=5):\n        \\''\\''\\''Return dataframe of ''nsamples''
          samples for each tag in ''hash_name'' column that are closest to the mean
          vector by tag\\''\\''\\''\n        proj_df = df[(df.max_freq <= 10000)]\n        crono_tags
          = proj_df.crono_hash_30m.unique()\n        proj_df.loc[: , f\"{hash_name}_time\"]
          = proj_df[hash_name].apply(lambda x: zero_t + datetime.timedelta(seconds=float(x*time_unit)))\n        vectors
          = vectorize_soundscape(proj_df, hash_name, indices)\n        min_index_vector
          = np.amin(np.stack(list(vectors.index_vector.values)), axis=(0,1))\n        max_index_vector
          = np.amax(np.stack(list(vectors.index_vector.values)), axis=(0,1))\n        index_range
          = (max_index_vector - min_index_vector)\n        vectors.loc[:, \"normalized_index_vector\"]
          = vectors.index_vector.apply(lambda x: (x-min_index_vector)/index_range)\n        all_samples
          = []\n\n        for crono_tag in crono_tags:\n            unit_vectors =
          vectors[vectors[hash_name] == crono_tag]\n            mean_unit_vector =
          unit_vectors.normalized_index_vector.mean()\n            unit_vectors.loc[:,
          \"distance\"] = unit_vectors.normalized_index_vector.apply(lambda x: distance_to_mean(x,
          mean_unit_vector))\n            all_samples.append(unit_vectors.sort_values(by=\"distance\").head(nsamples))\n        return
          pd.concat(all_samples)\n\n    def get_vectors(group, indices):\n        \\''\\''\\''Return
          array of indices by frequency\\''\\''\\''\n        return group.sort_values(by=\"max_freq\")[indices].values\n\n    def
          login():\n        \"\"\"\n        Tries a login to alfresco api and returns
          a session\n        object with credentials \n        Returns: \n            session
          (Session):  A session object to make \n                                requests
          to zendro.\n        \"\"\"\n        try:\n            auth = {\n                \"userId\":
          os.getenv(\"ALFRESCO_USER\"),\n                \"password\": os.getenv(\"ALFRESCO_PASSWORD\"),\n            }\n\n            login
          = requests.post(os.getenv(\"ALFRESCO_URL\") + AUTH_ENDPOINT + \"/tickets\",data=json.dumps(auth))\n\n            base64_login
          = base64.b64encode(bytes(login.json()[\"entry\"][\"id\"], ''utf-8'')).decode()\n\n            #
          se crea un objeto de Session para hacer requests\n            session =
          requests.Session()\n            # se establece bearer token\n            session.headers.update({''Authorization'':
          ''Basic '' + base64_login})\n\n            return session\n        except
          Exception as e:\n            print(\"Login failed: \", e)\n\n    def plot_spectrogram(audio_id,
          audio_df, save_path_folder, spectrum, cumulus):\n        sub_audio_df =
          audio_df[audio_df[\"id\"]==audio_id]\n        node = sub_audio_df[''node''].values[0]\n        recorder
          = sub_audio_df[''recorder''].values[0]\n        deployment = sub_audio_df[''deployment''].values[0]\n        #
          plot\n        fig, ax = plt.subplots(2,1,figsize=(20,10), sharex=True)\n        sub_audio_df.audio[0].plot(ax=ax[0],
          color=''grey'')\n        sub_audio_df.audio[0].features.db_spectrogram().plot(ax=ax[1])\n        ax[0].set_ylabel(''Amplitude'')\n        ax[0].grid(False)\n        ax[1].set_ylabel(''F
          (KHz)'')\n        ax[1].set_xlabel(''Time (seconds)'')\n        fig.text(0.75,
          0.04, f\"Cumulus: {cumulus} - Node: {node} - Recorder: {recorder}\", va=''center'')\n        plt.tight_layout()\n        if
          save_path_folder:\n            file_path = os.path.join(save_path_folder,
          f\"{audio_id}.png\")\n            fig.savefig(file_path)\n        plt.show()\n\n        save_metadata_spectrogram(audio_id,
          spectrum, save_path_folder, \n                                  cumulus,
          node, recorder, deployment, parent=\"Null\")\n\n    def plot_soundscape(soundscape,
          product_type, product_spectrum, sc_config, path, \n                        cumulus,
          node, recorder, deployment, parent, indices, min_freq=None,\n                      figsize=(20,15),
          plt_style=''ggplot''):\n\n        if min_freq:\n            soundscape =
          soundscape[soundscape[''min_freq'']<=min_freq]\n\n        if product_type
          == \"sequence\":\n            file_path = os.path.join(path, \"sequence.png\")\n            #
          product_id = hashlib.md5(file_path.encode(''utf-8'')).hexdigest()\n\n            plt.style.use(plt_style)\n            fig,
          ax = plt.subplots(figsize=figsize)\n            soundscape.sndscape.plot_sequence(rgb=indices,
          time_format=''%Y-%m %H:%M'', ax=ax)\n            plt.xticks(rotation = 90)\n            ax.grid(False)\n            plt.tight_layout()\n            plt.savefig(file_path)
          \n            plt.show()\n            # save metadata\n            save_metadata_sc(product_type,
          product_spectrum, sc_config,\n                      path, cumulus, node,
          recorder, deployment, parent=parent)\n\n        elif product_type == \"standard_deviation\":\n            file_path
          = os.path.join(path, \"std_soundscape.png\")\n            # product_id =
          hashlib.md5(file_path.encode(''utf-8'')).hexdigest()\n\n            plt.style.use(plt_style)\n            fig,
          ax = plt.subplots(figsize=figsize)\n            soundscape.sndscape.plot_cycle(rgb=indices,
          aggr=\"std\", time_format=''%H:%M'', \n                                           xticks=24,
          ax=ax)\n            plt.xticks(rotation = 90)\n            ax.grid(False)\n            plt.tight_layout()
          \n            plt.savefig(file_path)\n            plt.show()\n\n            #
          save metadata\n            save_metadata_sc(product_type, product_spectrum,
          sc_config,\n                      path, cumulus, node, recorder, deployment,
          parent)     \n\n        elif product_type == \"mean\": \n            file_path
          = os.path.join(path, \"mean_soundscape.png\")\n            # product_id
          = hashlib.md5(file_path.encode(''utf-8'')).hexdigest()\n\n            plt.style.use(plt_style)\n            fig,
          ax = plt.subplots(figsize=figsize)\n            soundscape.sndscape.plot_cycle(rgb=indices,
          aggr=\"mean\", time_format=''%H:%M'', \n                                           xticks=24,
          ax=ax)\n            plt.xticks(rotation = 90)\n            ax.grid(False)\n            plt.tight_layout()\n            plt.savefig(file_path)\n            plt.show()\n\n            #
          save metadata\n            save_metadata_sc(product_type, product_spectrum,
          sc_config,\n                      path, cumulus, node, recorder, deployment,
          parent)    \n\n        print(f\"File saved at {file_path}\")\n\n    def
          produce_clip(spec, frame_duration, min_freq, max_freq, start, stop, step,
          abs_start=None, \n                     colormap=cm.get_cmap(\"Greys\"),
          min_spec=0, spec_range=1.0, figsize=(5, 4), \n                     dpi=100,
          bands=None):\n        \\''\\''\\''Takes an individual frame and produces
          an image with references\\''\\''\\''\n        frame = spec.cut_array(start_time=start,
          end_time=stop, min_freq=min_freq, max_freq=max_freq, pad=True)\n        plt.style.use(''dark_background'')\n        frame
          = np.flip((frame - min_spec)/spec_range, axis=0)\n        fig, ax = plt.subplots(figsize=figsize)\n        ax.imshow(frame,
          cmap=colormap, extent=[0, frame_duration, min_freq/1000, max_freq/1000],
          \n                  aspect=\"auto\", vmin = 0, vmax = 1.0)\n\n        if
          bands is not None:\n            band_arr = np.flip(resize(np.expand_dims(bands,
          axis=1), (frame.shape[0], frame.shape[1])), axis=0)\n            ax.imshow(band_arr,
          extent=[0, frame_duration, min_freq/1000, max_freq/1000], aspect=\"auto\",
          vmin = 0, \n                      vmax = 1.0, alpha=0.5)\n\n        ax.tick_params(axis=''both'',
          which=''major'', labelsize=8)\n        ax.tick_params(axis=''both'', which=''minor'',
          labelsize=8)\n        mid = frame_duration/2.0\n        ax.axvline(x=mid,
          color=\"red\")\n        ax.set_ylabel(''F (kHz)'')\n        ax.set_xticks([])\n        ax.set_xticks([],
          minor=True)\n\n        if abs_start is not None:\n            time_text
          = (abs_start + datetime.timedelta(seconds=start+mid)).strftime(''%H:%M:%S.%f'').strip()[:-4]\n            ax.text(mid-0.3,
          -0.6, time_text)\n\n        buf = io.BytesIO()\n        fig.tight_layout()\n        fig.savefig(buf,
          dpi=dpi)\n        buf.seek(0)\n        im = Image.open(buf)\n        im.format
          = \"PNG\"\n        plt.close(fig)\n\n        return ImageClip(np.asarray(im),\n                         duration=step)\n\n    def
          remove_empty_folders(path_abs):\n        walk = list(os.walk(path_abs))\n        for
          path, _, _ in walk[::-1]:\n            if len(os.listdir(path)) == 0:\n                os.rmdir(path)            \n\n    def
          save_metadata_sc(product_type, product_spectrum, sc_config,\n                      path,
          cumulus, node, recorder, deployment, parent=\"Null\"):\n        if product_type
          == \"soundscape\":\n            product_name = \"Soundscape\"\n            file_path
          = os.path.join(path, \"hashed_soundscape.parquet\")\n            metadata_filename
          = os.path.join(path, \"soundscape_metadata.json\")\n        elif product_type
          == \"sequence\":\n            product_name = \"Soundscape sequential plot\"\n            file_path
          = os.path.join(path, \"soundscape_seq.png\")\n            metadata_filename
          = os.path.join(path, \"soundscape_seq_metadata.json\")\n        elif product_type
          == \"standard_deviation\":\n            product_name = \"Soundscape standard
          deviation plot\"\n            file_path = os.path.join(path, \"std_soundscape.png\")\n            metadata_filename
          = os.path.join(path, \"std_soundscape_metadata.json\")\n        elif product_type
          == \"mean\":\n            product_name = \"Soundscape mean plot\"\n            file_path
          = os.path.join(path, \"mean_soundscape.png\")\n            metadata_filename
          = os.path.join(path, \"mean_soundscape_metadata.json\")\n\n        if int(node.split(\"_\")[2])
          == 0:\n            node_category = \"Degradado\"\n        elif int(node.split(\"_\")[2])
          == 1:\n            node_category = \"Integro\"\n\n        metadata = {\n            \"product_parent\":
          parent,\n            \"product_name\": product_name,\n            \"product_configs\":
          sc_config,\n            \"product_path\": file_path,\n            \"product_spectrum\":
          product_spectrum,\n            \"CumulusName\": cumulus,\n            \"NodeCategoryIntegrity\":
          node_category,\n            \"NomenclatureNode\": node,\n            \"SerialNumber\":
          recorder,\n            \"DateDeployment\": deployment\n        }\n\n        with
          open(metadata_filename, ''w'', encoding=''utf-8'') as f:\n            json.dump(metadata,
          f, ensure_ascii=False, indent=4)\n\n    def save_metadata_spectrogram(audio_id,
          product_spectrum,\n                      path, cumulus, node, recorder,
          deployment, parent=\"Null\"):\n        # identifier is being used as audio_id
          in alfresco\n        product_name = \"Spectrogram\"\n        file_path =
          os.path.join(path, f\"{audio_id}.png\")\n        metadata_filename = os.path.join(path,
          f\"{audio_id}_spectrogram_metadata.json\")\n\n        if int(node.split(\"_\")[2])
          == 0:\n            node_category = \"Degradado\"\n        elif int(node.split(\"_\")[2])
          == 1:\n            node_category = \"Integro\"\n\n        metadata = {\n            \"product_parent\":
          parent,\n            \"product_name\": product_name,\n            \"product_path\":
          file_path,\n            \"product_spectrum\": product_spectrum,\n            \"CumulusName\":
          cumulus,\n            \"NodeCategoryIntegrity\": node_category,\n            \"NomenclatureNode\":
          node,\n            \"SerialNumber\": recorder,\n            \"DateDeployment\":
          deployment,\n            \"AudioID\": audio_id\n        }\n        with
          open(metadata_filename, ''w'', encoding=''utf-8'') as f:\n            json.dump(metadata,
          f, ensure_ascii=False, indent=4)\n\n        print(f\"{file_path} saved.\")\n        print(f\"{metadata_filename}
          saved.\")\n\n    def save_metadata_videoclip(audio_id, product_spectrum,
          path, cumulus, node, recorder, \n                                deployment,
          clip_start, clip_end, parent=\"Null\"):\n        # identifier is being used
          as audio_id in alfresco\n        product_name = \"spectrogram_video\"\n        file_path
          = os.path.join(path, f\"{audio_id}.mp4\")\n        metadata_filename = os.path.join(path,
          f\"{audio_id}_spectrogram_video_metadata.json\")\n\n        if int(node.split(\"_\")[2])
          == 0:\n            node_category = \"Degradado\"\n        elif int(node.split(\"_\")[2])
          == 1:\n            node_category = \"Integro\"\n\n        metadata = {\n            \"product_parent\":
          parent,\n            \"product_name\": product_name,\n            \"product_description\":
          \"Spectrogram Video. Time is show in local timezone\",\n            \"product_path\":
          file_path,\n            \"product_spectrum\": product_spectrum,\n            \"CumulusName\":
          cumulus,\n            \"NodeCategoryIntegrity\": node_category,\n            \"NomenclatureNode\":
          node,\n            \"SerialNumber\": recorder,\n            \"DateDeployment\":
          deployment,\n            \"ClipStart\": clip_start,\n            \"ClipEnd\":
          clip_end,\n            \"AudioID\": audio_id\n        }\n\n        with
          open(metadata_filename, ''w'', encoding=''utf-8'') as f:\n            json.dump(metadata,
          f, ensure_ascii=False, indent=4)\n\n        print(f\"{file_path} saved.\")\n        print(f\"{metadata_filename}
          saved.\")\n\n    def upload(session, node_id, data, file):\n        \"\"\"\n        Uploads
          a file to a specific folder.\n        Parameters:\n            session (Session):          A
          session object to make\n                                        requests
          to alfresco.\n            node_id (string):           Node id to which the
          file is going to be created\n            data (dict):                Dict
          that contains file options\n            file (object):              File
          to upload\n\n        Returns:\n            (list):     A list containing
          status code and status data\n        \"\"\"\n\n        try:\n            response
          = session.post(os.getenv(\"ALFRESCO_URL\")\n                        + BASE_ENDPOINT
          + \"/nodes/\" + node_id + \"/children\",\n                        data =
          data,\n                        files = file\n                        )\n\n            return
          [response.json(), response.status_code];\n        except Exception as e:
          \n            print(\"File \" + data[\"name\"] + \" could not be uploaded:
          \", e)\n\n    def upload_files(file_patterns, session, node_id, dir_path,
          recursive, file_identifier=\"\"):\n        \"\"\"\n        Uploads the files
          stored in a specific dir\n        to alfresco\n        Parameters:\n            session
          (Session):          A session object to make\n                                        requests
          to alfresco.\n            node_id (string):           Node id to which the
          file is going to be created\n            dir_path (string):          The
          name and path of the dir where files are stored\n            recursive (boolean):        A
          boolean to know if upload  must be recursive\n                                        in
          the specifed dir, and should preserve the\n                                        structure
          of dirs inside.\n            file_identifier (string):   File identifier
          for all files inside a dir\n        Returns:\n            (string):           Returns
          the info of recent created site.\n        \"\"\"\n\n        if recursive:\n            expression
          = \"/**/*\"\n        else:\n            expression = \"/*\"\n\n        files_in_dir
          = list(\n            itertools.chain.from_iterable(\n                glob.iglob(dir_path
          + expression + pattern, recursive=recursive)\n                for pattern
          in file_patterns\n            )\n        )\n        filename = \"logs/upload_log\"
          + dir_path.replace(''/'',''-'') + ''.txt''\n\n        os.makedirs(os.path.dirname(filename),
          exist_ok=True)\n\n        total_files = len(files_in_dir)\n        starttime
          = time.time()\n\n        try:\n            files_uploaded = []\n            for
          idx, file_with_path in enumerate(files_in_dir):\n\n                # total
          time since last login or script start\n                total_time = round((time.time()
          - starttime), 2)\n\n                if total_time > 2400:\n                    \"\"\"\n                    if
          total time is bigger than 2400\n                    or 40 minutes relogin
          to avoid ticket\n                    expiration\n                    \"\"\"\n                    time.sleep(5)\n\n                    print(\"Re-logging
          in to alfresco...\")\n\n                    session = login.login()\n                    #
          restart time\n                    starttime = time.time()\n                    time.sleep(5)\n                    print(\"Login
          sucessful, continuing upload\\\\n\")\n\n                len_of_path = len(file_with_path.split(\"/\"))\n                name_of_file
          = file_with_path.split(\"/\")[len_of_path - 1]\n                root_dir_path
          = file_with_path.replace(dir_path, \"\").replace(\n                    file_with_path.split(\"/\")[len_of_path
          - 1], \"\"\n                )\n\n                data = {\n                    \"name\":
          (\n                        name_of_file[0 : len(name_of_file) - 4]\n                        +
          file_identifier\n                        + name_of_file[len(name_of_file)
          - 4 : len(name_of_file)]\n                    ),\n                    \"nodeType\":
          \"cm:content\",\n                }\n\n                data[\"relativePath\"]
          = root_dir_path\n\n                data[\"properties\"] = {\n                    \"cm:title\":
          (\n                        name_of_file[0 : len(name_of_file) - 4]\n                        +
          file_identifier\n                        + name_of_file[len(name_of_file)
          - 4 : len(name_of_file)]\n                    )\n                }\n\n                print(\"Uploading
          \" + data[\"name\"] + \" file...\")\n\n                files = {\"filedata\":
          open(file_with_path, \"rb\")}\n                upload_response = upload(session,
          node_id, data, files)\n                if upload_response[1] and upload_response[1]
          == 201:\n                    files_uploaded.append(upload_response[0])\n                    print(\"Uploaded
          \" + data[\"name\"])\n\n                    filename = \"logs/upload_log\"
          + dir_path.replace(''/'',''-'') + ''.txt''\n                    with open(filename,
          ''a'') as log_file:\n                        log_file.writelines(\"%s\\\\n\"
          % file_with_path)\n\n                elif upload_response[1] and upload_response[1]
          == 409:\n                    if \"already exists\" in upload_response[0][\"error\"][\"errorKey\"]:\n                        print(\"File
          \" + data[\"name\"] + \" already uploaded\")\n\n                else:\n                    print(\"An
          error ocurred, file \" + data[\"name\"] + \" cannot be uploaded\")\n\n                print(\"Uploaded
          file \" + str(idx + 1) + \" of \" + str(total_files))\n                print(\"\\\\n\\\\n\")\n\n            return
          files_uploaded\n        except Exception as e:\n            print(\"An error
          ocurred in file upload: \", e)\n\n    def vectorize_soundscape(df, hash_name,
          indices):\n        \\''\\''\\''Return dataframe with array column containing
          indices by frequency\\''\\''\\''\n        return (df\n                .groupby(by=[\"id\",
          hash_name, \"start_time\", \"end_time\"])\n                .apply(get_vectors,
          indices)\n                .reset_index()\n                .rename(columns={0:\"index_vector\"}))\n    ''''''\n\n    _kale_block3
          = ''''''\n    # create results folder structure\n    nodes_list = recs.node.unique()\n    recorders_list
          = recs.recorder.unique()\n    deployments_list = recs.deployment.unique()\n    if
          os.path.isdir(RESULTS_DIR):\n        shutil.rmtree(RESULTS_DIR)\n    create_results_folder_str(RESULTS_DIR,
          CUMULO, nodes_list, recorders_list, deployments_list)\n    ''''''\n\n    _kale_data_saving_block
          = ''''''\n    # -----------------------DATA SAVING START---------------------------------\n    from
          kale import marshal as _kale_marshal\n    _kale_marshal.set_data_dir(\"/shared_volume/audio/.sndscs_spec_specvid-sipecam-cumulus-node-recorder-deployment-aws.ipynb.kale.marshal.dir\")\n    _kale_marshal.save(recs,
          \"recs\")\n    # -----------------------DATA SAVING END-----------------------------------\n    ''''''\n\n    #
          run the code blocks inside a jupyter kernel\n    from kale.common.jputils
          import run_code as _kale_run_code\n    from kale.common.kfputils import
          \\\n        update_uimetadata as _kale_update_uimetadata\n    _kale_blocks
          = (_kale_pipeline_parameters_block, _kale_data_loading_block,\n                    _kale_block1,\n                    _kale_block2,\n                    _kale_block3,\n                    _kale_data_saving_block)\n    _kale_html_artifact
          = _kale_run_code(_kale_blocks)\n    with open(\"/create_results_dirstruct.html\",
          \"w\") as f:\n        f.write(_kale_html_artifact)\n    _kale_update_uimetadata(''create_results_dirstruct'')\n\n    _kale_mlmdutils.call(\"mark_execution_complete\")\n\nimport
          argparse\n_parser = argparse.ArgumentParser(prog=''Create results dirstruct'',
          description='''')\n_parser.add_argument(\"--AUTH-ENDPOINT\", dest=\"AUTH_ENDPOINT\",
          type=str, required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"--BASE-ENDPOINT\",
          dest=\"BASE_ENDPOINT\", type=str, required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"--CUMULO\",
          dest=\"CUMULO\", type=int, required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"--RESULTS-DIR\",
          dest=\"RESULTS_DIR\", type=str, required=True, default=argparse.SUPPRESS)\n_parsed_args
          = vars(_parser.parse_args())\n\n_outputs = create_results_dirstruct(**_parsed_args)\n"],
          "image": "sipecam/audio-dgpi-kale-tensorflow-yuntu-dask-cert:0.6.1_dev"}},
          "inputs": [{"name": "AUTH_ENDPOINT", "type": "String"}, {"name": "BASE_ENDPOINT",
          "type": "String"}, {"name": "CUMULO", "type": "Integer"}, {"name": "RESULTS_DIR",
          "type": "String"}], "name": "Create results dirstruct"}', pipelines.kubeflow.org/component_ref: '{}',
        pipelines.kubeflow.org/arguments.parameters: '{"AUTH_ENDPOINT": "{{inputs.parameters.AUTH_ENDPOINT}}",
          "BASE_ENDPOINT": "{{inputs.parameters.BASE_ENDPOINT}}", "CUMULO": "{{inputs.parameters.CUMULO}}",
          "RESULTS_DIR": "{{inputs.parameters.RESULTS_DIR}}"}'}
      labels:
        pipelines.kubeflow.org/metadata_written: "true"
        pipelines.kubeflow.org/kfp_sdk_version: 1.8.11
        pipelines.kubeflow.org/pipeline-sdk-type: kfp
        pipelines.kubeflow.org/enable_caching: "true"
    volumes:
    - name: pvolume-ef6fe65091618f865041935b363277953274adf6b420fd4a7b8277d
      persistentVolumeClaim: {claimName: '{{inputs.parameters.vol_shared_volume}}'}
  - name: get-audio-df
    container:
      args: [--AUTH-ENDPOINT, '{{inputs.parameters.AUTH_ENDPOINT}}', --BASE-ENDPOINT,
        '{{inputs.parameters.BASE_ENDPOINT}}', --CUMULO, '{{inputs.parameters.CUMULO}}',
        --LIMIT, '{{inputs.parameters.LIMIT}}', --PAGESIZE, '{{inputs.parameters.PAGESIZE}}',
        --SAMPLERATE, '{{inputs.parameters.SAMPLERATE}}']
      command:
      - sh
      - -ec
      - |
        program_path=$(mktemp)
        printf "%s" "$0" > "$program_path"
        python3 -u "$program_path" "$@"
      - "def get_audio_df(AUTH_ENDPOINT, BASE_ENDPOINT, CUMULO, LIMIT, PAGESIZE, SAMPLERATE):\n\
        \    _kale_pipeline_parameters_block = '''\n    AUTH_ENDPOINT = \"{}\"\n \
        \   BASE_ENDPOINT = \"{}\"\n    CUMULO = {}\n    LIMIT = {}\n    PAGESIZE\
        \ = {}\n    SAMPLERATE = {}\n    '''.format(AUTH_ENDPOINT, BASE_ENDPOINT,\
        \ CUMULO, LIMIT, PAGESIZE, SAMPLERATE)\n\n    from kale.common import mlmdutils\
        \ as _kale_mlmdutils\n    _kale_mlmdutils.init_metadata()\n\n    _kale_block1\
        \ = '''\n    import base64\n    import datetime\n    import glob\n    import\
        \ hashlib\n    import io\n    import itertools\n    import json\n    import\
        \ matplotlib.pyplot as plt\n    import multiprocessing \n    import numpy\
        \ as np\n    import os\n    import pandas as pd\n    import psutil\n    import\
        \ requests\n    import shutil\n    import subprocess\n    import time\n  \
        \  import warnings\n\n    from dask.distributed import Client, LocalCluster\n\
        \    from datetime import timedelta\n    from dotenv import load_dotenv\n\
        \    from matplotlib import cm\n    from moviepy.editor import concatenate,\
        \ VideoFileClip, AudioFileClip\n    from moviepy.audio.AudioClip import AudioArrayClip\n\
        \    from moviepy.video.VideoClip import ImageClip\n    from os.path import\
        \ exists as file_exists\n    from PIL import Image\n    from skimage.transform\
        \ import resize\n\n    from yuntu import Audio\n    from yuntu.soundscape.utils\
        \ import aware_time\n    from yuntu.collection.methods import collection\n\
        \    from yuntu.soundscape.hashers.crono import DEFAULT_HASHER_CONFIG\n  \
        \  from yuntu.soundscape.processors.indices.direct import ICOMPLEXITY, TAIL\n\
        \    from yuntu.soundscape.pipelines.build_soundscape import CronoSoundscape,\
        \ HASHER_CONFIG\n    '''\n\n    _kale_block2 = '''\n    def audio2video(audio_id,\n\
        \                    audio_df,\n                    save_path_folder,\n  \
        \                  product_spectrum,\n                    cumulus,\n     \
        \               abs_start=None,\n                    fps=60,\n           \
        \         spec_configs={'hop_length': 512, 'n_fft': 1024, 'window_function':\
        \ 'hann'},\n                    rate=24,\n                    frame_duration=3.0,\n\
        \                    min_freq=0,\n                    max_freq=None,\n   \
        \                 cmap=\"Greys\",\n                    figsize=(5, 8),\n \
        \                   dpi=100,\n                    bands=None):\n        \\\
        '\\'\\'Takes and audio object and produces a mp4 video of the spectrogram\
        \ with audio\\'\\'\\'\n\n        sub_audio_df = audio_df[audio_df[\"id\"]==audio_id]\n\
        \        id_audio = sub_audio_df['id'].values[0]\n        node = sub_audio_df['node'].values[0]\n\
        \        recorder = sub_audio_df['recorder'].values[0]\n        deployment\
        \ = sub_audio_df['deployment'].values[0]\n        audio = sub_audio_df.audio[0]\n\
        \n        colormap = cm.get_cmap(cmap)\n        duration = audio.duration\n\
        \        step = 1/rate\n        start = -(frame_duration/2.0)\n        stop\
        \ = start + frame_duration\n        clips = []\n        last_stop = None\n\
        \n        if max_freq is None:\n            max_freq = audio.samplerate /\
        \ 2.0\n\n        if min_freq is None:\n            min_freq = 0\n\n      \
        \  with audio.features.db_spectrogram(**spec_configs) as spec:\n         \
        \   min_spec = np.amin(spec)\n            max_spec = np.amax(spec)\n     \
        \       spec_range = (max_spec-min_spec)\n\n            while stop <= duration+(frame_duration/2.0):\n\
        \                clip = produce_clip(spec, frame_duration, min_freq, max_freq,\
        \ start, stop, step, abs_start, colormap,\n                              \
        \      min_spec, spec_range, figsize, dpi, bands=bands)\n                clips.append(clip)\n\
        \n                if start + step + frame_duration > duration:\n         \
        \           last_stop = stop\n\n                start = start + step\n   \
        \             stop = start + frame_duration\n\n        video = concatenate(clips)\n\
        \        # edaudio = AudioArrayClip(audio_array, fps=audio.samplerate)\n \
        \       edaudio = AudioFileClip(audio.path).set_end(audio.duration)\n    \
        \    video = video.set_audio(edaudio)\n        file_path = os.path.join(save_path_folder,\
        \ f\"{audio_id}.mp4\")\n        video.write_videofile(file_path, fps=fps)\n\
        \n        save_metadata_videoclip(audio_id, product_spectrum,\n          \
        \            save_path_folder, cumulus, node, recorder, deployment, 0.0, audio.duration)\n\
        \        video.close()\n        edaudio.close()\n\n        for c in clips:\n\
        \            c.close()\n\n    def change_type_sipecam_sc(session, root_folder_id,\
        \ path, file_type, node_type):\n        if file_type == \"sequence.png\":\n\
        \            metadata_name = \"soundscape_seq_metadata.json\"\n          \
        \  aggr_type = \"None\"\n        elif file_type == \"mean_soundscape.png\"\
        :\n            metadata_name = \"mean_soundscape_metadata.json\"\n       \
        \     aggr_type = \"Mean\"\n        elif file_type ==  \"std_soundscape.png\"\
        :\n            metadata_name = \"std_soundscape_metadata.json\" \n       \
        \     aggr_type = \"Standard deviation\"\n        elif file_type == \"hashed_soundscape.parquet\"\
        :\n            metadata_name = \"soundscape_metadata.json\" \n           \
        \ aggr_type = \"None\"\n        elif \".png\" in file_type and (file_type\
        \ not in [\"sequence.png\", \"mean_soundscape.png\", \"std_soundscape.png\"\
        ]):\n            metadata_name = file_type.split(\".\")[0] + \"_spectrogram_metadata.json\"\
        \n            aggr_type = \"Null\"\n        elif \".mp4\" in file_type and\
        \ (file_type not in [\"sequence.png\", \"mean_soundscape.png\", \"std_soundscape.png\"\
        ]):\n            metadata_name = file_type.split(\".\")[0] + \"_spectrogram_video_metadata.json\"\
        \n            aggr_type = \"Null\"\n\n        try:\n            semi_path\
        \ = path.split(\"soundscapes/\")[-1]\n            semi_path_file = os.path.join(semi_path,\
        \ file_type)\n            local_path_file_metadata = os.path.join(path, metadata_name)\n\
        \            print(f\"Changing type for {os.path.join(semi_path)}\")\n   \
        \         alfresco_path = os.path.join(\"/Company Home/Sites/sipecam-soundscape/documentLibrary/\"\
        , semi_path)\n\n            response = session.get(\n                os.getenv(\"\
        ALFRESCO_URL\")\n                + BASE_ENDPOINT\n                + \"/nodes/\"\
        \n                + root_folder_id\n                + \"/children?relativePath=\"\
        +semi_path+\"&include=aspectNames&skipCount=0\"\n            )        \n \
        \           # if request is successful then continue\n            if response.status_code\
        \ == 200:\n\n                data_file = open(local_path_file_metadata)\n\
        \                data_json = json.load(data_file)\n                response_entries\
        \ = response.json()[\"list\"][\"entries\"]\n\n                for entry in\
        \ response_entries:\n                    if entry['entry']['name']==file_type\
        \ and entry['entry']['isFile']:\n                        prop_dict = {}\n\n\
        \                        if entry['entry']['name']==file_type:\n\n       \
        \                     if entry['entry']['name'] in [\"sequence.png\", \"mean_soundscape.png\"\
        , \"std_soundscape.png\"]:\n                                prop_dict[\"soundscape:CumulusName\"\
        ] = str(data_json[\"CumulusName\"])\n                                prop_dict[\"\
        soundscape:DateDeployment\"] = data_json[\"DateDeployment\"]\n           \
        \                     prop_dict[\"soundscape:NodeCategoryIntegrity\"] = str(data_json[\"\
        NodeCategoryIntegrity\"])\n                                prop_dict[\"soundscape:NomenclatureNode\"\
        ] = str(data_json[\"NomenclatureNode\"])\n                               \
        \ prop_dict[\"soundscape:SerialNumber\"] = str(data_json[\"SerialNumber\"\
        ])\n                                prop_dict[\"soundscape:aggr\"] = str(aggr_type)\n\
        \                                prop_dict[\"soundscape:cycle_config_aware_start\"\
        ] = str(data_json[\"product_configs\"]['hasher_config']['kwargs']['aware_start'])\n\
        \                                prop_dict[\"soundscape:cycle_config_start_format\"\
        ] = str(data_json[\"product_configs\"]['hasher_config']['kwargs']['start_format'])\n\
        \                                prop_dict[\"soundscape:cycle_config_start_time\"\
        ] =  datetime.datetime.strptime(data_json[\"product_configs\"]['hasher_config']['kwargs']['start_time'],\
        \ \n                                                                     \
        \                                   \"%Y-%m-%d %H:%M:%S\").strftime(\"%Y-%m-%dT%H:%M:%S.%f%z\"\
        )\n                                prop_dict[\"soundscape:cycle_config_start_tzone\"\
        ] = str(data_json[\"product_configs\"]['hasher_config']['kwargs']['start_tzone'])\n\
        \                                prop_dict[\"soundscape:cycle_config_time_module\"\
        ] = int(data_json[\"product_configs\"]['hasher_config']['kwargs']['time_module'])\n\
        \                                prop_dict[\"soundscape:cycle_config_time_unit\"\
        ] = str(data_json[\"product_configs\"]['hasher_config']['kwargs']['time_unit'])\n\
        \                                prop_dict[\"soundscape:cycle_config_time_utc_column\"\
        ] = str(data_json[\"product_configs\"]['hasher_config']['kwargs']['time_utc_column'])\n\
        \                                prop_dict[\"soundscape:frequency_bins\"]\
        \ = int(data_json[\"product_configs\"][\"slice_config\"][\"frequency_bins\"\
        ])\n                                prop_dict[\"soundscape:frequency_hop\"\
        ] = int(data_json[\"product_configs\"][\"slice_config\"][\"frequency_hop\"\
        ])\n                                prop_dict[\"soundscape:frequency_limits\"\
        ] = str(data_json[\"product_configs\"][\"slice_config\"][\"frequency_limits\"\
        ])\n                                prop_dict[\"soundscape:hash_name\"] =\
        \ str(data_json[\"product_configs\"][\"hash_name\"])\n                   \
        \             prop_dict[\"soundscape:hop_length\"] = int(data_json[\"product_configs\"\
        ][\"slice_config\"][\"feature_config\"][\"hop_length\"])\n               \
        \                 prop_dict[\"soundscape:indices\"] =  \", \".join(map(str,\
        \ data_json['product_configs']['indices']))\n                            \
        \    prop_dict[\"soundscape:n_fft\"] = int(data_json[\"product_configs\"][\"\
        slice_config\"][\"feature_config\"][\"n_fft\"])\n                        \
        \        prop_dict[\"soundscape:npartitions\"] = int(data_json[\"product_configs\"\
        ]['npartitions'])\n                                prop_dict[\"soundscape:product_name\"\
        ] = str(data_json[\"product_name\"])\n                                prop_dict[\"\
        soundscape:product_parent\"] = str(data_json[\"product_parent\"])\n      \
        \                          prop_dict[\"soundscape:product_path\"] = str(alfresco_path)\n\
        \                                prop_dict[\"soundscape:product_spectrum\"\
        ] = str(data_json[\"product_spectrum\"])\n                               \
        \ prop_dict[\"soundscape:slice_config_feature_type\"] = str(data_json[\"product_configs\"\
        ][\"slice_config\"][\"feature_type\"])\n                                prop_dict[\"\
        soundscape:slice_config_frequency_bins\"] = int(data_json[\"product_configs\"\
        ][\"slice_config\"][\"frequency_bins\"])\n                               \
        \ prop_dict[\"soundscape:slice_config_time_unit\"] = int(data_json[\"product_configs\"\
        ][\"slice_config\"][\"time_unit\"])\n                                prop_dict[\"\
        soundscape:time_hop\"] = int(data_json[\"product_configs\"][\"slice_config\"\
        ][\"time_hop\"])\n                                prop_dict[\"soundscape:window_function\"\
        ] = str(data_json[\"product_configs\"][\"slice_config\"][\"feature_config\"\
        ][\"window_function\"])  \n\n                            elif (\"spectrogram\"\
        \ or \"video\") in entry['entry']['name']:\n                             \
        \   prop_dict[\"soundscape:product_name\"] = str(data_json[\"product_name\"\
        ])\n                                prop_dict[\"soundscape:product_parent\"\
        ] = str(data_json[\"product_parent\"])\n                                prop_dict[\"\
        soundscape:product_path\"] = str(alfresco_path)\n                        \
        \        prop_dict[\"soundscape:product_spectrum\"] = str(data_json[\"product_spectrum\"\
        ])\n                                prop_dict[\"soundscape:CumulusName\"]\
        \ = str(data_json[\"CumulusName\"])\n                                prop_dict[\"\
        soundscape:NodeCategoryIntegrity\"] = str(data_json[\"NodeCategoryIntegrity\"\
        ])\n                                prop_dict[\"soundscape:NomenclatureNode\"\
        ] = str(data_json[\"NomenclatureNode\"])\n                               \
        \ prop_dict[\"soundscape:SerialNumber\"] = str(data_json[\"SerialNumber\"\
        ])\n                                prop_dict[\"soundscape:DateDeployment\"\
        ] = data_json[\"DateDeployment\"]\n                                prop_dict[\"\
        soundscape:AudioID\"] = data_json[\"AudioID\"]\n\n                       \
        \ aspects = entry['entry']['aspectNames']\n                        data =\
        \ {\"aspectNames\": aspects, \"nodeType\": node_type, \"properties\": prop_dict}\n\
        \                        # update properties request\n                   \
        \     update = session.put(\n                            os.getenv(\"ALFRESCO_URL\"\
        )\n                            + BASE_ENDPOINT\n                         \
        \   + \"/nodes/\"\n                            + entry['entry']['id'],\n \
        \                           data=json.dumps(data),\n                     \
        \   )\n\n                        if update.status_code == 200:\n         \
        \                   print(\"Updated \" + entry['entry']['id'])           \
        \         \n\n        except Exception as e:\n            print(\"Could not\
        \ add any aspect to this file: \", e)\n\n    def create_results_folder_str(results_dir,\
        \ cumulo, nodes_list, rec_list, dep_list): \n        # results directory\n\
        \        os.makedirs(results_dir, exist_ok=True)\n        # cumulus subdir\n\
        \        cum_subdir = os.path.join(results_dir, str(cumulo))\n        os.makedirs(cum_subdir,\
        \ exist_ok=True)\n        # node subdirs\n        for node in nodes_list:\n\
        \            node_subdir = os.path.join(cum_subdir, node)\n            os.makedirs(node_subdir,\
        \ exist_ok=True)\n            # recorder subdirs\n            for rec in rec_list:\n\
        \                rec_subdir = os.path.join(node_subdir, rec)\n           \
        \     os.makedirs(rec_subdir, exist_ok=True)\n                # deployment\
        \ subdirs\n                for dep in dep_list:\n                    dep_subdir\
        \ = os.path.join(rec_subdir, dep)\n                    os.makedirs(dep_subdir,\
        \ exist_ok=True)\n\n    def distance_to_mean(vector, mean):\n        \\'\\\
        '\\'Return euclidean distance to mean\\'\\'\\'\n        return np.sqrt(np.sum(np.square(mean\
        \ - vector)))\n\n    def find_subfolders(path_abs):\n        subdir_list =\
        \ []\n        walk = list(os.walk(path_abs))\n        for path, _, _ in walk[::-1]:\n\
        \            len_path = path.split(\"/\")\n            if len(len_path) ==\
        \ 8:\n                subdir_list.append(path)  \n\n        return subdir_list\n\
        \n    def get_audio_ids(soundscape_path, indices, nsamples):\n        df =\
        \ pd.read_parquet(os.path.join(soundscape_path, \"hashed_soundscape.parquet\"\
        ))\n\n        df[\"time_raw_hour\"] = df[\"time_raw\"].apply(lambda x: datetime.datetime.strptime(x,'%H:%M:%S\
        \ %d/%m/%Y (%z)').strftime(\"%H\"))\n        hours_list = list(df.time_raw_hour.unique())\n\
        \        hours_list.sort(key = int)\n\n        with open(os.path.join(soundscape_path,\
        \ \"soundscape_metadata.json\")) as f:\n            metadata = json.load(f)\n\
        \            f.close()\n\n        # indices = metadata[\"product_configs\"\
        ][\"indices\"]\n        # indices = [\"EXAG\", \"ICOMPLEXITY\", \"CORE\"]\n\
        \        hash_name = metadata[\"product_configs\"][\"hash_name\"]\n      \
        \  cycle_config = metadata[\"product_configs\"][\"hasher_config\"][\"kwargs\"\
        ]\n        time_unit = cycle_config[\"time_unit\"]\n        zero_t = aware_time(cycle_config[\"\
        start_time\"], cycle_config[\"start_tzone\"], cycle_config[\"start_format\"\
        ]) \n\n        # iterate over hours\n        audio_id_list = []\n        for\
        \ hour in hours_list:\n            subdf = df.query(f\"time_raw_hour == '{hour}'\"\
        )\n            # sample\n            samples_df = get_recording_samples(subdf,\
        \ hash_name, indices, time_unit, zero_t, nsamples=3)\n            unique_crono_hash_list\
        \ = list(samples_df.crono_hash_30m.unique())\n            sub_df = samples_df[samples_df.crono_hash_30m\
        \ == min(unique_crono_hash_list)]\n            audio_id_list += list(sub_df.id.tolist())\n\
        \n        return audio_id_list\n\n    def get_recording_samples(df, hash_name,\
        \ indices, time_unit, zero_t, nsamples=5):\n        \\'\\'\\'Return dataframe\
        \ of 'nsamples' samples for each tag in 'hash_name' column that are closest\
        \ to the mean vector by tag\\'\\'\\'\n        proj_df = df[(df.max_freq <=\
        \ 10000)]\n        crono_tags = proj_df.crono_hash_30m.unique()\n        proj_df.loc[:\
        \ , f\"{hash_name}_time\"] = proj_df[hash_name].apply(lambda x: zero_t + datetime.timedelta(seconds=float(x*time_unit)))\n\
        \        vectors = vectorize_soundscape(proj_df, hash_name, indices)\n   \
        \     min_index_vector = np.amin(np.stack(list(vectors.index_vector.values)),\
        \ axis=(0,1))\n        max_index_vector = np.amax(np.stack(list(vectors.index_vector.values)),\
        \ axis=(0,1))\n        index_range = (max_index_vector - min_index_vector)\n\
        \        vectors.loc[:, \"normalized_index_vector\"] = vectors.index_vector.apply(lambda\
        \ x: (x-min_index_vector)/index_range)\n        all_samples = []\n\n     \
        \   for crono_tag in crono_tags:\n            unit_vectors = vectors[vectors[hash_name]\
        \ == crono_tag]\n            mean_unit_vector = unit_vectors.normalized_index_vector.mean()\n\
        \            unit_vectors.loc[:, \"distance\"] = unit_vectors.normalized_index_vector.apply(lambda\
        \ x: distance_to_mean(x, mean_unit_vector))\n            all_samples.append(unit_vectors.sort_values(by=\"\
        distance\").head(nsamples))\n        return pd.concat(all_samples)\n\n   \
        \ def get_vectors(group, indices):\n        \\'\\'\\'Return array of indices\
        \ by frequency\\'\\'\\'\n        return group.sort_values(by=\"max_freq\"\
        )[indices].values\n\n    def login():\n        \"\"\"\n        Tries a login\
        \ to alfresco api and returns a session\n        object with credentials \n\
        \        Returns: \n            session (Session):  A session object to make\
        \ \n                                requests to zendro.\n        \"\"\"\n\
        \        try:\n            auth = {\n                \"userId\": os.getenv(\"\
        ALFRESCO_USER\"),\n                \"password\": os.getenv(\"ALFRESCO_PASSWORD\"\
        ),\n            }\n\n            login = requests.post(os.getenv(\"ALFRESCO_URL\"\
        ) + AUTH_ENDPOINT + \"/tickets\",data=json.dumps(auth))\n\n            base64_login\
        \ = base64.b64encode(bytes(login.json()[\"entry\"][\"id\"], 'utf-8')).decode()\n\
        \n            # se crea un objeto de Session para hacer requests\n       \
        \     session = requests.Session()\n            # se establece bearer token\n\
        \            session.headers.update({'Authorization': 'Basic ' + base64_login})\n\
        \n            return session\n        except Exception as e:\n           \
        \ print(\"Login failed: \", e)\n\n    def plot_spectrogram(audio_id, audio_df,\
        \ save_path_folder, spectrum, cumulus):\n        sub_audio_df = audio_df[audio_df[\"\
        id\"]==audio_id]\n        node = sub_audio_df['node'].values[0]\n        recorder\
        \ = sub_audio_df['recorder'].values[0]\n        deployment = sub_audio_df['deployment'].values[0]\n\
        \        # plot\n        fig, ax = plt.subplots(2,1,figsize=(20,10), sharex=True)\n\
        \        sub_audio_df.audio[0].plot(ax=ax[0], color='grey')\n        sub_audio_df.audio[0].features.db_spectrogram().plot(ax=ax[1])\n\
        \        ax[0].set_ylabel('Amplitude')\n        ax[0].grid(False)\n      \
        \  ax[1].set_ylabel('F (KHz)')\n        ax[1].set_xlabel('Time (seconds)')\n\
        \        fig.text(0.75, 0.04, f\"Cumulus: {cumulus} - Node: {node} - Recorder:\
        \ {recorder}\", va='center')\n        plt.tight_layout()\n        if save_path_folder:\n\
        \            file_path = os.path.join(save_path_folder, f\"{audio_id}.png\"\
        )\n            fig.savefig(file_path)\n        plt.show()\n\n        save_metadata_spectrogram(audio_id,\
        \ spectrum, save_path_folder, \n                                  cumulus,\
        \ node, recorder, deployment, parent=\"Null\")\n\n    def plot_soundscape(soundscape,\
        \ product_type, product_spectrum, sc_config, path, \n                    \
        \    cumulus, node, recorder, deployment, parent, indices, min_freq=None,\n\
        \                      figsize=(20,15), plt_style='ggplot'):\n\n        if\
        \ min_freq:\n            soundscape = soundscape[soundscape['min_freq']<=min_freq]\n\
        \n        if product_type == \"sequence\":\n            file_path = os.path.join(path,\
        \ \"sequence.png\")\n            # product_id = hashlib.md5(file_path.encode('utf-8')).hexdigest()\n\
        \n            plt.style.use(plt_style)\n            fig, ax = plt.subplots(figsize=figsize)\n\
        \            soundscape.sndscape.plot_sequence(rgb=indices, time_format='%Y-%m\
        \ %H:%M', ax=ax)\n            plt.xticks(rotation = 90)\n            ax.grid(False)\n\
        \            plt.tight_layout()\n            plt.savefig(file_path) \n   \
        \         plt.show()\n            # save metadata\n            save_metadata_sc(product_type,\
        \ product_spectrum, sc_config,\n                      path, cumulus, node,\
        \ recorder, deployment, parent=parent)\n\n        elif product_type == \"\
        standard_deviation\":\n            file_path = os.path.join(path, \"std_soundscape.png\"\
        )\n            # product_id = hashlib.md5(file_path.encode('utf-8')).hexdigest()\n\
        \n            plt.style.use(plt_style)\n            fig, ax = plt.subplots(figsize=figsize)\n\
        \            soundscape.sndscape.plot_cycle(rgb=indices, aggr=\"std\", time_format='%H:%M',\
        \ \n                                           xticks=24, ax=ax)\n       \
        \     plt.xticks(rotation = 90)\n            ax.grid(False)\n            plt.tight_layout()\
        \ \n            plt.savefig(file_path)\n            plt.show()\n\n       \
        \     # save metadata\n            save_metadata_sc(product_type, product_spectrum,\
        \ sc_config,\n                      path, cumulus, node, recorder, deployment,\
        \ parent)     \n\n        elif product_type == \"mean\": \n            file_path\
        \ = os.path.join(path, \"mean_soundscape.png\")\n            # product_id\
        \ = hashlib.md5(file_path.encode('utf-8')).hexdigest()\n\n            plt.style.use(plt_style)\n\
        \            fig, ax = plt.subplots(figsize=figsize)\n            soundscape.sndscape.plot_cycle(rgb=indices,\
        \ aggr=\"mean\", time_format='%H:%M', \n                                 \
        \          xticks=24, ax=ax)\n            plt.xticks(rotation = 90)\n    \
        \        ax.grid(False)\n            plt.tight_layout()\n            plt.savefig(file_path)\n\
        \            plt.show()\n\n            # save metadata\n            save_metadata_sc(product_type,\
        \ product_spectrum, sc_config,\n                      path, cumulus, node,\
        \ recorder, deployment, parent)    \n\n        print(f\"File saved at {file_path}\"\
        )\n\n    def produce_clip(spec, frame_duration, min_freq, max_freq, start,\
        \ stop, step, abs_start=None, \n                     colormap=cm.get_cmap(\"\
        Greys\"), min_spec=0, spec_range=1.0, figsize=(5, 4), \n                 \
        \    dpi=100, bands=None):\n        \\'\\'\\'Takes an individual frame and\
        \ produces an image with references\\'\\'\\'\n        frame = spec.cut_array(start_time=start,\
        \ end_time=stop, min_freq=min_freq, max_freq=max_freq, pad=True)\n       \
        \ plt.style.use('dark_background')\n        frame = np.flip((frame - min_spec)/spec_range,\
        \ axis=0)\n        fig, ax = plt.subplots(figsize=figsize)\n        ax.imshow(frame,\
        \ cmap=colormap, extent=[0, frame_duration, min_freq/1000, max_freq/1000],\
        \ \n                  aspect=\"auto\", vmin = 0, vmax = 1.0)\n\n        if\
        \ bands is not None:\n            band_arr = np.flip(resize(np.expand_dims(bands,\
        \ axis=1), (frame.shape[0], frame.shape[1])), axis=0)\n            ax.imshow(band_arr,\
        \ extent=[0, frame_duration, min_freq/1000, max_freq/1000], aspect=\"auto\"\
        , vmin = 0, \n                      vmax = 1.0, alpha=0.5)\n\n        ax.tick_params(axis='both',\
        \ which='major', labelsize=8)\n        ax.tick_params(axis='both', which='minor',\
        \ labelsize=8)\n        mid = frame_duration/2.0\n        ax.axvline(x=mid,\
        \ color=\"red\")\n        ax.set_ylabel('F (kHz)')\n        ax.set_xticks([])\n\
        \        ax.set_xticks([], minor=True)\n\n        if abs_start is not None:\n\
        \            time_text = (abs_start + datetime.timedelta(seconds=start+mid)).strftime('%H:%M:%S.%f').strip()[:-4]\n\
        \            ax.text(mid-0.3, -0.6, time_text)\n\n        buf = io.BytesIO()\n\
        \        fig.tight_layout()\n        fig.savefig(buf, dpi=dpi)\n        buf.seek(0)\n\
        \        im = Image.open(buf)\n        im.format = \"PNG\"\n        plt.close(fig)\n\
        \n        return ImageClip(np.asarray(im),\n                         duration=step)\n\
        \n    def remove_empty_folders(path_abs):\n        walk = list(os.walk(path_abs))\n\
        \        for path, _, _ in walk[::-1]:\n            if len(os.listdir(path))\
        \ == 0:\n                os.rmdir(path)            \n\n    def save_metadata_sc(product_type,\
        \ product_spectrum, sc_config,\n                      path, cumulus, node,\
        \ recorder, deployment, parent=\"Null\"):\n        if product_type == \"soundscape\"\
        :\n            product_name = \"Soundscape\"\n            file_path = os.path.join(path,\
        \ \"hashed_soundscape.parquet\")\n            metadata_filename = os.path.join(path,\
        \ \"soundscape_metadata.json\")\n        elif product_type == \"sequence\"\
        :\n            product_name = \"Soundscape sequential plot\"\n           \
        \ file_path = os.path.join(path, \"soundscape_seq.png\")\n            metadata_filename\
        \ = os.path.join(path, \"soundscape_seq_metadata.json\")\n        elif product_type\
        \ == \"standard_deviation\":\n            product_name = \"Soundscape standard\
        \ deviation plot\"\n            file_path = os.path.join(path, \"std_soundscape.png\"\
        )\n            metadata_filename = os.path.join(path, \"std_soundscape_metadata.json\"\
        )\n        elif product_type == \"mean\":\n            product_name = \"Soundscape\
        \ mean plot\"\n            file_path = os.path.join(path, \"mean_soundscape.png\"\
        )\n            metadata_filename = os.path.join(path, \"mean_soundscape_metadata.json\"\
        )\n\n        if int(node.split(\"_\")[2]) == 0:\n            node_category\
        \ = \"Degradado\"\n        elif int(node.split(\"_\")[2]) == 1:\n        \
        \    node_category = \"Integro\"\n\n        metadata = {\n            \"product_parent\"\
        : parent,\n            \"product_name\": product_name,\n            \"product_configs\"\
        : sc_config,\n            \"product_path\": file_path,\n            \"product_spectrum\"\
        : product_spectrum,\n            \"CumulusName\": cumulus,\n            \"\
        NodeCategoryIntegrity\": node_category,\n            \"NomenclatureNode\"\
        : node,\n            \"SerialNumber\": recorder,\n            \"DateDeployment\"\
        : deployment\n        }\n\n        with open(metadata_filename, 'w', encoding='utf-8')\
        \ as f:\n            json.dump(metadata, f, ensure_ascii=False, indent=4)\n\
        \n    def save_metadata_spectrogram(audio_id, product_spectrum,\n        \
        \              path, cumulus, node, recorder, deployment, parent=\"Null\"\
        ):\n        # identifier is being used as audio_id in alfresco\n        product_name\
        \ = \"Spectrogram\"\n        file_path = os.path.join(path, f\"{audio_id}.png\"\
        )\n        metadata_filename = os.path.join(path, f\"{audio_id}_spectrogram_metadata.json\"\
        )\n\n        if int(node.split(\"_\")[2]) == 0:\n            node_category\
        \ = \"Degradado\"\n        elif int(node.split(\"_\")[2]) == 1:\n        \
        \    node_category = \"Integro\"\n\n        metadata = {\n            \"product_parent\"\
        : parent,\n            \"product_name\": product_name,\n            \"product_path\"\
        : file_path,\n            \"product_spectrum\": product_spectrum,\n      \
        \      \"CumulusName\": cumulus,\n            \"NodeCategoryIntegrity\": node_category,\n\
        \            \"NomenclatureNode\": node,\n            \"SerialNumber\": recorder,\n\
        \            \"DateDeployment\": deployment,\n            \"AudioID\": audio_id\n\
        \        }\n        with open(metadata_filename, 'w', encoding='utf-8') as\
        \ f:\n            json.dump(metadata, f, ensure_ascii=False, indent=4)\n\n\
        \        print(f\"{file_path} saved.\")\n        print(f\"{metadata_filename}\
        \ saved.\")\n\n    def save_metadata_videoclip(audio_id, product_spectrum,\
        \ path, cumulus, node, recorder, \n                                deployment,\
        \ clip_start, clip_end, parent=\"Null\"):\n        # identifier is being used\
        \ as audio_id in alfresco\n        product_name = \"spectrogram_video\"\n\
        \        file_path = os.path.join(path, f\"{audio_id}.mp4\")\n        metadata_filename\
        \ = os.path.join(path, f\"{audio_id}_spectrogram_video_metadata.json\")\n\n\
        \        if int(node.split(\"_\")[2]) == 0:\n            node_category = \"\
        Degradado\"\n        elif int(node.split(\"_\")[2]) == 1:\n            node_category\
        \ = \"Integro\"\n\n        metadata = {\n            \"product_parent\": parent,\n\
        \            \"product_name\": product_name,\n            \"product_description\"\
        : \"Spectrogram Video. Time is show in local timezone\",\n            \"product_path\"\
        : file_path,\n            \"product_spectrum\": product_spectrum,\n      \
        \      \"CumulusName\": cumulus,\n            \"NodeCategoryIntegrity\": node_category,\n\
        \            \"NomenclatureNode\": node,\n            \"SerialNumber\": recorder,\n\
        \            \"DateDeployment\": deployment,\n            \"ClipStart\": clip_start,\n\
        \            \"ClipEnd\": clip_end,\n            \"AudioID\": audio_id\n \
        \       }\n\n        with open(metadata_filename, 'w', encoding='utf-8') as\
        \ f:\n            json.dump(metadata, f, ensure_ascii=False, indent=4)\n\n\
        \        print(f\"{file_path} saved.\")\n        print(f\"{metadata_filename}\
        \ saved.\")\n\n    def upload(session, node_id, data, file):\n        \"\"\
        \"\n        Uploads a file to a specific folder.\n        Parameters:\n  \
        \          session (Session):          A session object to make\n        \
        \                                requests to alfresco.\n            node_id\
        \ (string):           Node id to which the file is going to be created\n \
        \           data (dict):                Dict that contains file options\n\
        \            file (object):              File to upload\n\n        Returns:\n\
        \            (list):     A list containing status code and status data\n \
        \       \"\"\"\n\n        try:\n            response = session.post(os.getenv(\"\
        ALFRESCO_URL\")\n                        + BASE_ENDPOINT + \"/nodes/\" + node_id\
        \ + \"/children\",\n                        data = data,\n               \
        \         files = file\n                        )\n\n            return [response.json(),\
        \ response.status_code];\n        except Exception as e: \n            print(\"\
        File \" + data[\"name\"] + \" could not be uploaded: \", e)\n\n    def upload_files(file_patterns,\
        \ session, node_id, dir_path, recursive, file_identifier=\"\"):\n        \"\
        \"\"\n        Uploads the files stored in a specific dir\n        to alfresco\n\
        \        Parameters:\n            session (Session):          A session object\
        \ to make\n                                        requests to alfresco.\n\
        \            node_id (string):           Node id to which the file is going\
        \ to be created\n            dir_path (string):          The name and path\
        \ of the dir where files are stored\n            recursive (boolean):    \
        \    A boolean to know if upload  must be recursive\n                    \
        \                    in the specifed dir, and should preserve the\n      \
        \                                  structure of dirs inside.\n           \
        \ file_identifier (string):   File identifier for all files inside a dir\n\
        \        Returns:\n            (string):           Returns the info of recent\
        \ created site.\n        \"\"\"\n\n        if recursive:\n            expression\
        \ = \"/**/*\"\n        else:\n            expression = \"/*\"\n\n        files_in_dir\
        \ = list(\n            itertools.chain.from_iterable(\n                glob.iglob(dir_path\
        \ + expression + pattern, recursive=recursive)\n                for pattern\
        \ in file_patterns\n            )\n        )\n        filename = \"logs/upload_log\"\
        \ + dir_path.replace('/','-') + '.txt'\n\n        os.makedirs(os.path.dirname(filename),\
        \ exist_ok=True)\n\n        total_files = len(files_in_dir)\n        starttime\
        \ = time.time()\n\n        try:\n            files_uploaded = []\n       \
        \     for idx, file_with_path in enumerate(files_in_dir):\n\n            \
        \    # total time since last login or script start\n                total_time\
        \ = round((time.time() - starttime), 2)\n\n                if total_time >\
        \ 2400:\n                    \"\"\"\n                    if total time is\
        \ bigger than 2400\n                    or 40 minutes relogin to avoid ticket\n\
        \                    expiration\n                    \"\"\"\n            \
        \        time.sleep(5)\n\n                    print(\"Re-logging in to alfresco...\"\
        )\n\n                    session = login.login()\n                    # restart\
        \ time\n                    starttime = time.time()\n                    time.sleep(5)\n\
        \                    print(\"Login sucessful, continuing upload\\\\n\")\n\n\
        \                len_of_path = len(file_with_path.split(\"/\"))\n        \
        \        name_of_file = file_with_path.split(\"/\")[len_of_path - 1]\n   \
        \             root_dir_path = file_with_path.replace(dir_path, \"\").replace(\n\
        \                    file_with_path.split(\"/\")[len_of_path - 1], \"\"\n\
        \                )\n\n                data = {\n                    \"name\"\
        : (\n                        name_of_file[0 : len(name_of_file) - 4]\n   \
        \                     + file_identifier\n                        + name_of_file[len(name_of_file)\
        \ - 4 : len(name_of_file)]\n                    ),\n                    \"\
        nodeType\": \"cm:content\",\n                }\n\n                data[\"\
        relativePath\"] = root_dir_path\n\n                data[\"properties\"] =\
        \ {\n                    \"cm:title\": (\n                        name_of_file[0\
        \ : len(name_of_file) - 4]\n                        + file_identifier\n  \
        \                      + name_of_file[len(name_of_file) - 4 : len(name_of_file)]\n\
        \                    )\n                }\n\n                print(\"Uploading\
        \ \" + data[\"name\"] + \" file...\")\n\n                files = {\"filedata\"\
        : open(file_with_path, \"rb\")}\n                upload_response = upload(session,\
        \ node_id, data, files)\n                if upload_response[1] and upload_response[1]\
        \ == 201:\n                    files_uploaded.append(upload_response[0])\n\
        \                    print(\"Uploaded \" + data[\"name\"])\n\n           \
        \         filename = \"logs/upload_log\" + dir_path.replace('/','-') + '.txt'\n\
        \                    with open(filename, 'a') as log_file:\n             \
        \           log_file.writelines(\"%s\\\\n\" % file_with_path)\n\n        \
        \        elif upload_response[1] and upload_response[1] == 409:\n        \
        \            if \"already exists\" in upload_response[0][\"error\"][\"errorKey\"\
        ]:\n                        print(\"File \" + data[\"name\"] + \" already\
        \ uploaded\")\n\n                else:\n                    print(\"An error\
        \ ocurred, file \" + data[\"name\"] + \" cannot be uploaded\")\n\n       \
        \         print(\"Uploaded file \" + str(idx + 1) + \" of \" + str(total_files))\n\
        \                print(\"\\\\n\\\\n\")\n\n            return files_uploaded\n\
        \        except Exception as e:\n            print(\"An error ocurred in file\
        \ upload: \", e)\n\n    def vectorize_soundscape(df, hash_name, indices):\n\
        \        \\'\\'\\'Return dataframe with array column containing indices by\
        \ frequency\\'\\'\\'\n        return (df\n                .groupby(by=[\"\
        id\", hash_name, \"start_time\", \"end_time\"])\n                .apply(get_vectors,\
        \ indices)\n                .reset_index()\n                .rename(columns={0:\"\
        index_vector\"}))\n    '''\n\n    _kale_block3 = '''\n    load_dotenv()\n\
        \    DB_CONFIG = {\n        'provider': 'alfresco',\n        'config': {\n\
        \            'api_url': 'https://api.conabio.gob.mx/alfresco',\n         \
        \   'page_size': PAGESIZE,\n            'api_key': os.getenv(\"X_API_KEY\"\
        ),\n            'base_filter': \"+TYPE: \\\\\"sipecam:audio\\\\\" AND -TYPE:\
        \ \\\\\"dummyType\\\\\"\",\n            'recording_parser': {\"path\": \"\
        /shared_volume/audio/utils.py\",\n                                 \"object_name\"\
        : \"parser\"}\n        }\n    }\n\n    COL_CONFIG = {\n        \"col_type\"\
        : \"alfresco\",\n        \"db_config\": DB_CONFIG\n    }\n\n    col = collection(**COL_CONFIG)\n\
        \    query = f\"(sipecam:CumulusName:\\\\\"{CUMULO}\\\\\") AND (sipecam:SampleRate:{SAMPLERATE})\"\
        \n\n    if LIMIT:\n        recs = col.get_recording_dataframe(query, limit=LIMIT,\
        \ with_metadata = True, with_geometry = False)\n    else:\n        recs =\
        \ col.get_recording_dataframe(query, with_metadata = True, with_geometry =\
        \ False)\n\n    # include filtering columns for processing units\n    recs.loc[:,\
        \ \"node\"] = recs.metadata.apply(lambda x: x[\"entry\"][\"properties\"][\"\
        sipecam:NomenclatureNode\"])\n    recs.loc[:, \"recorder\"] = recs.metadata.apply(lambda\
        \ x: x[\"entry\"][\"properties\"][\"sipecam:SerialNumber\"]) \n    recs.loc[:,\
        \ \"deployment\"] = recs.metadata.apply(lambda x: x[\"entry\"][\"path\"][\"\
        name\"].split(\"/audio\")[0].split(\"/\")[-1])\n    recs.loc[:,\"proc_unit\"\
        ] = recs.apply(lambda x: (x[\"node\"], x[\"recorder\"], x[\"deployment\"]),\
        \ axis=1)\n    '''\n\n    _kale_data_saving_block = '''\n    # -----------------------DATA\
        \ SAVING START---------------------------------\n    from kale import marshal\
        \ as _kale_marshal\n    _kale_marshal.set_data_dir(\"/shared_volume/audio/.sndscs_spec_specvid-sipecam-cumulus-node-recorder-deployment-aws.ipynb.kale.marshal.dir\"\
        )\n    _kale_marshal.save(recs, \"recs\")\n    # -----------------------DATA\
        \ SAVING END-----------------------------------\n    '''\n\n    # run the\
        \ code blocks inside a jupyter kernel\n    from kale.common.jputils import\
        \ run_code as _kale_run_code\n    from kale.common.kfputils import \\\n  \
        \      update_uimetadata as _kale_update_uimetadata\n    _kale_blocks = (_kale_pipeline_parameters_block,\n\
        \                    _kale_block1,\n                    _kale_block2,\n  \
        \                  _kale_block3,\n                    _kale_data_saving_block)\n\
        \    _kale_html_artifact = _kale_run_code(_kale_blocks)\n    with open(\"\
        /get_audio_df.html\", \"w\") as f:\n        f.write(_kale_html_artifact)\n\
        \    _kale_update_uimetadata('get_audio_df')\n\n    _kale_mlmdutils.call(\"\
        mark_execution_complete\")\n\ndef _deserialize_bool(s) -> bool:\n    from\
        \ distutils.util import strtobool\n    return strtobool(s) == 1\n\nimport\
        \ argparse\n_parser = argparse.ArgumentParser(prog='Get audio df', description='')\n\
        _parser.add_argument(\"--AUTH-ENDPOINT\", dest=\"AUTH_ENDPOINT\", type=str,\
        \ required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"--BASE-ENDPOINT\"\
        , dest=\"BASE_ENDPOINT\", type=str, required=True, default=argparse.SUPPRESS)\n\
        _parser.add_argument(\"--CUMULO\", dest=\"CUMULO\", type=int, required=True,\
        \ default=argparse.SUPPRESS)\n_parser.add_argument(\"--LIMIT\", dest=\"LIMIT\"\
        , type=_deserialize_bool, required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"\
        --PAGESIZE\", dest=\"PAGESIZE\", type=int, required=True, default=argparse.SUPPRESS)\n\
        _parser.add_argument(\"--SAMPLERATE\", dest=\"SAMPLERATE\", type=float, required=True,\
        \ default=argparse.SUPPRESS)\n_parsed_args = vars(_parser.parse_args())\n\n\
        _outputs = get_audio_df(**_parsed_args)\n"
      image: sipecam/audio-dgpi-kale-tensorflow-yuntu-dask-cert:0.6.1_dev
      securityContext: {runAsUser: 0}
      volumeMounts:
      - {mountPath: /shared_volume, name: pvolume-ef6fe65091618f865041935b363277953274adf6b420fd4a7b8277d}
      workingDir: //shared_volume/audio
    inputs:
      parameters:
      - {name: AUTH_ENDPOINT}
      - {name: BASE_ENDPOINT}
      - {name: CUMULO}
      - {name: LIMIT}
      - {name: PAGESIZE}
      - {name: SAMPLERATE}
      - {name: vol_shared_volume}
    outputs:
      artifacts:
      - {name: mlpipeline-ui-metadata, path: /tmp/mlpipeline-ui-metadata.json}
      - {name: get_audio_df, path: /get_audio_df.html}
    metadata:
      annotations: {kubeflow-kale.org/dependent-templates: '[]', pipelines.kubeflow.org/component_spec: '{"implementation":
          {"container": {"args": ["--AUTH-ENDPOINT", {"inputValue": "AUTH_ENDPOINT"},
          "--BASE-ENDPOINT", {"inputValue": "BASE_ENDPOINT"}, "--CUMULO", {"inputValue":
          "CUMULO"}, "--LIMIT", {"inputValue": "LIMIT"}, "--PAGESIZE", {"inputValue":
          "PAGESIZE"}, "--SAMPLERATE", {"inputValue": "SAMPLERATE"}], "command": ["sh",
          "-ec", "program_path=$(mktemp)\nprintf \"%s\" \"$0\" > \"$program_path\"\npython3
          -u \"$program_path\" \"$@\"\n", "def get_audio_df(AUTH_ENDPOINT, BASE_ENDPOINT,
          CUMULO, LIMIT, PAGESIZE, SAMPLERATE):\n    _kale_pipeline_parameters_block
          = ''''''\n    AUTH_ENDPOINT = \"{}\"\n    BASE_ENDPOINT = \"{}\"\n    CUMULO
          = {}\n    LIMIT = {}\n    PAGESIZE = {}\n    SAMPLERATE = {}\n    ''''''.format(AUTH_ENDPOINT,
          BASE_ENDPOINT, CUMULO, LIMIT, PAGESIZE, SAMPLERATE)\n\n    from kale.common
          import mlmdutils as _kale_mlmdutils\n    _kale_mlmdutils.init_metadata()\n\n    _kale_block1
          = ''''''\n    import base64\n    import datetime\n    import glob\n    import
          hashlib\n    import io\n    import itertools\n    import json\n    import
          matplotlib.pyplot as plt\n    import multiprocessing \n    import numpy
          as np\n    import os\n    import pandas as pd\n    import psutil\n    import
          requests\n    import shutil\n    import subprocess\n    import time\n    import
          warnings\n\n    from dask.distributed import Client, LocalCluster\n    from
          datetime import timedelta\n    from dotenv import load_dotenv\n    from
          matplotlib import cm\n    from moviepy.editor import concatenate, VideoFileClip,
          AudioFileClip\n    from moviepy.audio.AudioClip import AudioArrayClip\n    from
          moviepy.video.VideoClip import ImageClip\n    from os.path import exists
          as file_exists\n    from PIL import Image\n    from skimage.transform import
          resize\n\n    from yuntu import Audio\n    from yuntu.soundscape.utils import
          aware_time\n    from yuntu.collection.methods import collection\n    from
          yuntu.soundscape.hashers.crono import DEFAULT_HASHER_CONFIG\n    from yuntu.soundscape.processors.indices.direct
          import ICOMPLEXITY, TAIL\n    from yuntu.soundscape.pipelines.build_soundscape
          import CronoSoundscape, HASHER_CONFIG\n    ''''''\n\n    _kale_block2 =
          ''''''\n    def audio2video(audio_id,\n                    audio_df,\n                    save_path_folder,\n                    product_spectrum,\n                    cumulus,\n                    abs_start=None,\n                    fps=60,\n                    spec_configs={''hop_length'':
          512, ''n_fft'': 1024, ''window_function'': ''hann''},\n                    rate=24,\n                    frame_duration=3.0,\n                    min_freq=0,\n                    max_freq=None,\n                    cmap=\"Greys\",\n                    figsize=(5,
          8),\n                    dpi=100,\n                    bands=None):\n        \\''\\''\\''Takes
          and audio object and produces a mp4 video of the spectrogram with audio\\''\\''\\''\n\n        sub_audio_df
          = audio_df[audio_df[\"id\"]==audio_id]\n        id_audio = sub_audio_df[''id''].values[0]\n        node
          = sub_audio_df[''node''].values[0]\n        recorder = sub_audio_df[''recorder''].values[0]\n        deployment
          = sub_audio_df[''deployment''].values[0]\n        audio = sub_audio_df.audio[0]\n\n        colormap
          = cm.get_cmap(cmap)\n        duration = audio.duration\n        step = 1/rate\n        start
          = -(frame_duration/2.0)\n        stop = start + frame_duration\n        clips
          = []\n        last_stop = None\n\n        if max_freq is None:\n            max_freq
          = audio.samplerate / 2.0\n\n        if min_freq is None:\n            min_freq
          = 0\n\n        with audio.features.db_spectrogram(**spec_configs) as spec:\n            min_spec
          = np.amin(spec)\n            max_spec = np.amax(spec)\n            spec_range
          = (max_spec-min_spec)\n\n            while stop <= duration+(frame_duration/2.0):\n                clip
          = produce_clip(spec, frame_duration, min_freq, max_freq, start, stop, step,
          abs_start, colormap,\n                                    min_spec, spec_range,
          figsize, dpi, bands=bands)\n                clips.append(clip)\n\n                if
          start + step + frame_duration > duration:\n                    last_stop
          = stop\n\n                start = start + step\n                stop = start
          + frame_duration\n\n        video = concatenate(clips)\n        # edaudio
          = AudioArrayClip(audio_array, fps=audio.samplerate)\n        edaudio = AudioFileClip(audio.path).set_end(audio.duration)\n        video
          = video.set_audio(edaudio)\n        file_path = os.path.join(save_path_folder,
          f\"{audio_id}.mp4\")\n        video.write_videofile(file_path, fps=fps)\n\n        save_metadata_videoclip(audio_id,
          product_spectrum,\n                      save_path_folder, cumulus, node,
          recorder, deployment, 0.0, audio.duration)\n        video.close()\n        edaudio.close()\n\n        for
          c in clips:\n            c.close()\n\n    def change_type_sipecam_sc(session,
          root_folder_id, path, file_type, node_type):\n        if file_type == \"sequence.png\":\n            metadata_name
          = \"soundscape_seq_metadata.json\"\n            aggr_type = \"None\"\n        elif
          file_type == \"mean_soundscape.png\":\n            metadata_name = \"mean_soundscape_metadata.json\"\n            aggr_type
          = \"Mean\"\n        elif file_type ==  \"std_soundscape.png\":\n            metadata_name
          = \"std_soundscape_metadata.json\" \n            aggr_type = \"Standard
          deviation\"\n        elif file_type == \"hashed_soundscape.parquet\":\n            metadata_name
          = \"soundscape_metadata.json\" \n            aggr_type = \"None\"\n        elif
          \".png\" in file_type and (file_type not in [\"sequence.png\", \"mean_soundscape.png\",
          \"std_soundscape.png\"]):\n            metadata_name = file_type.split(\".\")[0]
          + \"_spectrogram_metadata.json\"\n            aggr_type = \"Null\"\n        elif
          \".mp4\" in file_type and (file_type not in [\"sequence.png\", \"mean_soundscape.png\",
          \"std_soundscape.png\"]):\n            metadata_name = file_type.split(\".\")[0]
          + \"_spectrogram_video_metadata.json\"\n            aggr_type = \"Null\"\n\n        try:\n            semi_path
          = path.split(\"soundscapes/\")[-1]\n            semi_path_file = os.path.join(semi_path,
          file_type)\n            local_path_file_metadata = os.path.join(path, metadata_name)\n            print(f\"Changing
          type for {os.path.join(semi_path)}\")\n            alfresco_path = os.path.join(\"/Company
          Home/Sites/sipecam-soundscape/documentLibrary/\", semi_path)\n\n            response
          = session.get(\n                os.getenv(\"ALFRESCO_URL\")\n                +
          BASE_ENDPOINT\n                + \"/nodes/\"\n                + root_folder_id\n                +
          \"/children?relativePath=\"+semi_path+\"&include=aspectNames&skipCount=0\"\n            )        \n            #
          if request is successful then continue\n            if response.status_code
          == 200:\n\n                data_file = open(local_path_file_metadata)\n                data_json
          = json.load(data_file)\n                response_entries = response.json()[\"list\"][\"entries\"]\n\n                for
          entry in response_entries:\n                    if entry[''entry''][''name'']==file_type
          and entry[''entry''][''isFile'']:\n                        prop_dict = {}\n\n                        if
          entry[''entry''][''name'']==file_type:\n\n                            if
          entry[''entry''][''name''] in [\"sequence.png\", \"mean_soundscape.png\",
          \"std_soundscape.png\"]:\n                                prop_dict[\"soundscape:CumulusName\"]
          = str(data_json[\"CumulusName\"])\n                                prop_dict[\"soundscape:DateDeployment\"]
          = data_json[\"DateDeployment\"]\n                                prop_dict[\"soundscape:NodeCategoryIntegrity\"]
          = str(data_json[\"NodeCategoryIntegrity\"])\n                                prop_dict[\"soundscape:NomenclatureNode\"]
          = str(data_json[\"NomenclatureNode\"])\n                                prop_dict[\"soundscape:SerialNumber\"]
          = str(data_json[\"SerialNumber\"])\n                                prop_dict[\"soundscape:aggr\"]
          = str(aggr_type)\n                                prop_dict[\"soundscape:cycle_config_aware_start\"]
          = str(data_json[\"product_configs\"][''hasher_config''][''kwargs''][''aware_start''])\n                                prop_dict[\"soundscape:cycle_config_start_format\"]
          = str(data_json[\"product_configs\"][''hasher_config''][''kwargs''][''start_format''])\n                                prop_dict[\"soundscape:cycle_config_start_time\"]
          =  datetime.datetime.strptime(data_json[\"product_configs\"][''hasher_config''][''kwargs''][''start_time''],
          \n                                                                                                        \"%Y-%m-%d
          %H:%M:%S\").strftime(\"%Y-%m-%dT%H:%M:%S.%f%z\")\n                                prop_dict[\"soundscape:cycle_config_start_tzone\"]
          = str(data_json[\"product_configs\"][''hasher_config''][''kwargs''][''start_tzone''])\n                                prop_dict[\"soundscape:cycle_config_time_module\"]
          = int(data_json[\"product_configs\"][''hasher_config''][''kwargs''][''time_module''])\n                                prop_dict[\"soundscape:cycle_config_time_unit\"]
          = str(data_json[\"product_configs\"][''hasher_config''][''kwargs''][''time_unit''])\n                                prop_dict[\"soundscape:cycle_config_time_utc_column\"]
          = str(data_json[\"product_configs\"][''hasher_config''][''kwargs''][''time_utc_column''])\n                                prop_dict[\"soundscape:frequency_bins\"]
          = int(data_json[\"product_configs\"][\"slice_config\"][\"frequency_bins\"])\n                                prop_dict[\"soundscape:frequency_hop\"]
          = int(data_json[\"product_configs\"][\"slice_config\"][\"frequency_hop\"])\n                                prop_dict[\"soundscape:frequency_limits\"]
          = str(data_json[\"product_configs\"][\"slice_config\"][\"frequency_limits\"])\n                                prop_dict[\"soundscape:hash_name\"]
          = str(data_json[\"product_configs\"][\"hash_name\"])\n                                prop_dict[\"soundscape:hop_length\"]
          = int(data_json[\"product_configs\"][\"slice_config\"][\"feature_config\"][\"hop_length\"])\n                                prop_dict[\"soundscape:indices\"]
          =  \", \".join(map(str, data_json[''product_configs''][''indices'']))\n                                prop_dict[\"soundscape:n_fft\"]
          = int(data_json[\"product_configs\"][\"slice_config\"][\"feature_config\"][\"n_fft\"])\n                                prop_dict[\"soundscape:npartitions\"]
          = int(data_json[\"product_configs\"][''npartitions''])\n                                prop_dict[\"soundscape:product_name\"]
          = str(data_json[\"product_name\"])\n                                prop_dict[\"soundscape:product_parent\"]
          = str(data_json[\"product_parent\"])\n                                prop_dict[\"soundscape:product_path\"]
          = str(alfresco_path)\n                                prop_dict[\"soundscape:product_spectrum\"]
          = str(data_json[\"product_spectrum\"])\n                                prop_dict[\"soundscape:slice_config_feature_type\"]
          = str(data_json[\"product_configs\"][\"slice_config\"][\"feature_type\"])\n                                prop_dict[\"soundscape:slice_config_frequency_bins\"]
          = int(data_json[\"product_configs\"][\"slice_config\"][\"frequency_bins\"])\n                                prop_dict[\"soundscape:slice_config_time_unit\"]
          = int(data_json[\"product_configs\"][\"slice_config\"][\"time_unit\"])\n                                prop_dict[\"soundscape:time_hop\"]
          = int(data_json[\"product_configs\"][\"slice_config\"][\"time_hop\"])\n                                prop_dict[\"soundscape:window_function\"]
          = str(data_json[\"product_configs\"][\"slice_config\"][\"feature_config\"][\"window_function\"])  \n\n                            elif
          (\"spectrogram\" or \"video\") in entry[''entry''][''name'']:\n                                prop_dict[\"soundscape:product_name\"]
          = str(data_json[\"product_name\"])\n                                prop_dict[\"soundscape:product_parent\"]
          = str(data_json[\"product_parent\"])\n                                prop_dict[\"soundscape:product_path\"]
          = str(alfresco_path)\n                                prop_dict[\"soundscape:product_spectrum\"]
          = str(data_json[\"product_spectrum\"])\n                                prop_dict[\"soundscape:CumulusName\"]
          = str(data_json[\"CumulusName\"])\n                                prop_dict[\"soundscape:NodeCategoryIntegrity\"]
          = str(data_json[\"NodeCategoryIntegrity\"])\n                                prop_dict[\"soundscape:NomenclatureNode\"]
          = str(data_json[\"NomenclatureNode\"])\n                                prop_dict[\"soundscape:SerialNumber\"]
          = str(data_json[\"SerialNumber\"])\n                                prop_dict[\"soundscape:DateDeployment\"]
          = data_json[\"DateDeployment\"]\n                                prop_dict[\"soundscape:AudioID\"]
          = data_json[\"AudioID\"]\n\n                        aspects = entry[''entry''][''aspectNames'']\n                        data
          = {\"aspectNames\": aspects, \"nodeType\": node_type, \"properties\": prop_dict}\n                        #
          update properties request\n                        update = session.put(\n                            os.getenv(\"ALFRESCO_URL\")\n                            +
          BASE_ENDPOINT\n                            + \"/nodes/\"\n                            +
          entry[''entry''][''id''],\n                            data=json.dumps(data),\n                        )\n\n                        if
          update.status_code == 200:\n                            print(\"Updated
          \" + entry[''entry''][''id''])                    \n\n        except Exception
          as e:\n            print(\"Could not add any aspect to this file: \", e)\n\n    def
          create_results_folder_str(results_dir, cumulo, nodes_list, rec_list, dep_list):
          \n        # results directory\n        os.makedirs(results_dir, exist_ok=True)\n        #
          cumulus subdir\n        cum_subdir = os.path.join(results_dir, str(cumulo))\n        os.makedirs(cum_subdir,
          exist_ok=True)\n        # node subdirs\n        for node in nodes_list:\n            node_subdir
          = os.path.join(cum_subdir, node)\n            os.makedirs(node_subdir, exist_ok=True)\n            #
          recorder subdirs\n            for rec in rec_list:\n                rec_subdir
          = os.path.join(node_subdir, rec)\n                os.makedirs(rec_subdir,
          exist_ok=True)\n                # deployment subdirs\n                for
          dep in dep_list:\n                    dep_subdir = os.path.join(rec_subdir,
          dep)\n                    os.makedirs(dep_subdir, exist_ok=True)\n\n    def
          distance_to_mean(vector, mean):\n        \\''\\''\\''Return euclidean distance
          to mean\\''\\''\\''\n        return np.sqrt(np.sum(np.square(mean - vector)))\n\n    def
          find_subfolders(path_abs):\n        subdir_list = []\n        walk = list(os.walk(path_abs))\n        for
          path, _, _ in walk[::-1]:\n            len_path = path.split(\"/\")\n            if
          len(len_path) == 8:\n                subdir_list.append(path)  \n\n        return
          subdir_list\n\n    def get_audio_ids(soundscape_path, indices, nsamples):\n        df
          = pd.read_parquet(os.path.join(soundscape_path, \"hashed_soundscape.parquet\"))\n\n        df[\"time_raw_hour\"]
          = df[\"time_raw\"].apply(lambda x: datetime.datetime.strptime(x,''%H:%M:%S
          %d/%m/%Y (%z)'').strftime(\"%H\"))\n        hours_list = list(df.time_raw_hour.unique())\n        hours_list.sort(key
          = int)\n\n        with open(os.path.join(soundscape_path, \"soundscape_metadata.json\"))
          as f:\n            metadata = json.load(f)\n            f.close()\n\n        #
          indices = metadata[\"product_configs\"][\"indices\"]\n        # indices
          = [\"EXAG\", \"ICOMPLEXITY\", \"CORE\"]\n        hash_name = metadata[\"product_configs\"][\"hash_name\"]\n        cycle_config
          = metadata[\"product_configs\"][\"hasher_config\"][\"kwargs\"]\n        time_unit
          = cycle_config[\"time_unit\"]\n        zero_t = aware_time(cycle_config[\"start_time\"],
          cycle_config[\"start_tzone\"], cycle_config[\"start_format\"]) \n\n        #
          iterate over hours\n        audio_id_list = []\n        for hour in hours_list:\n            subdf
          = df.query(f\"time_raw_hour == ''{hour}''\")\n            # sample\n            samples_df
          = get_recording_samples(subdf, hash_name, indices, time_unit, zero_t, nsamples=3)\n            unique_crono_hash_list
          = list(samples_df.crono_hash_30m.unique())\n            sub_df = samples_df[samples_df.crono_hash_30m
          == min(unique_crono_hash_list)]\n            audio_id_list += list(sub_df.id.tolist())\n\n        return
          audio_id_list\n\n    def get_recording_samples(df, hash_name, indices, time_unit,
          zero_t, nsamples=5):\n        \\''\\''\\''Return dataframe of ''nsamples''
          samples for each tag in ''hash_name'' column that are closest to the mean
          vector by tag\\''\\''\\''\n        proj_df = df[(df.max_freq <= 10000)]\n        crono_tags
          = proj_df.crono_hash_30m.unique()\n        proj_df.loc[: , f\"{hash_name}_time\"]
          = proj_df[hash_name].apply(lambda x: zero_t + datetime.timedelta(seconds=float(x*time_unit)))\n        vectors
          = vectorize_soundscape(proj_df, hash_name, indices)\n        min_index_vector
          = np.amin(np.stack(list(vectors.index_vector.values)), axis=(0,1))\n        max_index_vector
          = np.amax(np.stack(list(vectors.index_vector.values)), axis=(0,1))\n        index_range
          = (max_index_vector - min_index_vector)\n        vectors.loc[:, \"normalized_index_vector\"]
          = vectors.index_vector.apply(lambda x: (x-min_index_vector)/index_range)\n        all_samples
          = []\n\n        for crono_tag in crono_tags:\n            unit_vectors =
          vectors[vectors[hash_name] == crono_tag]\n            mean_unit_vector =
          unit_vectors.normalized_index_vector.mean()\n            unit_vectors.loc[:,
          \"distance\"] = unit_vectors.normalized_index_vector.apply(lambda x: distance_to_mean(x,
          mean_unit_vector))\n            all_samples.append(unit_vectors.sort_values(by=\"distance\").head(nsamples))\n        return
          pd.concat(all_samples)\n\n    def get_vectors(group, indices):\n        \\''\\''\\''Return
          array of indices by frequency\\''\\''\\''\n        return group.sort_values(by=\"max_freq\")[indices].values\n\n    def
          login():\n        \"\"\"\n        Tries a login to alfresco api and returns
          a session\n        object with credentials \n        Returns: \n            session
          (Session):  A session object to make \n                                requests
          to zendro.\n        \"\"\"\n        try:\n            auth = {\n                \"userId\":
          os.getenv(\"ALFRESCO_USER\"),\n                \"password\": os.getenv(\"ALFRESCO_PASSWORD\"),\n            }\n\n            login
          = requests.post(os.getenv(\"ALFRESCO_URL\") + AUTH_ENDPOINT + \"/tickets\",data=json.dumps(auth))\n\n            base64_login
          = base64.b64encode(bytes(login.json()[\"entry\"][\"id\"], ''utf-8'')).decode()\n\n            #
          se crea un objeto de Session para hacer requests\n            session =
          requests.Session()\n            # se establece bearer token\n            session.headers.update({''Authorization'':
          ''Basic '' + base64_login})\n\n            return session\n        except
          Exception as e:\n            print(\"Login failed: \", e)\n\n    def plot_spectrogram(audio_id,
          audio_df, save_path_folder, spectrum, cumulus):\n        sub_audio_df =
          audio_df[audio_df[\"id\"]==audio_id]\n        node = sub_audio_df[''node''].values[0]\n        recorder
          = sub_audio_df[''recorder''].values[0]\n        deployment = sub_audio_df[''deployment''].values[0]\n        #
          plot\n        fig, ax = plt.subplots(2,1,figsize=(20,10), sharex=True)\n        sub_audio_df.audio[0].plot(ax=ax[0],
          color=''grey'')\n        sub_audio_df.audio[0].features.db_spectrogram().plot(ax=ax[1])\n        ax[0].set_ylabel(''Amplitude'')\n        ax[0].grid(False)\n        ax[1].set_ylabel(''F
          (KHz)'')\n        ax[1].set_xlabel(''Time (seconds)'')\n        fig.text(0.75,
          0.04, f\"Cumulus: {cumulus} - Node: {node} - Recorder: {recorder}\", va=''center'')\n        plt.tight_layout()\n        if
          save_path_folder:\n            file_path = os.path.join(save_path_folder,
          f\"{audio_id}.png\")\n            fig.savefig(file_path)\n        plt.show()\n\n        save_metadata_spectrogram(audio_id,
          spectrum, save_path_folder, \n                                  cumulus,
          node, recorder, deployment, parent=\"Null\")\n\n    def plot_soundscape(soundscape,
          product_type, product_spectrum, sc_config, path, \n                        cumulus,
          node, recorder, deployment, parent, indices, min_freq=None,\n                      figsize=(20,15),
          plt_style=''ggplot''):\n\n        if min_freq:\n            soundscape =
          soundscape[soundscape[''min_freq'']<=min_freq]\n\n        if product_type
          == \"sequence\":\n            file_path = os.path.join(path, \"sequence.png\")\n            #
          product_id = hashlib.md5(file_path.encode(''utf-8'')).hexdigest()\n\n            plt.style.use(plt_style)\n            fig,
          ax = plt.subplots(figsize=figsize)\n            soundscape.sndscape.plot_sequence(rgb=indices,
          time_format=''%Y-%m %H:%M'', ax=ax)\n            plt.xticks(rotation = 90)\n            ax.grid(False)\n            plt.tight_layout()\n            plt.savefig(file_path)
          \n            plt.show()\n            # save metadata\n            save_metadata_sc(product_type,
          product_spectrum, sc_config,\n                      path, cumulus, node,
          recorder, deployment, parent=parent)\n\n        elif product_type == \"standard_deviation\":\n            file_path
          = os.path.join(path, \"std_soundscape.png\")\n            # product_id =
          hashlib.md5(file_path.encode(''utf-8'')).hexdigest()\n\n            plt.style.use(plt_style)\n            fig,
          ax = plt.subplots(figsize=figsize)\n            soundscape.sndscape.plot_cycle(rgb=indices,
          aggr=\"std\", time_format=''%H:%M'', \n                                           xticks=24,
          ax=ax)\n            plt.xticks(rotation = 90)\n            ax.grid(False)\n            plt.tight_layout()
          \n            plt.savefig(file_path)\n            plt.show()\n\n            #
          save metadata\n            save_metadata_sc(product_type, product_spectrum,
          sc_config,\n                      path, cumulus, node, recorder, deployment,
          parent)     \n\n        elif product_type == \"mean\": \n            file_path
          = os.path.join(path, \"mean_soundscape.png\")\n            # product_id
          = hashlib.md5(file_path.encode(''utf-8'')).hexdigest()\n\n            plt.style.use(plt_style)\n            fig,
          ax = plt.subplots(figsize=figsize)\n            soundscape.sndscape.plot_cycle(rgb=indices,
          aggr=\"mean\", time_format=''%H:%M'', \n                                           xticks=24,
          ax=ax)\n            plt.xticks(rotation = 90)\n            ax.grid(False)\n            plt.tight_layout()\n            plt.savefig(file_path)\n            plt.show()\n\n            #
          save metadata\n            save_metadata_sc(product_type, product_spectrum,
          sc_config,\n                      path, cumulus, node, recorder, deployment,
          parent)    \n\n        print(f\"File saved at {file_path}\")\n\n    def
          produce_clip(spec, frame_duration, min_freq, max_freq, start, stop, step,
          abs_start=None, \n                     colormap=cm.get_cmap(\"Greys\"),
          min_spec=0, spec_range=1.0, figsize=(5, 4), \n                     dpi=100,
          bands=None):\n        \\''\\''\\''Takes an individual frame and produces
          an image with references\\''\\''\\''\n        frame = spec.cut_array(start_time=start,
          end_time=stop, min_freq=min_freq, max_freq=max_freq, pad=True)\n        plt.style.use(''dark_background'')\n        frame
          = np.flip((frame - min_spec)/spec_range, axis=0)\n        fig, ax = plt.subplots(figsize=figsize)\n        ax.imshow(frame,
          cmap=colormap, extent=[0, frame_duration, min_freq/1000, max_freq/1000],
          \n                  aspect=\"auto\", vmin = 0, vmax = 1.0)\n\n        if
          bands is not None:\n            band_arr = np.flip(resize(np.expand_dims(bands,
          axis=1), (frame.shape[0], frame.shape[1])), axis=0)\n            ax.imshow(band_arr,
          extent=[0, frame_duration, min_freq/1000, max_freq/1000], aspect=\"auto\",
          vmin = 0, \n                      vmax = 1.0, alpha=0.5)\n\n        ax.tick_params(axis=''both'',
          which=''major'', labelsize=8)\n        ax.tick_params(axis=''both'', which=''minor'',
          labelsize=8)\n        mid = frame_duration/2.0\n        ax.axvline(x=mid,
          color=\"red\")\n        ax.set_ylabel(''F (kHz)'')\n        ax.set_xticks([])\n        ax.set_xticks([],
          minor=True)\n\n        if abs_start is not None:\n            time_text
          = (abs_start + datetime.timedelta(seconds=start+mid)).strftime(''%H:%M:%S.%f'').strip()[:-4]\n            ax.text(mid-0.3,
          -0.6, time_text)\n\n        buf = io.BytesIO()\n        fig.tight_layout()\n        fig.savefig(buf,
          dpi=dpi)\n        buf.seek(0)\n        im = Image.open(buf)\n        im.format
          = \"PNG\"\n        plt.close(fig)\n\n        return ImageClip(np.asarray(im),\n                         duration=step)\n\n    def
          remove_empty_folders(path_abs):\n        walk = list(os.walk(path_abs))\n        for
          path, _, _ in walk[::-1]:\n            if len(os.listdir(path)) == 0:\n                os.rmdir(path)            \n\n    def
          save_metadata_sc(product_type, product_spectrum, sc_config,\n                      path,
          cumulus, node, recorder, deployment, parent=\"Null\"):\n        if product_type
          == \"soundscape\":\n            product_name = \"Soundscape\"\n            file_path
          = os.path.join(path, \"hashed_soundscape.parquet\")\n            metadata_filename
          = os.path.join(path, \"soundscape_metadata.json\")\n        elif product_type
          == \"sequence\":\n            product_name = \"Soundscape sequential plot\"\n            file_path
          = os.path.join(path, \"soundscape_seq.png\")\n            metadata_filename
          = os.path.join(path, \"soundscape_seq_metadata.json\")\n        elif product_type
          == \"standard_deviation\":\n            product_name = \"Soundscape standard
          deviation plot\"\n            file_path = os.path.join(path, \"std_soundscape.png\")\n            metadata_filename
          = os.path.join(path, \"std_soundscape_metadata.json\")\n        elif product_type
          == \"mean\":\n            product_name = \"Soundscape mean plot\"\n            file_path
          = os.path.join(path, \"mean_soundscape.png\")\n            metadata_filename
          = os.path.join(path, \"mean_soundscape_metadata.json\")\n\n        if int(node.split(\"_\")[2])
          == 0:\n            node_category = \"Degradado\"\n        elif int(node.split(\"_\")[2])
          == 1:\n            node_category = \"Integro\"\n\n        metadata = {\n            \"product_parent\":
          parent,\n            \"product_name\": product_name,\n            \"product_configs\":
          sc_config,\n            \"product_path\": file_path,\n            \"product_spectrum\":
          product_spectrum,\n            \"CumulusName\": cumulus,\n            \"NodeCategoryIntegrity\":
          node_category,\n            \"NomenclatureNode\": node,\n            \"SerialNumber\":
          recorder,\n            \"DateDeployment\": deployment\n        }\n\n        with
          open(metadata_filename, ''w'', encoding=''utf-8'') as f:\n            json.dump(metadata,
          f, ensure_ascii=False, indent=4)\n\n    def save_metadata_spectrogram(audio_id,
          product_spectrum,\n                      path, cumulus, node, recorder,
          deployment, parent=\"Null\"):\n        # identifier is being used as audio_id
          in alfresco\n        product_name = \"Spectrogram\"\n        file_path =
          os.path.join(path, f\"{audio_id}.png\")\n        metadata_filename = os.path.join(path,
          f\"{audio_id}_spectrogram_metadata.json\")\n\n        if int(node.split(\"_\")[2])
          == 0:\n            node_category = \"Degradado\"\n        elif int(node.split(\"_\")[2])
          == 1:\n            node_category = \"Integro\"\n\n        metadata = {\n            \"product_parent\":
          parent,\n            \"product_name\": product_name,\n            \"product_path\":
          file_path,\n            \"product_spectrum\": product_spectrum,\n            \"CumulusName\":
          cumulus,\n            \"NodeCategoryIntegrity\": node_category,\n            \"NomenclatureNode\":
          node,\n            \"SerialNumber\": recorder,\n            \"DateDeployment\":
          deployment,\n            \"AudioID\": audio_id\n        }\n        with
          open(metadata_filename, ''w'', encoding=''utf-8'') as f:\n            json.dump(metadata,
          f, ensure_ascii=False, indent=4)\n\n        print(f\"{file_path} saved.\")\n        print(f\"{metadata_filename}
          saved.\")\n\n    def save_metadata_videoclip(audio_id, product_spectrum,
          path, cumulus, node, recorder, \n                                deployment,
          clip_start, clip_end, parent=\"Null\"):\n        # identifier is being used
          as audio_id in alfresco\n        product_name = \"spectrogram_video\"\n        file_path
          = os.path.join(path, f\"{audio_id}.mp4\")\n        metadata_filename = os.path.join(path,
          f\"{audio_id}_spectrogram_video_metadata.json\")\n\n        if int(node.split(\"_\")[2])
          == 0:\n            node_category = \"Degradado\"\n        elif int(node.split(\"_\")[2])
          == 1:\n            node_category = \"Integro\"\n\n        metadata = {\n            \"product_parent\":
          parent,\n            \"product_name\": product_name,\n            \"product_description\":
          \"Spectrogram Video. Time is show in local timezone\",\n            \"product_path\":
          file_path,\n            \"product_spectrum\": product_spectrum,\n            \"CumulusName\":
          cumulus,\n            \"NodeCategoryIntegrity\": node_category,\n            \"NomenclatureNode\":
          node,\n            \"SerialNumber\": recorder,\n            \"DateDeployment\":
          deployment,\n            \"ClipStart\": clip_start,\n            \"ClipEnd\":
          clip_end,\n            \"AudioID\": audio_id\n        }\n\n        with
          open(metadata_filename, ''w'', encoding=''utf-8'') as f:\n            json.dump(metadata,
          f, ensure_ascii=False, indent=4)\n\n        print(f\"{file_path} saved.\")\n        print(f\"{metadata_filename}
          saved.\")\n\n    def upload(session, node_id, data, file):\n        \"\"\"\n        Uploads
          a file to a specific folder.\n        Parameters:\n            session (Session):          A
          session object to make\n                                        requests
          to alfresco.\n            node_id (string):           Node id to which the
          file is going to be created\n            data (dict):                Dict
          that contains file options\n            file (object):              File
          to upload\n\n        Returns:\n            (list):     A list containing
          status code and status data\n        \"\"\"\n\n        try:\n            response
          = session.post(os.getenv(\"ALFRESCO_URL\")\n                        + BASE_ENDPOINT
          + \"/nodes/\" + node_id + \"/children\",\n                        data =
          data,\n                        files = file\n                        )\n\n            return
          [response.json(), response.status_code];\n        except Exception as e:
          \n            print(\"File \" + data[\"name\"] + \" could not be uploaded:
          \", e)\n\n    def upload_files(file_patterns, session, node_id, dir_path,
          recursive, file_identifier=\"\"):\n        \"\"\"\n        Uploads the files
          stored in a specific dir\n        to alfresco\n        Parameters:\n            session
          (Session):          A session object to make\n                                        requests
          to alfresco.\n            node_id (string):           Node id to which the
          file is going to be created\n            dir_path (string):          The
          name and path of the dir where files are stored\n            recursive (boolean):        A
          boolean to know if upload  must be recursive\n                                        in
          the specifed dir, and should preserve the\n                                        structure
          of dirs inside.\n            file_identifier (string):   File identifier
          for all files inside a dir\n        Returns:\n            (string):           Returns
          the info of recent created site.\n        \"\"\"\n\n        if recursive:\n            expression
          = \"/**/*\"\n        else:\n            expression = \"/*\"\n\n        files_in_dir
          = list(\n            itertools.chain.from_iterable(\n                glob.iglob(dir_path
          + expression + pattern, recursive=recursive)\n                for pattern
          in file_patterns\n            )\n        )\n        filename = \"logs/upload_log\"
          + dir_path.replace(''/'',''-'') + ''.txt''\n\n        os.makedirs(os.path.dirname(filename),
          exist_ok=True)\n\n        total_files = len(files_in_dir)\n        starttime
          = time.time()\n\n        try:\n            files_uploaded = []\n            for
          idx, file_with_path in enumerate(files_in_dir):\n\n                # total
          time since last login or script start\n                total_time = round((time.time()
          - starttime), 2)\n\n                if total_time > 2400:\n                    \"\"\"\n                    if
          total time is bigger than 2400\n                    or 40 minutes relogin
          to avoid ticket\n                    expiration\n                    \"\"\"\n                    time.sleep(5)\n\n                    print(\"Re-logging
          in to alfresco...\")\n\n                    session = login.login()\n                    #
          restart time\n                    starttime = time.time()\n                    time.sleep(5)\n                    print(\"Login
          sucessful, continuing upload\\\\n\")\n\n                len_of_path = len(file_with_path.split(\"/\"))\n                name_of_file
          = file_with_path.split(\"/\")[len_of_path - 1]\n                root_dir_path
          = file_with_path.replace(dir_path, \"\").replace(\n                    file_with_path.split(\"/\")[len_of_path
          - 1], \"\"\n                )\n\n                data = {\n                    \"name\":
          (\n                        name_of_file[0 : len(name_of_file) - 4]\n                        +
          file_identifier\n                        + name_of_file[len(name_of_file)
          - 4 : len(name_of_file)]\n                    ),\n                    \"nodeType\":
          \"cm:content\",\n                }\n\n                data[\"relativePath\"]
          = root_dir_path\n\n                data[\"properties\"] = {\n                    \"cm:title\":
          (\n                        name_of_file[0 : len(name_of_file) - 4]\n                        +
          file_identifier\n                        + name_of_file[len(name_of_file)
          - 4 : len(name_of_file)]\n                    )\n                }\n\n                print(\"Uploading
          \" + data[\"name\"] + \" file...\")\n\n                files = {\"filedata\":
          open(file_with_path, \"rb\")}\n                upload_response = upload(session,
          node_id, data, files)\n                if upload_response[1] and upload_response[1]
          == 201:\n                    files_uploaded.append(upload_response[0])\n                    print(\"Uploaded
          \" + data[\"name\"])\n\n                    filename = \"logs/upload_log\"
          + dir_path.replace(''/'',''-'') + ''.txt''\n                    with open(filename,
          ''a'') as log_file:\n                        log_file.writelines(\"%s\\\\n\"
          % file_with_path)\n\n                elif upload_response[1] and upload_response[1]
          == 409:\n                    if \"already exists\" in upload_response[0][\"error\"][\"errorKey\"]:\n                        print(\"File
          \" + data[\"name\"] + \" already uploaded\")\n\n                else:\n                    print(\"An
          error ocurred, file \" + data[\"name\"] + \" cannot be uploaded\")\n\n                print(\"Uploaded
          file \" + str(idx + 1) + \" of \" + str(total_files))\n                print(\"\\\\n\\\\n\")\n\n            return
          files_uploaded\n        except Exception as e:\n            print(\"An error
          ocurred in file upload: \", e)\n\n    def vectorize_soundscape(df, hash_name,
          indices):\n        \\''\\''\\''Return dataframe with array column containing
          indices by frequency\\''\\''\\''\n        return (df\n                .groupby(by=[\"id\",
          hash_name, \"start_time\", \"end_time\"])\n                .apply(get_vectors,
          indices)\n                .reset_index()\n                .rename(columns={0:\"index_vector\"}))\n    ''''''\n\n    _kale_block3
          = ''''''\n    load_dotenv()\n    DB_CONFIG = {\n        ''provider'': ''alfresco'',\n        ''config'':
          {\n            ''api_url'': ''https://api.conabio.gob.mx/alfresco'',\n            ''page_size'':
          PAGESIZE,\n            ''api_key'': os.getenv(\"X_API_KEY\"),\n            ''base_filter'':
          \"+TYPE: \\\\\"sipecam:audio\\\\\" AND -TYPE: \\\\\"dummyType\\\\\"\",\n            ''recording_parser'':
          {\"path\": \"/shared_volume/audio/utils.py\",\n                                 \"object_name\":
          \"parser\"}\n        }\n    }\n\n    COL_CONFIG = {\n        \"col_type\":
          \"alfresco\",\n        \"db_config\": DB_CONFIG\n    }\n\n    col = collection(**COL_CONFIG)\n    query
          = f\"(sipecam:CumulusName:\\\\\"{CUMULO}\\\\\") AND (sipecam:SampleRate:{SAMPLERATE})\"\n\n    if
          LIMIT:\n        recs = col.get_recording_dataframe(query, limit=LIMIT, with_metadata
          = True, with_geometry = False)\n    else:\n        recs = col.get_recording_dataframe(query,
          with_metadata = True, with_geometry = False)\n\n    # include filtering
          columns for processing units\n    recs.loc[:, \"node\"] = recs.metadata.apply(lambda
          x: x[\"entry\"][\"properties\"][\"sipecam:NomenclatureNode\"])\n    recs.loc[:,
          \"recorder\"] = recs.metadata.apply(lambda x: x[\"entry\"][\"properties\"][\"sipecam:SerialNumber\"])
          \n    recs.loc[:, \"deployment\"] = recs.metadata.apply(lambda x: x[\"entry\"][\"path\"][\"name\"].split(\"/audio\")[0].split(\"/\")[-1])\n    recs.loc[:,\"proc_unit\"]
          = recs.apply(lambda x: (x[\"node\"], x[\"recorder\"], x[\"deployment\"]),
          axis=1)\n    ''''''\n\n    _kale_data_saving_block = ''''''\n    # -----------------------DATA
          SAVING START---------------------------------\n    from kale import marshal
          as _kale_marshal\n    _kale_marshal.set_data_dir(\"/shared_volume/audio/.sndscs_spec_specvid-sipecam-cumulus-node-recorder-deployment-aws.ipynb.kale.marshal.dir\")\n    _kale_marshal.save(recs,
          \"recs\")\n    # -----------------------DATA SAVING END-----------------------------------\n    ''''''\n\n    #
          run the code blocks inside a jupyter kernel\n    from kale.common.jputils
          import run_code as _kale_run_code\n    from kale.common.kfputils import
          \\\n        update_uimetadata as _kale_update_uimetadata\n    _kale_blocks
          = (_kale_pipeline_parameters_block,\n                    _kale_block1,\n                    _kale_block2,\n                    _kale_block3,\n                    _kale_data_saving_block)\n    _kale_html_artifact
          = _kale_run_code(_kale_blocks)\n    with open(\"/get_audio_df.html\", \"w\")
          as f:\n        f.write(_kale_html_artifact)\n    _kale_update_uimetadata(''get_audio_df'')\n\n    _kale_mlmdutils.call(\"mark_execution_complete\")\n\ndef
          _deserialize_bool(s) -> bool:\n    from distutils.util import strtobool\n    return
          strtobool(s) == 1\n\nimport argparse\n_parser = argparse.ArgumentParser(prog=''Get
          audio df'', description='''')\n_parser.add_argument(\"--AUTH-ENDPOINT\",
          dest=\"AUTH_ENDPOINT\", type=str, required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"--BASE-ENDPOINT\",
          dest=\"BASE_ENDPOINT\", type=str, required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"--CUMULO\",
          dest=\"CUMULO\", type=int, required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"--LIMIT\",
          dest=\"LIMIT\", type=_deserialize_bool, required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"--PAGESIZE\",
          dest=\"PAGESIZE\", type=int, required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"--SAMPLERATE\",
          dest=\"SAMPLERATE\", type=float, required=True, default=argparse.SUPPRESS)\n_parsed_args
          = vars(_parser.parse_args())\n\n_outputs = get_audio_df(**_parsed_args)\n"],
          "image": "sipecam/audio-dgpi-kale-tensorflow-yuntu-dask-cert:0.6.1_dev"}},
          "inputs": [{"name": "AUTH_ENDPOINT", "type": "String"}, {"name": "BASE_ENDPOINT",
          "type": "String"}, {"name": "CUMULO", "type": "Integer"}, {"name": "LIMIT",
          "type": "Boolean"}, {"name": "PAGESIZE", "type": "Integer"}, {"name": "SAMPLERATE",
          "type": "Float"}], "name": "Get audio df"}', pipelines.kubeflow.org/component_ref: '{}',
        pipelines.kubeflow.org/arguments.parameters: '{"AUTH_ENDPOINT": "{{inputs.parameters.AUTH_ENDPOINT}}",
          "BASE_ENDPOINT": "{{inputs.parameters.BASE_ENDPOINT}}", "CUMULO": "{{inputs.parameters.CUMULO}}",
          "LIMIT": "{{inputs.parameters.LIMIT}}", "PAGESIZE": "{{inputs.parameters.PAGESIZE}}",
          "SAMPLERATE": "{{inputs.parameters.SAMPLERATE}}"}'}
      labels:
        pipelines.kubeflow.org/metadata_written: "true"
        pipelines.kubeflow.org/kfp_sdk_version: 1.8.11
        pipelines.kubeflow.org/pipeline-sdk-type: kfp
        pipelines.kubeflow.org/enable_caching: "true"
    volumes:
    - name: pvolume-ef6fe65091618f865041935b363277953274adf6b420fd4a7b8277d
      persistentVolumeClaim: {claimName: '{{inputs.parameters.vol_shared_volume}}'}
  - name: sound-scape-nod-rec-dep-rs7g6
    inputs:
      parameters:
      - {name: ALFRESCO_NODE_ID}
      - {name: AUTH_ENDPOINT}
      - {name: BASE_ENDPOINT}
      - {name: BLUE_IDX}
      - {name: CUMULO}
      - {name: FREQUENCY_BINS}
      - {name: FREQUENCY_LIMITS_LB}
      - {name: FREQUENCY_LIMITS_UB}
      - {name: GREEN_IDX}
      - {name: HASHER_TIME_MODULE}
      - {name: HASHER_TIME_UNIT}
      - {name: HASH_NAME}
      - {name: LIMIT}
      - {name: MIN_FREQ_SC}
      - {name: PAGESIZE}
      - {name: RED_IDX}
      - {name: RESULTS_DIR}
      - {name: SAMPLERATE}
      - {name: SPECTRUM}
      - {name: THREADS_PER_WORKER}
      - {name: TIME_UNIT}
      - {name: VIDS_PER_HOUR}
      - {name: WORK_DIR_PIPELINE}
      - {name: vol_shared_volume}
    dag:
      tasks:
      - name: compute-soundscapes
        template: compute-soundscapes
        dependencies: [create-results-dirstruct, get-audio-df]
        arguments:
          parameters:
          - {name: AUTH_ENDPOINT, value: '{{inputs.parameters.AUTH_ENDPOINT}}'}
          - {name: BASE_ENDPOINT, value: '{{inputs.parameters.BASE_ENDPOINT}}'}
          - {name: BLUE_IDX, value: '{{inputs.parameters.BLUE_IDX}}'}
          - {name: CUMULO, value: '{{inputs.parameters.CUMULO}}'}
          - {name: FREQUENCY_BINS, value: '{{inputs.parameters.FREQUENCY_BINS}}'}
          - {name: FREQUENCY_LIMITS_LB, value: '{{inputs.parameters.FREQUENCY_LIMITS_LB}}'}
          - {name: FREQUENCY_LIMITS_UB, value: '{{inputs.parameters.FREQUENCY_LIMITS_UB}}'}
          - {name: GREEN_IDX, value: '{{inputs.parameters.GREEN_IDX}}'}
          - {name: HASHER_TIME_MODULE, value: '{{inputs.parameters.HASHER_TIME_MODULE}}'}
          - {name: HASHER_TIME_UNIT, value: '{{inputs.parameters.HASHER_TIME_UNIT}}'}
          - {name: HASH_NAME, value: '{{inputs.parameters.HASH_NAME}}'}
          - {name: MIN_FREQ_SC, value: '{{inputs.parameters.MIN_FREQ_SC}}'}
          - {name: RED_IDX, value: '{{inputs.parameters.RED_IDX}}'}
          - {name: RESULTS_DIR, value: '{{inputs.parameters.RESULTS_DIR}}'}
          - {name: SPECTRUM, value: '{{inputs.parameters.SPECTRUM}}'}
          - {name: THREADS_PER_WORKER, value: '{{inputs.parameters.THREADS_PER_WORKER}}'}
          - {name: TIME_UNIT, value: '{{inputs.parameters.TIME_UNIT}}'}
          - {name: WORK_DIR_PIPELINE, value: '{{inputs.parameters.WORK_DIR_PIPELINE}}'}
          - {name: vol_shared_volume, value: '{{inputs.parameters.vol_shared_volume}}'}
      - name: create-results-dirstruct
        template: create-results-dirstruct
        dependencies: [get-audio-df]
        arguments:
          parameters:
          - {name: AUTH_ENDPOINT, value: '{{inputs.parameters.AUTH_ENDPOINT}}'}
          - {name: BASE_ENDPOINT, value: '{{inputs.parameters.BASE_ENDPOINT}}'}
          - {name: CUMULO, value: '{{inputs.parameters.CUMULO}}'}
          - {name: RESULTS_DIR, value: '{{inputs.parameters.RESULTS_DIR}}'}
          - {name: vol_shared_volume, value: '{{inputs.parameters.vol_shared_volume}}'}
      - name: get-audio-df
        template: get-audio-df
        arguments:
          parameters:
          - {name: AUTH_ENDPOINT, value: '{{inputs.parameters.AUTH_ENDPOINT}}'}
          - {name: BASE_ENDPOINT, value: '{{inputs.parameters.BASE_ENDPOINT}}'}
          - {name: CUMULO, value: '{{inputs.parameters.CUMULO}}'}
          - {name: LIMIT, value: '{{inputs.parameters.LIMIT}}'}
          - {name: PAGESIZE, value: '{{inputs.parameters.PAGESIZE}}'}
          - {name: SAMPLERATE, value: '{{inputs.parameters.SAMPLERATE}}'}
          - {name: vol_shared_volume, value: '{{inputs.parameters.vol_shared_volume}}'}
      - name: spec-n-specvid
        template: spec-n-specvid
        dependencies: [compute-soundscapes]
        arguments:
          parameters:
          - {name: AUTH_ENDPOINT, value: '{{inputs.parameters.AUTH_ENDPOINT}}'}
          - {name: BASE_ENDPOINT, value: '{{inputs.parameters.BASE_ENDPOINT}}'}
          - {name: BLUE_IDX, value: '{{inputs.parameters.BLUE_IDX}}'}
          - {name: CUMULO, value: '{{inputs.parameters.CUMULO}}'}
          - {name: GREEN_IDX, value: '{{inputs.parameters.GREEN_IDX}}'}
          - {name: RED_IDX, value: '{{inputs.parameters.RED_IDX}}'}
          - {name: RESULTS_DIR, value: '{{inputs.parameters.RESULTS_DIR}}'}
          - {name: SPECTRUM, value: '{{inputs.parameters.SPECTRUM}}'}
          - {name: VIDS_PER_HOUR, value: '{{inputs.parameters.VIDS_PER_HOUR}}'}
          - {name: vol_shared_volume, value: '{{inputs.parameters.vol_shared_volume}}'}
      - name: upload-alfresco-model-data
        template: upload-alfresco-model-data
        dependencies: [upload-to-alfresco]
        arguments:
          parameters:
          - {name: ALFRESCO_NODE_ID, value: '{{inputs.parameters.ALFRESCO_NODE_ID}}'}
          - {name: AUTH_ENDPOINT, value: '{{inputs.parameters.AUTH_ENDPOINT}}'}
          - {name: BASE_ENDPOINT, value: '{{inputs.parameters.BASE_ENDPOINT}}'}
          - {name: vol_shared_volume, value: '{{inputs.parameters.vol_shared_volume}}'}
      - name: upload-to-alfresco
        template: upload-to-alfresco
        dependencies: [spec-n-specvid]
        arguments:
          parameters:
          - {name: ALFRESCO_NODE_ID, value: '{{inputs.parameters.ALFRESCO_NODE_ID}}'}
          - {name: AUTH_ENDPOINT, value: '{{inputs.parameters.AUTH_ENDPOINT}}'}
          - {name: BASE_ENDPOINT, value: '{{inputs.parameters.BASE_ENDPOINT}}'}
          - {name: RESULTS_DIR, value: '{{inputs.parameters.RESULTS_DIR}}'}
          - {name: vol_shared_volume, value: '{{inputs.parameters.vol_shared_volume}}'}
  - name: spec-n-specvid
    container:
      args: [--AUTH-ENDPOINT, '{{inputs.parameters.AUTH_ENDPOINT}}', --BASE-ENDPOINT,
        '{{inputs.parameters.BASE_ENDPOINT}}', --BLUE-IDX, '{{inputs.parameters.BLUE_IDX}}',
        --CUMULO, '{{inputs.parameters.CUMULO}}', --GREEN-IDX, '{{inputs.parameters.GREEN_IDX}}',
        --RED-IDX, '{{inputs.parameters.RED_IDX}}', --RESULTS-DIR, '{{inputs.parameters.RESULTS_DIR}}',
        --SPECTRUM, '{{inputs.parameters.SPECTRUM}}', --VIDS-PER-HOUR, '{{inputs.parameters.VIDS_PER_HOUR}}']
      command:
      - sh
      - -ec
      - |
        program_path=$(mktemp)
        printf "%s" "$0" > "$program_path"
        python3 -u "$program_path" "$@"
      - "def spec_n_specvid(AUTH_ENDPOINT, BASE_ENDPOINT, BLUE_IDX, CUMULO, GREEN_IDX,\
        \ RED_IDX, RESULTS_DIR, SPECTRUM, VIDS_PER_HOUR):\n    _kale_pipeline_parameters_block\
        \ = '''\n    AUTH_ENDPOINT = \"{}\"\n    BASE_ENDPOINT = \"{}\"\n    BLUE_IDX\
        \ = \"{}\"\n    CUMULO = {}\n    GREEN_IDX = \"{}\"\n    RED_IDX = \"{}\"\n\
        \    RESULTS_DIR = \"{}\"\n    SPECTRUM = \"{}\"\n    VIDS_PER_HOUR = {}\n\
        \    '''.format(AUTH_ENDPOINT, BASE_ENDPOINT, BLUE_IDX, CUMULO, GREEN_IDX,\
        \ RED_IDX, RESULTS_DIR, SPECTRUM, VIDS_PER_HOUR)\n\n    from kale.common import\
        \ mlmdutils as _kale_mlmdutils\n    _kale_mlmdutils.init_metadata()\n\n  \
        \  _kale_data_loading_block = '''\n    # -----------------------DATA LOADING\
        \ START--------------------------------\n    from kale import marshal as _kale_marshal\n\
        \    _kale_marshal.set_data_dir(\"/shared_volume/audio/.sndscs_spec_specvid-sipecam-cumulus-node-recorder-deployment-aws.ipynb.kale.marshal.dir\"\
        )\n    recs = _kale_marshal.load(\"recs\")\n    # -----------------------DATA\
        \ LOADING END----------------------------------\n    '''\n\n    _kale_block1\
        \ = '''\n    import base64\n    import datetime\n    import glob\n    import\
        \ hashlib\n    import io\n    import itertools\n    import json\n    import\
        \ matplotlib.pyplot as plt\n    import multiprocessing \n    import numpy\
        \ as np\n    import os\n    import pandas as pd\n    import psutil\n    import\
        \ requests\n    import shutil\n    import subprocess\n    import time\n  \
        \  import warnings\n\n    from dask.distributed import Client, LocalCluster\n\
        \    from datetime import timedelta\n    from dotenv import load_dotenv\n\
        \    from matplotlib import cm\n    from moviepy.editor import concatenate,\
        \ VideoFileClip, AudioFileClip\n    from moviepy.audio.AudioClip import AudioArrayClip\n\
        \    from moviepy.video.VideoClip import ImageClip\n    from os.path import\
        \ exists as file_exists\n    from PIL import Image\n    from skimage.transform\
        \ import resize\n\n    from yuntu import Audio\n    from yuntu.soundscape.utils\
        \ import aware_time\n    from yuntu.collection.methods import collection\n\
        \    from yuntu.soundscape.hashers.crono import DEFAULT_HASHER_CONFIG\n  \
        \  from yuntu.soundscape.processors.indices.direct import ICOMPLEXITY, TAIL\n\
        \    from yuntu.soundscape.pipelines.build_soundscape import CronoSoundscape,\
        \ HASHER_CONFIG\n    '''\n\n    _kale_block2 = '''\n    def audio2video(audio_id,\n\
        \                    audio_df,\n                    save_path_folder,\n  \
        \                  product_spectrum,\n                    cumulus,\n     \
        \               abs_start=None,\n                    fps=60,\n           \
        \         spec_configs={'hop_length': 512, 'n_fft': 1024, 'window_function':\
        \ 'hann'},\n                    rate=24,\n                    frame_duration=3.0,\n\
        \                    min_freq=0,\n                    max_freq=None,\n   \
        \                 cmap=\"Greys\",\n                    figsize=(5, 8),\n \
        \                   dpi=100,\n                    bands=None):\n        \\\
        '\\'\\'Takes and audio object and produces a mp4 video of the spectrogram\
        \ with audio\\'\\'\\'\n\n        sub_audio_df = audio_df[audio_df[\"id\"]==audio_id]\n\
        \        id_audio = sub_audio_df['id'].values[0]\n        node = sub_audio_df['node'].values[0]\n\
        \        recorder = sub_audio_df['recorder'].values[0]\n        deployment\
        \ = sub_audio_df['deployment'].values[0]\n        audio = sub_audio_df.audio[0]\n\
        \n        colormap = cm.get_cmap(cmap)\n        duration = audio.duration\n\
        \        step = 1/rate\n        start = -(frame_duration/2.0)\n        stop\
        \ = start + frame_duration\n        clips = []\n        last_stop = None\n\
        \n        if max_freq is None:\n            max_freq = audio.samplerate /\
        \ 2.0\n\n        if min_freq is None:\n            min_freq = 0\n\n      \
        \  with audio.features.db_spectrogram(**spec_configs) as spec:\n         \
        \   min_spec = np.amin(spec)\n            max_spec = np.amax(spec)\n     \
        \       spec_range = (max_spec-min_spec)\n\n            while stop <= duration+(frame_duration/2.0):\n\
        \                clip = produce_clip(spec, frame_duration, min_freq, max_freq,\
        \ start, stop, step, abs_start, colormap,\n                              \
        \      min_spec, spec_range, figsize, dpi, bands=bands)\n                clips.append(clip)\n\
        \n                if start + step + frame_duration > duration:\n         \
        \           last_stop = stop\n\n                start = start + step\n   \
        \             stop = start + frame_duration\n\n        video = concatenate(clips)\n\
        \        # edaudio = AudioArrayClip(audio_array, fps=audio.samplerate)\n \
        \       edaudio = AudioFileClip(audio.path).set_end(audio.duration)\n    \
        \    video = video.set_audio(edaudio)\n        file_path = os.path.join(save_path_folder,\
        \ f\"{audio_id}.mp4\")\n        video.write_videofile(file_path, fps=fps)\n\
        \n        save_metadata_videoclip(audio_id, product_spectrum,\n          \
        \            save_path_folder, cumulus, node, recorder, deployment, 0.0, audio.duration)\n\
        \        video.close()\n        edaudio.close()\n\n        for c in clips:\n\
        \            c.close()\n\n    def change_type_sipecam_sc(session, root_folder_id,\
        \ path, file_type, node_type):\n        if file_type == \"sequence.png\":\n\
        \            metadata_name = \"soundscape_seq_metadata.json\"\n          \
        \  aggr_type = \"None\"\n        elif file_type == \"mean_soundscape.png\"\
        :\n            metadata_name = \"mean_soundscape_metadata.json\"\n       \
        \     aggr_type = \"Mean\"\n        elif file_type ==  \"std_soundscape.png\"\
        :\n            metadata_name = \"std_soundscape_metadata.json\" \n       \
        \     aggr_type = \"Standard deviation\"\n        elif file_type == \"hashed_soundscape.parquet\"\
        :\n            metadata_name = \"soundscape_metadata.json\" \n           \
        \ aggr_type = \"None\"\n        elif \".png\" in file_type and (file_type\
        \ not in [\"sequence.png\", \"mean_soundscape.png\", \"std_soundscape.png\"\
        ]):\n            metadata_name = file_type.split(\".\")[0] + \"_spectrogram_metadata.json\"\
        \n            aggr_type = \"Null\"\n        elif \".mp4\" in file_type and\
        \ (file_type not in [\"sequence.png\", \"mean_soundscape.png\", \"std_soundscape.png\"\
        ]):\n            metadata_name = file_type.split(\".\")[0] + \"_spectrogram_video_metadata.json\"\
        \n            aggr_type = \"Null\"\n\n        try:\n            semi_path\
        \ = path.split(\"soundscapes/\")[-1]\n            semi_path_file = os.path.join(semi_path,\
        \ file_type)\n            local_path_file_metadata = os.path.join(path, metadata_name)\n\
        \            print(f\"Changing type for {os.path.join(semi_path)}\")\n   \
        \         alfresco_path = os.path.join(\"/Company Home/Sites/sipecam-soundscape/documentLibrary/\"\
        , semi_path)\n\n            response = session.get(\n                os.getenv(\"\
        ALFRESCO_URL\")\n                + BASE_ENDPOINT\n                + \"/nodes/\"\
        \n                + root_folder_id\n                + \"/children?relativePath=\"\
        +semi_path+\"&include=aspectNames&skipCount=0\"\n            )        \n \
        \           # if request is successful then continue\n            if response.status_code\
        \ == 200:\n\n                data_file = open(local_path_file_metadata)\n\
        \                data_json = json.load(data_file)\n                response_entries\
        \ = response.json()[\"list\"][\"entries\"]\n\n                for entry in\
        \ response_entries:\n                    if entry['entry']['name']==file_type\
        \ and entry['entry']['isFile']:\n                        prop_dict = {}\n\n\
        \                        if entry['entry']['name']==file_type:\n\n       \
        \                     if entry['entry']['name'] in [\"sequence.png\", \"mean_soundscape.png\"\
        , \"std_soundscape.png\"]:\n                                prop_dict[\"soundscape:CumulusName\"\
        ] = str(data_json[\"CumulusName\"])\n                                prop_dict[\"\
        soundscape:DateDeployment\"] = data_json[\"DateDeployment\"]\n           \
        \                     prop_dict[\"soundscape:NodeCategoryIntegrity\"] = str(data_json[\"\
        NodeCategoryIntegrity\"])\n                                prop_dict[\"soundscape:NomenclatureNode\"\
        ] = str(data_json[\"NomenclatureNode\"])\n                               \
        \ prop_dict[\"soundscape:SerialNumber\"] = str(data_json[\"SerialNumber\"\
        ])\n                                prop_dict[\"soundscape:aggr\"] = str(aggr_type)\n\
        \                                prop_dict[\"soundscape:cycle_config_aware_start\"\
        ] = str(data_json[\"product_configs\"]['hasher_config']['kwargs']['aware_start'])\n\
        \                                prop_dict[\"soundscape:cycle_config_start_format\"\
        ] = str(data_json[\"product_configs\"]['hasher_config']['kwargs']['start_format'])\n\
        \                                prop_dict[\"soundscape:cycle_config_start_time\"\
        ] =  datetime.datetime.strptime(data_json[\"product_configs\"]['hasher_config']['kwargs']['start_time'],\
        \ \n                                                                     \
        \                                   \"%Y-%m-%d %H:%M:%S\").strftime(\"%Y-%m-%dT%H:%M:%S.%f%z\"\
        )\n                                prop_dict[\"soundscape:cycle_config_start_tzone\"\
        ] = str(data_json[\"product_configs\"]['hasher_config']['kwargs']['start_tzone'])\n\
        \                                prop_dict[\"soundscape:cycle_config_time_module\"\
        ] = int(data_json[\"product_configs\"]['hasher_config']['kwargs']['time_module'])\n\
        \                                prop_dict[\"soundscape:cycle_config_time_unit\"\
        ] = str(data_json[\"product_configs\"]['hasher_config']['kwargs']['time_unit'])\n\
        \                                prop_dict[\"soundscape:cycle_config_time_utc_column\"\
        ] = str(data_json[\"product_configs\"]['hasher_config']['kwargs']['time_utc_column'])\n\
        \                                prop_dict[\"soundscape:frequency_bins\"]\
        \ = int(data_json[\"product_configs\"][\"slice_config\"][\"frequency_bins\"\
        ])\n                                prop_dict[\"soundscape:frequency_hop\"\
        ] = int(data_json[\"product_configs\"][\"slice_config\"][\"frequency_hop\"\
        ])\n                                prop_dict[\"soundscape:frequency_limits\"\
        ] = str(data_json[\"product_configs\"][\"slice_config\"][\"frequency_limits\"\
        ])\n                                prop_dict[\"soundscape:hash_name\"] =\
        \ str(data_json[\"product_configs\"][\"hash_name\"])\n                   \
        \             prop_dict[\"soundscape:hop_length\"] = int(data_json[\"product_configs\"\
        ][\"slice_config\"][\"feature_config\"][\"hop_length\"])\n               \
        \                 prop_dict[\"soundscape:indices\"] =  \", \".join(map(str,\
        \ data_json['product_configs']['indices']))\n                            \
        \    prop_dict[\"soundscape:n_fft\"] = int(data_json[\"product_configs\"][\"\
        slice_config\"][\"feature_config\"][\"n_fft\"])\n                        \
        \        prop_dict[\"soundscape:npartitions\"] = int(data_json[\"product_configs\"\
        ]['npartitions'])\n                                prop_dict[\"soundscape:product_name\"\
        ] = str(data_json[\"product_name\"])\n                                prop_dict[\"\
        soundscape:product_parent\"] = str(data_json[\"product_parent\"])\n      \
        \                          prop_dict[\"soundscape:product_path\"] = str(alfresco_path)\n\
        \                                prop_dict[\"soundscape:product_spectrum\"\
        ] = str(data_json[\"product_spectrum\"])\n                               \
        \ prop_dict[\"soundscape:slice_config_feature_type\"] = str(data_json[\"product_configs\"\
        ][\"slice_config\"][\"feature_type\"])\n                                prop_dict[\"\
        soundscape:slice_config_frequency_bins\"] = int(data_json[\"product_configs\"\
        ][\"slice_config\"][\"frequency_bins\"])\n                               \
        \ prop_dict[\"soundscape:slice_config_time_unit\"] = int(data_json[\"product_configs\"\
        ][\"slice_config\"][\"time_unit\"])\n                                prop_dict[\"\
        soundscape:time_hop\"] = int(data_json[\"product_configs\"][\"slice_config\"\
        ][\"time_hop\"])\n                                prop_dict[\"soundscape:window_function\"\
        ] = str(data_json[\"product_configs\"][\"slice_config\"][\"feature_config\"\
        ][\"window_function\"])  \n\n                            elif (\"spectrogram\"\
        \ or \"video\") in entry['entry']['name']:\n                             \
        \   prop_dict[\"soundscape:product_name\"] = str(data_json[\"product_name\"\
        ])\n                                prop_dict[\"soundscape:product_parent\"\
        ] = str(data_json[\"product_parent\"])\n                                prop_dict[\"\
        soundscape:product_path\"] = str(alfresco_path)\n                        \
        \        prop_dict[\"soundscape:product_spectrum\"] = str(data_json[\"product_spectrum\"\
        ])\n                                prop_dict[\"soundscape:CumulusName\"]\
        \ = str(data_json[\"CumulusName\"])\n                                prop_dict[\"\
        soundscape:NodeCategoryIntegrity\"] = str(data_json[\"NodeCategoryIntegrity\"\
        ])\n                                prop_dict[\"soundscape:NomenclatureNode\"\
        ] = str(data_json[\"NomenclatureNode\"])\n                               \
        \ prop_dict[\"soundscape:SerialNumber\"] = str(data_json[\"SerialNumber\"\
        ])\n                                prop_dict[\"soundscape:DateDeployment\"\
        ] = data_json[\"DateDeployment\"]\n                                prop_dict[\"\
        soundscape:AudioID\"] = data_json[\"AudioID\"]\n\n                       \
        \ aspects = entry['entry']['aspectNames']\n                        data =\
        \ {\"aspectNames\": aspects, \"nodeType\": node_type, \"properties\": prop_dict}\n\
        \                        # update properties request\n                   \
        \     update = session.put(\n                            os.getenv(\"ALFRESCO_URL\"\
        )\n                            + BASE_ENDPOINT\n                         \
        \   + \"/nodes/\"\n                            + entry['entry']['id'],\n \
        \                           data=json.dumps(data),\n                     \
        \   )\n\n                        if update.status_code == 200:\n         \
        \                   print(\"Updated \" + entry['entry']['id'])           \
        \         \n\n        except Exception as e:\n            print(\"Could not\
        \ add any aspect to this file: \", e)\n\n    def create_results_folder_str(results_dir,\
        \ cumulo, nodes_list, rec_list, dep_list): \n        # results directory\n\
        \        os.makedirs(results_dir, exist_ok=True)\n        # cumulus subdir\n\
        \        cum_subdir = os.path.join(results_dir, str(cumulo))\n        os.makedirs(cum_subdir,\
        \ exist_ok=True)\n        # node subdirs\n        for node in nodes_list:\n\
        \            node_subdir = os.path.join(cum_subdir, node)\n            os.makedirs(node_subdir,\
        \ exist_ok=True)\n            # recorder subdirs\n            for rec in rec_list:\n\
        \                rec_subdir = os.path.join(node_subdir, rec)\n           \
        \     os.makedirs(rec_subdir, exist_ok=True)\n                # deployment\
        \ subdirs\n                for dep in dep_list:\n                    dep_subdir\
        \ = os.path.join(rec_subdir, dep)\n                    os.makedirs(dep_subdir,\
        \ exist_ok=True)\n\n    def distance_to_mean(vector, mean):\n        \\'\\\
        '\\'Return euclidean distance to mean\\'\\'\\'\n        return np.sqrt(np.sum(np.square(mean\
        \ - vector)))\n\n    def find_subfolders(path_abs):\n        subdir_list =\
        \ []\n        walk = list(os.walk(path_abs))\n        for path, _, _ in walk[::-1]:\n\
        \            len_path = path.split(\"/\")\n            if len(len_path) ==\
        \ 8:\n                subdir_list.append(path)  \n\n        return subdir_list\n\
        \n    def get_audio_ids(soundscape_path, indices, nsamples):\n        df =\
        \ pd.read_parquet(os.path.join(soundscape_path, \"hashed_soundscape.parquet\"\
        ))\n\n        df[\"time_raw_hour\"] = df[\"time_raw\"].apply(lambda x: datetime.datetime.strptime(x,'%H:%M:%S\
        \ %d/%m/%Y (%z)').strftime(\"%H\"))\n        hours_list = list(df.time_raw_hour.unique())\n\
        \        hours_list.sort(key = int)\n\n        with open(os.path.join(soundscape_path,\
        \ \"soundscape_metadata.json\")) as f:\n            metadata = json.load(f)\n\
        \            f.close()\n\n        # indices = metadata[\"product_configs\"\
        ][\"indices\"]\n        # indices = [\"EXAG\", \"ICOMPLEXITY\", \"CORE\"]\n\
        \        hash_name = metadata[\"product_configs\"][\"hash_name\"]\n      \
        \  cycle_config = metadata[\"product_configs\"][\"hasher_config\"][\"kwargs\"\
        ]\n        time_unit = cycle_config[\"time_unit\"]\n        zero_t = aware_time(cycle_config[\"\
        start_time\"], cycle_config[\"start_tzone\"], cycle_config[\"start_format\"\
        ]) \n\n        # iterate over hours\n        audio_id_list = []\n        for\
        \ hour in hours_list:\n            subdf = df.query(f\"time_raw_hour == '{hour}'\"\
        )\n            # sample\n            samples_df = get_recording_samples(subdf,\
        \ hash_name, indices, time_unit, zero_t, nsamples=3)\n            unique_crono_hash_list\
        \ = list(samples_df.crono_hash_30m.unique())\n            sub_df = samples_df[samples_df.crono_hash_30m\
        \ == min(unique_crono_hash_list)]\n            audio_id_list += list(sub_df.id.tolist())\n\
        \n        return audio_id_list\n\n    def get_recording_samples(df, hash_name,\
        \ indices, time_unit, zero_t, nsamples=5):\n        \\'\\'\\'Return dataframe\
        \ of 'nsamples' samples for each tag in 'hash_name' column that are closest\
        \ to the mean vector by tag\\'\\'\\'\n        proj_df = df[(df.max_freq <=\
        \ 10000)]\n        crono_tags = proj_df.crono_hash_30m.unique()\n        proj_df.loc[:\
        \ , f\"{hash_name}_time\"] = proj_df[hash_name].apply(lambda x: zero_t + datetime.timedelta(seconds=float(x*time_unit)))\n\
        \        vectors = vectorize_soundscape(proj_df, hash_name, indices)\n   \
        \     min_index_vector = np.amin(np.stack(list(vectors.index_vector.values)),\
        \ axis=(0,1))\n        max_index_vector = np.amax(np.stack(list(vectors.index_vector.values)),\
        \ axis=(0,1))\n        index_range = (max_index_vector - min_index_vector)\n\
        \        vectors.loc[:, \"normalized_index_vector\"] = vectors.index_vector.apply(lambda\
        \ x: (x-min_index_vector)/index_range)\n        all_samples = []\n\n     \
        \   for crono_tag in crono_tags:\n            unit_vectors = vectors[vectors[hash_name]\
        \ == crono_tag]\n            mean_unit_vector = unit_vectors.normalized_index_vector.mean()\n\
        \            unit_vectors.loc[:, \"distance\"] = unit_vectors.normalized_index_vector.apply(lambda\
        \ x: distance_to_mean(x, mean_unit_vector))\n            all_samples.append(unit_vectors.sort_values(by=\"\
        distance\").head(nsamples))\n        return pd.concat(all_samples)\n\n   \
        \ def get_vectors(group, indices):\n        \\'\\'\\'Return array of indices\
        \ by frequency\\'\\'\\'\n        return group.sort_values(by=\"max_freq\"\
        )[indices].values\n\n    def login():\n        \"\"\"\n        Tries a login\
        \ to alfresco api and returns a session\n        object with credentials \n\
        \        Returns: \n            session (Session):  A session object to make\
        \ \n                                requests to zendro.\n        \"\"\"\n\
        \        try:\n            auth = {\n                \"userId\": os.getenv(\"\
        ALFRESCO_USER\"),\n                \"password\": os.getenv(\"ALFRESCO_PASSWORD\"\
        ),\n            }\n\n            login = requests.post(os.getenv(\"ALFRESCO_URL\"\
        ) + AUTH_ENDPOINT + \"/tickets\",data=json.dumps(auth))\n\n            base64_login\
        \ = base64.b64encode(bytes(login.json()[\"entry\"][\"id\"], 'utf-8')).decode()\n\
        \n            # se crea un objeto de Session para hacer requests\n       \
        \     session = requests.Session()\n            # se establece bearer token\n\
        \            session.headers.update({'Authorization': 'Basic ' + base64_login})\n\
        \n            return session\n        except Exception as e:\n           \
        \ print(\"Login failed: \", e)\n\n    def plot_spectrogram(audio_id, audio_df,\
        \ save_path_folder, spectrum, cumulus):\n        sub_audio_df = audio_df[audio_df[\"\
        id\"]==audio_id]\n        node = sub_audio_df['node'].values[0]\n        recorder\
        \ = sub_audio_df['recorder'].values[0]\n        deployment = sub_audio_df['deployment'].values[0]\n\
        \        # plot\n        fig, ax = plt.subplots(2,1,figsize=(20,10), sharex=True)\n\
        \        sub_audio_df.audio[0].plot(ax=ax[0], color='grey')\n        sub_audio_df.audio[0].features.db_spectrogram().plot(ax=ax[1])\n\
        \        ax[0].set_ylabel('Amplitude')\n        ax[0].grid(False)\n      \
        \  ax[1].set_ylabel('F (KHz)')\n        ax[1].set_xlabel('Time (seconds)')\n\
        \        fig.text(0.75, 0.04, f\"Cumulus: {cumulus} - Node: {node} - Recorder:\
        \ {recorder}\", va='center')\n        plt.tight_layout()\n        if save_path_folder:\n\
        \            file_path = os.path.join(save_path_folder, f\"{audio_id}.png\"\
        )\n            fig.savefig(file_path)\n        plt.show()\n\n        save_metadata_spectrogram(audio_id,\
        \ spectrum, save_path_folder, \n                                  cumulus,\
        \ node, recorder, deployment, parent=\"Null\")\n\n    def plot_soundscape(soundscape,\
        \ product_type, product_spectrum, sc_config, path, \n                    \
        \    cumulus, node, recorder, deployment, parent, indices, min_freq=None,\n\
        \                      figsize=(20,15), plt_style='ggplot'):\n\n        if\
        \ min_freq:\n            soundscape = soundscape[soundscape['min_freq']<=min_freq]\n\
        \n        if product_type == \"sequence\":\n            file_path = os.path.join(path,\
        \ \"sequence.png\")\n            # product_id = hashlib.md5(file_path.encode('utf-8')).hexdigest()\n\
        \n            plt.style.use(plt_style)\n            fig, ax = plt.subplots(figsize=figsize)\n\
        \            soundscape.sndscape.plot_sequence(rgb=indices, time_format='%Y-%m\
        \ %H:%M', ax=ax)\n            plt.xticks(rotation = 90)\n            ax.grid(False)\n\
        \            plt.tight_layout()\n            plt.savefig(file_path) \n   \
        \         plt.show()\n            # save metadata\n            save_metadata_sc(product_type,\
        \ product_spectrum, sc_config,\n                      path, cumulus, node,\
        \ recorder, deployment, parent=parent)\n\n        elif product_type == \"\
        standard_deviation\":\n            file_path = os.path.join(path, \"std_soundscape.png\"\
        )\n            # product_id = hashlib.md5(file_path.encode('utf-8')).hexdigest()\n\
        \n            plt.style.use(plt_style)\n            fig, ax = plt.subplots(figsize=figsize)\n\
        \            soundscape.sndscape.plot_cycle(rgb=indices, aggr=\"std\", time_format='%H:%M',\
        \ \n                                           xticks=24, ax=ax)\n       \
        \     plt.xticks(rotation = 90)\n            ax.grid(False)\n            plt.tight_layout()\
        \ \n            plt.savefig(file_path)\n            plt.show()\n\n       \
        \     # save metadata\n            save_metadata_sc(product_type, product_spectrum,\
        \ sc_config,\n                      path, cumulus, node, recorder, deployment,\
        \ parent)     \n\n        elif product_type == \"mean\": \n            file_path\
        \ = os.path.join(path, \"mean_soundscape.png\")\n            # product_id\
        \ = hashlib.md5(file_path.encode('utf-8')).hexdigest()\n\n            plt.style.use(plt_style)\n\
        \            fig, ax = plt.subplots(figsize=figsize)\n            soundscape.sndscape.plot_cycle(rgb=indices,\
        \ aggr=\"mean\", time_format='%H:%M', \n                                 \
        \          xticks=24, ax=ax)\n            plt.xticks(rotation = 90)\n    \
        \        ax.grid(False)\n            plt.tight_layout()\n            plt.savefig(file_path)\n\
        \            plt.show()\n\n            # save metadata\n            save_metadata_sc(product_type,\
        \ product_spectrum, sc_config,\n                      path, cumulus, node,\
        \ recorder, deployment, parent)    \n\n        print(f\"File saved at {file_path}\"\
        )\n\n    def produce_clip(spec, frame_duration, min_freq, max_freq, start,\
        \ stop, step, abs_start=None, \n                     colormap=cm.get_cmap(\"\
        Greys\"), min_spec=0, spec_range=1.0, figsize=(5, 4), \n                 \
        \    dpi=100, bands=None):\n        \\'\\'\\'Takes an individual frame and\
        \ produces an image with references\\'\\'\\'\n        frame = spec.cut_array(start_time=start,\
        \ end_time=stop, min_freq=min_freq, max_freq=max_freq, pad=True)\n       \
        \ plt.style.use('dark_background')\n        frame = np.flip((frame - min_spec)/spec_range,\
        \ axis=0)\n        fig, ax = plt.subplots(figsize=figsize)\n        ax.imshow(frame,\
        \ cmap=colormap, extent=[0, frame_duration, min_freq/1000, max_freq/1000],\
        \ \n                  aspect=\"auto\", vmin = 0, vmax = 1.0)\n\n        if\
        \ bands is not None:\n            band_arr = np.flip(resize(np.expand_dims(bands,\
        \ axis=1), (frame.shape[0], frame.shape[1])), axis=0)\n            ax.imshow(band_arr,\
        \ extent=[0, frame_duration, min_freq/1000, max_freq/1000], aspect=\"auto\"\
        , vmin = 0, \n                      vmax = 1.0, alpha=0.5)\n\n        ax.tick_params(axis='both',\
        \ which='major', labelsize=8)\n        ax.tick_params(axis='both', which='minor',\
        \ labelsize=8)\n        mid = frame_duration/2.0\n        ax.axvline(x=mid,\
        \ color=\"red\")\n        ax.set_ylabel('F (kHz)')\n        ax.set_xticks([])\n\
        \        ax.set_xticks([], minor=True)\n\n        if abs_start is not None:\n\
        \            time_text = (abs_start + datetime.timedelta(seconds=start+mid)).strftime('%H:%M:%S.%f').strip()[:-4]\n\
        \            ax.text(mid-0.3, -0.6, time_text)\n\n        buf = io.BytesIO()\n\
        \        fig.tight_layout()\n        fig.savefig(buf, dpi=dpi)\n        buf.seek(0)\n\
        \        im = Image.open(buf)\n        im.format = \"PNG\"\n        plt.close(fig)\n\
        \n        return ImageClip(np.asarray(im),\n                         duration=step)\n\
        \n    def remove_empty_folders(path_abs):\n        walk = list(os.walk(path_abs))\n\
        \        for path, _, _ in walk[::-1]:\n            if len(os.listdir(path))\
        \ == 0:\n                os.rmdir(path)            \n\n    def save_metadata_sc(product_type,\
        \ product_spectrum, sc_config,\n                      path, cumulus, node,\
        \ recorder, deployment, parent=\"Null\"):\n        if product_type == \"soundscape\"\
        :\n            product_name = \"Soundscape\"\n            file_path = os.path.join(path,\
        \ \"hashed_soundscape.parquet\")\n            metadata_filename = os.path.join(path,\
        \ \"soundscape_metadata.json\")\n        elif product_type == \"sequence\"\
        :\n            product_name = \"Soundscape sequential plot\"\n           \
        \ file_path = os.path.join(path, \"soundscape_seq.png\")\n            metadata_filename\
        \ = os.path.join(path, \"soundscape_seq_metadata.json\")\n        elif product_type\
        \ == \"standard_deviation\":\n            product_name = \"Soundscape standard\
        \ deviation plot\"\n            file_path = os.path.join(path, \"std_soundscape.png\"\
        )\n            metadata_filename = os.path.join(path, \"std_soundscape_metadata.json\"\
        )\n        elif product_type == \"mean\":\n            product_name = \"Soundscape\
        \ mean plot\"\n            file_path = os.path.join(path, \"mean_soundscape.png\"\
        )\n            metadata_filename = os.path.join(path, \"mean_soundscape_metadata.json\"\
        )\n\n        if int(node.split(\"_\")[2]) == 0:\n            node_category\
        \ = \"Degradado\"\n        elif int(node.split(\"_\")[2]) == 1:\n        \
        \    node_category = \"Integro\"\n\n        metadata = {\n            \"product_parent\"\
        : parent,\n            \"product_name\": product_name,\n            \"product_configs\"\
        : sc_config,\n            \"product_path\": file_path,\n            \"product_spectrum\"\
        : product_spectrum,\n            \"CumulusName\": cumulus,\n            \"\
        NodeCategoryIntegrity\": node_category,\n            \"NomenclatureNode\"\
        : node,\n            \"SerialNumber\": recorder,\n            \"DateDeployment\"\
        : deployment\n        }\n\n        with open(metadata_filename, 'w', encoding='utf-8')\
        \ as f:\n            json.dump(metadata, f, ensure_ascii=False, indent=4)\n\
        \n    def save_metadata_spectrogram(audio_id, product_spectrum,\n        \
        \              path, cumulus, node, recorder, deployment, parent=\"Null\"\
        ):\n        # identifier is being used as audio_id in alfresco\n        product_name\
        \ = \"Spectrogram\"\n        file_path = os.path.join(path, f\"{audio_id}.png\"\
        )\n        metadata_filename = os.path.join(path, f\"{audio_id}_spectrogram_metadata.json\"\
        )\n\n        if int(node.split(\"_\")[2]) == 0:\n            node_category\
        \ = \"Degradado\"\n        elif int(node.split(\"_\")[2]) == 1:\n        \
        \    node_category = \"Integro\"\n\n        metadata = {\n            \"product_parent\"\
        : parent,\n            \"product_name\": product_name,\n            \"product_path\"\
        : file_path,\n            \"product_spectrum\": product_spectrum,\n      \
        \      \"CumulusName\": cumulus,\n            \"NodeCategoryIntegrity\": node_category,\n\
        \            \"NomenclatureNode\": node,\n            \"SerialNumber\": recorder,\n\
        \            \"DateDeployment\": deployment,\n            \"AudioID\": audio_id\n\
        \        }\n        with open(metadata_filename, 'w', encoding='utf-8') as\
        \ f:\n            json.dump(metadata, f, ensure_ascii=False, indent=4)\n\n\
        \        print(f\"{file_path} saved.\")\n        print(f\"{metadata_filename}\
        \ saved.\")\n\n    def save_metadata_videoclip(audio_id, product_spectrum,\
        \ path, cumulus, node, recorder, \n                                deployment,\
        \ clip_start, clip_end, parent=\"Null\"):\n        # identifier is being used\
        \ as audio_id in alfresco\n        product_name = \"spectrogram_video\"\n\
        \        file_path = os.path.join(path, f\"{audio_id}.mp4\")\n        metadata_filename\
        \ = os.path.join(path, f\"{audio_id}_spectrogram_video_metadata.json\")\n\n\
        \        if int(node.split(\"_\")[2]) == 0:\n            node_category = \"\
        Degradado\"\n        elif int(node.split(\"_\")[2]) == 1:\n            node_category\
        \ = \"Integro\"\n\n        metadata = {\n            \"product_parent\": parent,\n\
        \            \"product_name\": product_name,\n            \"product_description\"\
        : \"Spectrogram Video. Time is show in local timezone\",\n            \"product_path\"\
        : file_path,\n            \"product_spectrum\": product_spectrum,\n      \
        \      \"CumulusName\": cumulus,\n            \"NodeCategoryIntegrity\": node_category,\n\
        \            \"NomenclatureNode\": node,\n            \"SerialNumber\": recorder,\n\
        \            \"DateDeployment\": deployment,\n            \"ClipStart\": clip_start,\n\
        \            \"ClipEnd\": clip_end,\n            \"AudioID\": audio_id\n \
        \       }\n\n        with open(metadata_filename, 'w', encoding='utf-8') as\
        \ f:\n            json.dump(metadata, f, ensure_ascii=False, indent=4)\n\n\
        \        print(f\"{file_path} saved.\")\n        print(f\"{metadata_filename}\
        \ saved.\")\n\n    def upload(session, node_id, data, file):\n        \"\"\
        \"\n        Uploads a file to a specific folder.\n        Parameters:\n  \
        \          session (Session):          A session object to make\n        \
        \                                requests to alfresco.\n            node_id\
        \ (string):           Node id to which the file is going to be created\n \
        \           data (dict):                Dict that contains file options\n\
        \            file (object):              File to upload\n\n        Returns:\n\
        \            (list):     A list containing status code and status data\n \
        \       \"\"\"\n\n        try:\n            response = session.post(os.getenv(\"\
        ALFRESCO_URL\")\n                        + BASE_ENDPOINT + \"/nodes/\" + node_id\
        \ + \"/children\",\n                        data = data,\n               \
        \         files = file\n                        )\n\n            return [response.json(),\
        \ response.status_code];\n        except Exception as e: \n            print(\"\
        File \" + data[\"name\"] + \" could not be uploaded: \", e)\n\n    def upload_files(file_patterns,\
        \ session, node_id, dir_path, recursive, file_identifier=\"\"):\n        \"\
        \"\"\n        Uploads the files stored in a specific dir\n        to alfresco\n\
        \        Parameters:\n            session (Session):          A session object\
        \ to make\n                                        requests to alfresco.\n\
        \            node_id (string):           Node id to which the file is going\
        \ to be created\n            dir_path (string):          The name and path\
        \ of the dir where files are stored\n            recursive (boolean):    \
        \    A boolean to know if upload  must be recursive\n                    \
        \                    in the specifed dir, and should preserve the\n      \
        \                                  structure of dirs inside.\n           \
        \ file_identifier (string):   File identifier for all files inside a dir\n\
        \        Returns:\n            (string):           Returns the info of recent\
        \ created site.\n        \"\"\"\n\n        if recursive:\n            expression\
        \ = \"/**/*\"\n        else:\n            expression = \"/*\"\n\n        files_in_dir\
        \ = list(\n            itertools.chain.from_iterable(\n                glob.iglob(dir_path\
        \ + expression + pattern, recursive=recursive)\n                for pattern\
        \ in file_patterns\n            )\n        )\n        filename = \"logs/upload_log\"\
        \ + dir_path.replace('/','-') + '.txt'\n\n        os.makedirs(os.path.dirname(filename),\
        \ exist_ok=True)\n\n        total_files = len(files_in_dir)\n        starttime\
        \ = time.time()\n\n        try:\n            files_uploaded = []\n       \
        \     for idx, file_with_path in enumerate(files_in_dir):\n\n            \
        \    # total time since last login or script start\n                total_time\
        \ = round((time.time() - starttime), 2)\n\n                if total_time >\
        \ 2400:\n                    \"\"\"\n                    if total time is\
        \ bigger than 2400\n                    or 40 minutes relogin to avoid ticket\n\
        \                    expiration\n                    \"\"\"\n            \
        \        time.sleep(5)\n\n                    print(\"Re-logging in to alfresco...\"\
        )\n\n                    session = login.login()\n                    # restart\
        \ time\n                    starttime = time.time()\n                    time.sleep(5)\n\
        \                    print(\"Login sucessful, continuing upload\\\\n\")\n\n\
        \                len_of_path = len(file_with_path.split(\"/\"))\n        \
        \        name_of_file = file_with_path.split(\"/\")[len_of_path - 1]\n   \
        \             root_dir_path = file_with_path.replace(dir_path, \"\").replace(\n\
        \                    file_with_path.split(\"/\")[len_of_path - 1], \"\"\n\
        \                )\n\n                data = {\n                    \"name\"\
        : (\n                        name_of_file[0 : len(name_of_file) - 4]\n   \
        \                     + file_identifier\n                        + name_of_file[len(name_of_file)\
        \ - 4 : len(name_of_file)]\n                    ),\n                    \"\
        nodeType\": \"cm:content\",\n                }\n\n                data[\"\
        relativePath\"] = root_dir_path\n\n                data[\"properties\"] =\
        \ {\n                    \"cm:title\": (\n                        name_of_file[0\
        \ : len(name_of_file) - 4]\n                        + file_identifier\n  \
        \                      + name_of_file[len(name_of_file) - 4 : len(name_of_file)]\n\
        \                    )\n                }\n\n                print(\"Uploading\
        \ \" + data[\"name\"] + \" file...\")\n\n                files = {\"filedata\"\
        : open(file_with_path, \"rb\")}\n                upload_response = upload(session,\
        \ node_id, data, files)\n                if upload_response[1] and upload_response[1]\
        \ == 201:\n                    files_uploaded.append(upload_response[0])\n\
        \                    print(\"Uploaded \" + data[\"name\"])\n\n           \
        \         filename = \"logs/upload_log\" + dir_path.replace('/','-') + '.txt'\n\
        \                    with open(filename, 'a') as log_file:\n             \
        \           log_file.writelines(\"%s\\\\n\" % file_with_path)\n\n        \
        \        elif upload_response[1] and upload_response[1] == 409:\n        \
        \            if \"already exists\" in upload_response[0][\"error\"][\"errorKey\"\
        ]:\n                        print(\"File \" + data[\"name\"] + \" already\
        \ uploaded\")\n\n                else:\n                    print(\"An error\
        \ ocurred, file \" + data[\"name\"] + \" cannot be uploaded\")\n\n       \
        \         print(\"Uploaded file \" + str(idx + 1) + \" of \" + str(total_files))\n\
        \                print(\"\\\\n\\\\n\")\n\n            return files_uploaded\n\
        \        except Exception as e:\n            print(\"An error ocurred in file\
        \ upload: \", e)\n\n    def vectorize_soundscape(df, hash_name, indices):\n\
        \        \\'\\'\\'Return dataframe with array column containing indices by\
        \ frequency\\'\\'\\'\n        return (df\n                .groupby(by=[\"\
        id\", hash_name, \"start_time\", \"end_time\"])\n                .apply(get_vectors,\
        \ indices)\n                .reset_index()\n                .rename(columns={0:\"\
        index_vector\"}))\n    '''\n\n    _kale_block3 = '''\n    plt.style.use('dark_background')\n\
        \    warnings.filterwarnings('ignore')\n\n    sub_folder_results = find_subfolders(RESULTS_DIR)\n\
        \n    for sc_path in sub_folder_results:\n        # parquet_file_path = os.path.join(sc_path,\
        \ \"hashed_soundscape.parquet\")\n        if \"hashed_soundscape.parquet\"\
        \ in os.listdir(sc_path):\n            print(f\"Processing results folder\
        \ {sc_path}\")\n\n            # filter dataframe by hour\n            ids_audios\
        \ = get_audio_ids(sc_path, indices = [RED_IDX, GREEN_IDX, BLUE_IDX], nsamples=VIDS_PER_HOUR)\n\
        \            for id_audio in ids_audios:\n                print(f\"Processing\
        \ audio {id_audio}\")\n                try:\n                    plot_spectrogram(id_audio,\
        \ recs, sc_path, SPECTRUM, CUMULO)   \n                    audio2video(id_audio,\
        \ id_audio, recs, sc_path, SPECTRUM, CUMULO)\n                except:\n  \
        \                  pass\n\n        else:\n            print(f\"hashed_soundscape.parquet\
        \ not found in {sc_path}\")\n    '''\n\n    _kale_data_saving_block = '''\n\
        \    # -----------------------DATA SAVING START---------------------------------\n\
        \    from kale import marshal as _kale_marshal\n    _kale_marshal.set_data_dir(\"\
        /shared_volume/audio/.sndscs_spec_specvid-sipecam-cumulus-node-recorder-deployment-aws.ipynb.kale.marshal.dir\"\
        )\n    _kale_marshal.save(sub_folder_results, \"sub_folder_results\")\n  \
        \  # -----------------------DATA SAVING END-----------------------------------\n\
        \    '''\n\n    # run the code blocks inside a jupyter kernel\n    from kale.common.jputils\
        \ import run_code as _kale_run_code\n    from kale.common.kfputils import\
        \ \\\n        update_uimetadata as _kale_update_uimetadata\n    _kale_blocks\
        \ = (_kale_pipeline_parameters_block, _kale_data_loading_block,\n        \
        \            _kale_block1,\n                    _kale_block2,\n          \
        \          _kale_block3,\n                    _kale_data_saving_block)\n \
        \   _kale_html_artifact = _kale_run_code(_kale_blocks)\n    with open(\"/spec_n_specvid.html\"\
        , \"w\") as f:\n        f.write(_kale_html_artifact)\n    _kale_update_uimetadata('spec_n_specvid')\n\
        \n    _kale_mlmdutils.call(\"mark_execution_complete\")\n\nimport argparse\n\
        _parser = argparse.ArgumentParser(prog='Spec n specvid', description='')\n\
        _parser.add_argument(\"--AUTH-ENDPOINT\", dest=\"AUTH_ENDPOINT\", type=str,\
        \ required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"--BASE-ENDPOINT\"\
        , dest=\"BASE_ENDPOINT\", type=str, required=True, default=argparse.SUPPRESS)\n\
        _parser.add_argument(\"--BLUE-IDX\", dest=\"BLUE_IDX\", type=str, required=True,\
        \ default=argparse.SUPPRESS)\n_parser.add_argument(\"--CUMULO\", dest=\"CUMULO\"\
        , type=int, required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"\
        --GREEN-IDX\", dest=\"GREEN_IDX\", type=str, required=True, default=argparse.SUPPRESS)\n\
        _parser.add_argument(\"--RED-IDX\", dest=\"RED_IDX\", type=str, required=True,\
        \ default=argparse.SUPPRESS)\n_parser.add_argument(\"--RESULTS-DIR\", dest=\"\
        RESULTS_DIR\", type=str, required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"\
        --SPECTRUM\", dest=\"SPECTRUM\", type=str, required=True, default=argparse.SUPPRESS)\n\
        _parser.add_argument(\"--VIDS-PER-HOUR\", dest=\"VIDS_PER_HOUR\", type=int,\
        \ required=True, default=argparse.SUPPRESS)\n_parsed_args = vars(_parser.parse_args())\n\
        \n_outputs = spec_n_specvid(**_parsed_args)\n"
      image: sipecam/audio-dgpi-kale-tensorflow-yuntu-dask-cert:0.6.1_dev
      securityContext: {runAsUser: 0}
      volumeMounts:
      - {mountPath: /shared_volume, name: pvolume-ef6fe65091618f865041935b363277953274adf6b420fd4a7b8277d}
      workingDir: //shared_volume/audio
    inputs:
      parameters:
      - {name: AUTH_ENDPOINT}
      - {name: BASE_ENDPOINT}
      - {name: BLUE_IDX}
      - {name: CUMULO}
      - {name: GREEN_IDX}
      - {name: RED_IDX}
      - {name: RESULTS_DIR}
      - {name: SPECTRUM}
      - {name: VIDS_PER_HOUR}
      - {name: vol_shared_volume}
    outputs:
      artifacts:
      - {name: mlpipeline-ui-metadata, path: /tmp/mlpipeline-ui-metadata.json}
      - {name: spec_n_specvid, path: /spec_n_specvid.html}
    metadata:
      annotations: {kubeflow-kale.org/dependent-templates: '["compute-soundscapes"]',
        pipelines.kubeflow.org/component_spec: '{"implementation": {"container": {"args":
          ["--AUTH-ENDPOINT", {"inputValue": "AUTH_ENDPOINT"}, "--BASE-ENDPOINT",
          {"inputValue": "BASE_ENDPOINT"}, "--BLUE-IDX", {"inputValue": "BLUE_IDX"},
          "--CUMULO", {"inputValue": "CUMULO"}, "--GREEN-IDX", {"inputValue": "GREEN_IDX"},
          "--RED-IDX", {"inputValue": "RED_IDX"}, "--RESULTS-DIR", {"inputValue":
          "RESULTS_DIR"}, "--SPECTRUM", {"inputValue": "SPECTRUM"}, "--VIDS-PER-HOUR",
          {"inputValue": "VIDS_PER_HOUR"}], "command": ["sh", "-ec", "program_path=$(mktemp)\nprintf
          \"%s\" \"$0\" > \"$program_path\"\npython3 -u \"$program_path\" \"$@\"\n",
          "def spec_n_specvid(AUTH_ENDPOINT, BASE_ENDPOINT, BLUE_IDX, CUMULO, GREEN_IDX,
          RED_IDX, RESULTS_DIR, SPECTRUM, VIDS_PER_HOUR):\n    _kale_pipeline_parameters_block
          = ''''''\n    AUTH_ENDPOINT = \"{}\"\n    BASE_ENDPOINT = \"{}\"\n    BLUE_IDX
          = \"{}\"\n    CUMULO = {}\n    GREEN_IDX = \"{}\"\n    RED_IDX = \"{}\"\n    RESULTS_DIR
          = \"{}\"\n    SPECTRUM = \"{}\"\n    VIDS_PER_HOUR = {}\n    ''''''.format(AUTH_ENDPOINT,
          BASE_ENDPOINT, BLUE_IDX, CUMULO, GREEN_IDX, RED_IDX, RESULTS_DIR, SPECTRUM,
          VIDS_PER_HOUR)\n\n    from kale.common import mlmdutils as _kale_mlmdutils\n    _kale_mlmdutils.init_metadata()\n\n    _kale_data_loading_block
          = ''''''\n    # -----------------------DATA LOADING START--------------------------------\n    from
          kale import marshal as _kale_marshal\n    _kale_marshal.set_data_dir(\"/shared_volume/audio/.sndscs_spec_specvid-sipecam-cumulus-node-recorder-deployment-aws.ipynb.kale.marshal.dir\")\n    recs
          = _kale_marshal.load(\"recs\")\n    # -----------------------DATA LOADING
          END----------------------------------\n    ''''''\n\n    _kale_block1 =
          ''''''\n    import base64\n    import datetime\n    import glob\n    import
          hashlib\n    import io\n    import itertools\n    import json\n    import
          matplotlib.pyplot as plt\n    import multiprocessing \n    import numpy
          as np\n    import os\n    import pandas as pd\n    import psutil\n    import
          requests\n    import shutil\n    import subprocess\n    import time\n    import
          warnings\n\n    from dask.distributed import Client, LocalCluster\n    from
          datetime import timedelta\n    from dotenv import load_dotenv\n    from
          matplotlib import cm\n    from moviepy.editor import concatenate, VideoFileClip,
          AudioFileClip\n    from moviepy.audio.AudioClip import AudioArrayClip\n    from
          moviepy.video.VideoClip import ImageClip\n    from os.path import exists
          as file_exists\n    from PIL import Image\n    from skimage.transform import
          resize\n\n    from yuntu import Audio\n    from yuntu.soundscape.utils import
          aware_time\n    from yuntu.collection.methods import collection\n    from
          yuntu.soundscape.hashers.crono import DEFAULT_HASHER_CONFIG\n    from yuntu.soundscape.processors.indices.direct
          import ICOMPLEXITY, TAIL\n    from yuntu.soundscape.pipelines.build_soundscape
          import CronoSoundscape, HASHER_CONFIG\n    ''''''\n\n    _kale_block2 =
          ''''''\n    def audio2video(audio_id,\n                    audio_df,\n                    save_path_folder,\n                    product_spectrum,\n                    cumulus,\n                    abs_start=None,\n                    fps=60,\n                    spec_configs={''hop_length'':
          512, ''n_fft'': 1024, ''window_function'': ''hann''},\n                    rate=24,\n                    frame_duration=3.0,\n                    min_freq=0,\n                    max_freq=None,\n                    cmap=\"Greys\",\n                    figsize=(5,
          8),\n                    dpi=100,\n                    bands=None):\n        \\''\\''\\''Takes
          and audio object and produces a mp4 video of the spectrogram with audio\\''\\''\\''\n\n        sub_audio_df
          = audio_df[audio_df[\"id\"]==audio_id]\n        id_audio = sub_audio_df[''id''].values[0]\n        node
          = sub_audio_df[''node''].values[0]\n        recorder = sub_audio_df[''recorder''].values[0]\n        deployment
          = sub_audio_df[''deployment''].values[0]\n        audio = sub_audio_df.audio[0]\n\n        colormap
          = cm.get_cmap(cmap)\n        duration = audio.duration\n        step = 1/rate\n        start
          = -(frame_duration/2.0)\n        stop = start + frame_duration\n        clips
          = []\n        last_stop = None\n\n        if max_freq is None:\n            max_freq
          = audio.samplerate / 2.0\n\n        if min_freq is None:\n            min_freq
          = 0\n\n        with audio.features.db_spectrogram(**spec_configs) as spec:\n            min_spec
          = np.amin(spec)\n            max_spec = np.amax(spec)\n            spec_range
          = (max_spec-min_spec)\n\n            while stop <= duration+(frame_duration/2.0):\n                clip
          = produce_clip(spec, frame_duration, min_freq, max_freq, start, stop, step,
          abs_start, colormap,\n                                    min_spec, spec_range,
          figsize, dpi, bands=bands)\n                clips.append(clip)\n\n                if
          start + step + frame_duration > duration:\n                    last_stop
          = stop\n\n                start = start + step\n                stop = start
          + frame_duration\n\n        video = concatenate(clips)\n        # edaudio
          = AudioArrayClip(audio_array, fps=audio.samplerate)\n        edaudio = AudioFileClip(audio.path).set_end(audio.duration)\n        video
          = video.set_audio(edaudio)\n        file_path = os.path.join(save_path_folder,
          f\"{audio_id}.mp4\")\n        video.write_videofile(file_path, fps=fps)\n\n        save_metadata_videoclip(audio_id,
          product_spectrum,\n                      save_path_folder, cumulus, node,
          recorder, deployment, 0.0, audio.duration)\n        video.close()\n        edaudio.close()\n\n        for
          c in clips:\n            c.close()\n\n    def change_type_sipecam_sc(session,
          root_folder_id, path, file_type, node_type):\n        if file_type == \"sequence.png\":\n            metadata_name
          = \"soundscape_seq_metadata.json\"\n            aggr_type = \"None\"\n        elif
          file_type == \"mean_soundscape.png\":\n            metadata_name = \"mean_soundscape_metadata.json\"\n            aggr_type
          = \"Mean\"\n        elif file_type ==  \"std_soundscape.png\":\n            metadata_name
          = \"std_soundscape_metadata.json\" \n            aggr_type = \"Standard
          deviation\"\n        elif file_type == \"hashed_soundscape.parquet\":\n            metadata_name
          = \"soundscape_metadata.json\" \n            aggr_type = \"None\"\n        elif
          \".png\" in file_type and (file_type not in [\"sequence.png\", \"mean_soundscape.png\",
          \"std_soundscape.png\"]):\n            metadata_name = file_type.split(\".\")[0]
          + \"_spectrogram_metadata.json\"\n            aggr_type = \"Null\"\n        elif
          \".mp4\" in file_type and (file_type not in [\"sequence.png\", \"mean_soundscape.png\",
          \"std_soundscape.png\"]):\n            metadata_name = file_type.split(\".\")[0]
          + \"_spectrogram_video_metadata.json\"\n            aggr_type = \"Null\"\n\n        try:\n            semi_path
          = path.split(\"soundscapes/\")[-1]\n            semi_path_file = os.path.join(semi_path,
          file_type)\n            local_path_file_metadata = os.path.join(path, metadata_name)\n            print(f\"Changing
          type for {os.path.join(semi_path)}\")\n            alfresco_path = os.path.join(\"/Company
          Home/Sites/sipecam-soundscape/documentLibrary/\", semi_path)\n\n            response
          = session.get(\n                os.getenv(\"ALFRESCO_URL\")\n                +
          BASE_ENDPOINT\n                + \"/nodes/\"\n                + root_folder_id\n                +
          \"/children?relativePath=\"+semi_path+\"&include=aspectNames&skipCount=0\"\n            )        \n            #
          if request is successful then continue\n            if response.status_code
          == 200:\n\n                data_file = open(local_path_file_metadata)\n                data_json
          = json.load(data_file)\n                response_entries = response.json()[\"list\"][\"entries\"]\n\n                for
          entry in response_entries:\n                    if entry[''entry''][''name'']==file_type
          and entry[''entry''][''isFile'']:\n                        prop_dict = {}\n\n                        if
          entry[''entry''][''name'']==file_type:\n\n                            if
          entry[''entry''][''name''] in [\"sequence.png\", \"mean_soundscape.png\",
          \"std_soundscape.png\"]:\n                                prop_dict[\"soundscape:CumulusName\"]
          = str(data_json[\"CumulusName\"])\n                                prop_dict[\"soundscape:DateDeployment\"]
          = data_json[\"DateDeployment\"]\n                                prop_dict[\"soundscape:NodeCategoryIntegrity\"]
          = str(data_json[\"NodeCategoryIntegrity\"])\n                                prop_dict[\"soundscape:NomenclatureNode\"]
          = str(data_json[\"NomenclatureNode\"])\n                                prop_dict[\"soundscape:SerialNumber\"]
          = str(data_json[\"SerialNumber\"])\n                                prop_dict[\"soundscape:aggr\"]
          = str(aggr_type)\n                                prop_dict[\"soundscape:cycle_config_aware_start\"]
          = str(data_json[\"product_configs\"][''hasher_config''][''kwargs''][''aware_start''])\n                                prop_dict[\"soundscape:cycle_config_start_format\"]
          = str(data_json[\"product_configs\"][''hasher_config''][''kwargs''][''start_format''])\n                                prop_dict[\"soundscape:cycle_config_start_time\"]
          =  datetime.datetime.strptime(data_json[\"product_configs\"][''hasher_config''][''kwargs''][''start_time''],
          \n                                                                                                        \"%Y-%m-%d
          %H:%M:%S\").strftime(\"%Y-%m-%dT%H:%M:%S.%f%z\")\n                                prop_dict[\"soundscape:cycle_config_start_tzone\"]
          = str(data_json[\"product_configs\"][''hasher_config''][''kwargs''][''start_tzone''])\n                                prop_dict[\"soundscape:cycle_config_time_module\"]
          = int(data_json[\"product_configs\"][''hasher_config''][''kwargs''][''time_module''])\n                                prop_dict[\"soundscape:cycle_config_time_unit\"]
          = str(data_json[\"product_configs\"][''hasher_config''][''kwargs''][''time_unit''])\n                                prop_dict[\"soundscape:cycle_config_time_utc_column\"]
          = str(data_json[\"product_configs\"][''hasher_config''][''kwargs''][''time_utc_column''])\n                                prop_dict[\"soundscape:frequency_bins\"]
          = int(data_json[\"product_configs\"][\"slice_config\"][\"frequency_bins\"])\n                                prop_dict[\"soundscape:frequency_hop\"]
          = int(data_json[\"product_configs\"][\"slice_config\"][\"frequency_hop\"])\n                                prop_dict[\"soundscape:frequency_limits\"]
          = str(data_json[\"product_configs\"][\"slice_config\"][\"frequency_limits\"])\n                                prop_dict[\"soundscape:hash_name\"]
          = str(data_json[\"product_configs\"][\"hash_name\"])\n                                prop_dict[\"soundscape:hop_length\"]
          = int(data_json[\"product_configs\"][\"slice_config\"][\"feature_config\"][\"hop_length\"])\n                                prop_dict[\"soundscape:indices\"]
          =  \", \".join(map(str, data_json[''product_configs''][''indices'']))\n                                prop_dict[\"soundscape:n_fft\"]
          = int(data_json[\"product_configs\"][\"slice_config\"][\"feature_config\"][\"n_fft\"])\n                                prop_dict[\"soundscape:npartitions\"]
          = int(data_json[\"product_configs\"][''npartitions''])\n                                prop_dict[\"soundscape:product_name\"]
          = str(data_json[\"product_name\"])\n                                prop_dict[\"soundscape:product_parent\"]
          = str(data_json[\"product_parent\"])\n                                prop_dict[\"soundscape:product_path\"]
          = str(alfresco_path)\n                                prop_dict[\"soundscape:product_spectrum\"]
          = str(data_json[\"product_spectrum\"])\n                                prop_dict[\"soundscape:slice_config_feature_type\"]
          = str(data_json[\"product_configs\"][\"slice_config\"][\"feature_type\"])\n                                prop_dict[\"soundscape:slice_config_frequency_bins\"]
          = int(data_json[\"product_configs\"][\"slice_config\"][\"frequency_bins\"])\n                                prop_dict[\"soundscape:slice_config_time_unit\"]
          = int(data_json[\"product_configs\"][\"slice_config\"][\"time_unit\"])\n                                prop_dict[\"soundscape:time_hop\"]
          = int(data_json[\"product_configs\"][\"slice_config\"][\"time_hop\"])\n                                prop_dict[\"soundscape:window_function\"]
          = str(data_json[\"product_configs\"][\"slice_config\"][\"feature_config\"][\"window_function\"])  \n\n                            elif
          (\"spectrogram\" or \"video\") in entry[''entry''][''name'']:\n                                prop_dict[\"soundscape:product_name\"]
          = str(data_json[\"product_name\"])\n                                prop_dict[\"soundscape:product_parent\"]
          = str(data_json[\"product_parent\"])\n                                prop_dict[\"soundscape:product_path\"]
          = str(alfresco_path)\n                                prop_dict[\"soundscape:product_spectrum\"]
          = str(data_json[\"product_spectrum\"])\n                                prop_dict[\"soundscape:CumulusName\"]
          = str(data_json[\"CumulusName\"])\n                                prop_dict[\"soundscape:NodeCategoryIntegrity\"]
          = str(data_json[\"NodeCategoryIntegrity\"])\n                                prop_dict[\"soundscape:NomenclatureNode\"]
          = str(data_json[\"NomenclatureNode\"])\n                                prop_dict[\"soundscape:SerialNumber\"]
          = str(data_json[\"SerialNumber\"])\n                                prop_dict[\"soundscape:DateDeployment\"]
          = data_json[\"DateDeployment\"]\n                                prop_dict[\"soundscape:AudioID\"]
          = data_json[\"AudioID\"]\n\n                        aspects = entry[''entry''][''aspectNames'']\n                        data
          = {\"aspectNames\": aspects, \"nodeType\": node_type, \"properties\": prop_dict}\n                        #
          update properties request\n                        update = session.put(\n                            os.getenv(\"ALFRESCO_URL\")\n                            +
          BASE_ENDPOINT\n                            + \"/nodes/\"\n                            +
          entry[''entry''][''id''],\n                            data=json.dumps(data),\n                        )\n\n                        if
          update.status_code == 200:\n                            print(\"Updated
          \" + entry[''entry''][''id''])                    \n\n        except Exception
          as e:\n            print(\"Could not add any aspect to this file: \", e)\n\n    def
          create_results_folder_str(results_dir, cumulo, nodes_list, rec_list, dep_list):
          \n        # results directory\n        os.makedirs(results_dir, exist_ok=True)\n        #
          cumulus subdir\n        cum_subdir = os.path.join(results_dir, str(cumulo))\n        os.makedirs(cum_subdir,
          exist_ok=True)\n        # node subdirs\n        for node in nodes_list:\n            node_subdir
          = os.path.join(cum_subdir, node)\n            os.makedirs(node_subdir, exist_ok=True)\n            #
          recorder subdirs\n            for rec in rec_list:\n                rec_subdir
          = os.path.join(node_subdir, rec)\n                os.makedirs(rec_subdir,
          exist_ok=True)\n                # deployment subdirs\n                for
          dep in dep_list:\n                    dep_subdir = os.path.join(rec_subdir,
          dep)\n                    os.makedirs(dep_subdir, exist_ok=True)\n\n    def
          distance_to_mean(vector, mean):\n        \\''\\''\\''Return euclidean distance
          to mean\\''\\''\\''\n        return np.sqrt(np.sum(np.square(mean - vector)))\n\n    def
          find_subfolders(path_abs):\n        subdir_list = []\n        walk = list(os.walk(path_abs))\n        for
          path, _, _ in walk[::-1]:\n            len_path = path.split(\"/\")\n            if
          len(len_path) == 8:\n                subdir_list.append(path)  \n\n        return
          subdir_list\n\n    def get_audio_ids(soundscape_path, indices, nsamples):\n        df
          = pd.read_parquet(os.path.join(soundscape_path, \"hashed_soundscape.parquet\"))\n\n        df[\"time_raw_hour\"]
          = df[\"time_raw\"].apply(lambda x: datetime.datetime.strptime(x,''%H:%M:%S
          %d/%m/%Y (%z)'').strftime(\"%H\"))\n        hours_list = list(df.time_raw_hour.unique())\n        hours_list.sort(key
          = int)\n\n        with open(os.path.join(soundscape_path, \"soundscape_metadata.json\"))
          as f:\n            metadata = json.load(f)\n            f.close()\n\n        #
          indices = metadata[\"product_configs\"][\"indices\"]\n        # indices
          = [\"EXAG\", \"ICOMPLEXITY\", \"CORE\"]\n        hash_name = metadata[\"product_configs\"][\"hash_name\"]\n        cycle_config
          = metadata[\"product_configs\"][\"hasher_config\"][\"kwargs\"]\n        time_unit
          = cycle_config[\"time_unit\"]\n        zero_t = aware_time(cycle_config[\"start_time\"],
          cycle_config[\"start_tzone\"], cycle_config[\"start_format\"]) \n\n        #
          iterate over hours\n        audio_id_list = []\n        for hour in hours_list:\n            subdf
          = df.query(f\"time_raw_hour == ''{hour}''\")\n            # sample\n            samples_df
          = get_recording_samples(subdf, hash_name, indices, time_unit, zero_t, nsamples=3)\n            unique_crono_hash_list
          = list(samples_df.crono_hash_30m.unique())\n            sub_df = samples_df[samples_df.crono_hash_30m
          == min(unique_crono_hash_list)]\n            audio_id_list += list(sub_df.id.tolist())\n\n        return
          audio_id_list\n\n    def get_recording_samples(df, hash_name, indices, time_unit,
          zero_t, nsamples=5):\n        \\''\\''\\''Return dataframe of ''nsamples''
          samples for each tag in ''hash_name'' column that are closest to the mean
          vector by tag\\''\\''\\''\n        proj_df = df[(df.max_freq <= 10000)]\n        crono_tags
          = proj_df.crono_hash_30m.unique()\n        proj_df.loc[: , f\"{hash_name}_time\"]
          = proj_df[hash_name].apply(lambda x: zero_t + datetime.timedelta(seconds=float(x*time_unit)))\n        vectors
          = vectorize_soundscape(proj_df, hash_name, indices)\n        min_index_vector
          = np.amin(np.stack(list(vectors.index_vector.values)), axis=(0,1))\n        max_index_vector
          = np.amax(np.stack(list(vectors.index_vector.values)), axis=(0,1))\n        index_range
          = (max_index_vector - min_index_vector)\n        vectors.loc[:, \"normalized_index_vector\"]
          = vectors.index_vector.apply(lambda x: (x-min_index_vector)/index_range)\n        all_samples
          = []\n\n        for crono_tag in crono_tags:\n            unit_vectors =
          vectors[vectors[hash_name] == crono_tag]\n            mean_unit_vector =
          unit_vectors.normalized_index_vector.mean()\n            unit_vectors.loc[:,
          \"distance\"] = unit_vectors.normalized_index_vector.apply(lambda x: distance_to_mean(x,
          mean_unit_vector))\n            all_samples.append(unit_vectors.sort_values(by=\"distance\").head(nsamples))\n        return
          pd.concat(all_samples)\n\n    def get_vectors(group, indices):\n        \\''\\''\\''Return
          array of indices by frequency\\''\\''\\''\n        return group.sort_values(by=\"max_freq\")[indices].values\n\n    def
          login():\n        \"\"\"\n        Tries a login to alfresco api and returns
          a session\n        object with credentials \n        Returns: \n            session
          (Session):  A session object to make \n                                requests
          to zendro.\n        \"\"\"\n        try:\n            auth = {\n                \"userId\":
          os.getenv(\"ALFRESCO_USER\"),\n                \"password\": os.getenv(\"ALFRESCO_PASSWORD\"),\n            }\n\n            login
          = requests.post(os.getenv(\"ALFRESCO_URL\") + AUTH_ENDPOINT + \"/tickets\",data=json.dumps(auth))\n\n            base64_login
          = base64.b64encode(bytes(login.json()[\"entry\"][\"id\"], ''utf-8'')).decode()\n\n            #
          se crea un objeto de Session para hacer requests\n            session =
          requests.Session()\n            # se establece bearer token\n            session.headers.update({''Authorization'':
          ''Basic '' + base64_login})\n\n            return session\n        except
          Exception as e:\n            print(\"Login failed: \", e)\n\n    def plot_spectrogram(audio_id,
          audio_df, save_path_folder, spectrum, cumulus):\n        sub_audio_df =
          audio_df[audio_df[\"id\"]==audio_id]\n        node = sub_audio_df[''node''].values[0]\n        recorder
          = sub_audio_df[''recorder''].values[0]\n        deployment = sub_audio_df[''deployment''].values[0]\n        #
          plot\n        fig, ax = plt.subplots(2,1,figsize=(20,10), sharex=True)\n        sub_audio_df.audio[0].plot(ax=ax[0],
          color=''grey'')\n        sub_audio_df.audio[0].features.db_spectrogram().plot(ax=ax[1])\n        ax[0].set_ylabel(''Amplitude'')\n        ax[0].grid(False)\n        ax[1].set_ylabel(''F
          (KHz)'')\n        ax[1].set_xlabel(''Time (seconds)'')\n        fig.text(0.75,
          0.04, f\"Cumulus: {cumulus} - Node: {node} - Recorder: {recorder}\", va=''center'')\n        plt.tight_layout()\n        if
          save_path_folder:\n            file_path = os.path.join(save_path_folder,
          f\"{audio_id}.png\")\n            fig.savefig(file_path)\n        plt.show()\n\n        save_metadata_spectrogram(audio_id,
          spectrum, save_path_folder, \n                                  cumulus,
          node, recorder, deployment, parent=\"Null\")\n\n    def plot_soundscape(soundscape,
          product_type, product_spectrum, sc_config, path, \n                        cumulus,
          node, recorder, deployment, parent, indices, min_freq=None,\n                      figsize=(20,15),
          plt_style=''ggplot''):\n\n        if min_freq:\n            soundscape =
          soundscape[soundscape[''min_freq'']<=min_freq]\n\n        if product_type
          == \"sequence\":\n            file_path = os.path.join(path, \"sequence.png\")\n            #
          product_id = hashlib.md5(file_path.encode(''utf-8'')).hexdigest()\n\n            plt.style.use(plt_style)\n            fig,
          ax = plt.subplots(figsize=figsize)\n            soundscape.sndscape.plot_sequence(rgb=indices,
          time_format=''%Y-%m %H:%M'', ax=ax)\n            plt.xticks(rotation = 90)\n            ax.grid(False)\n            plt.tight_layout()\n            plt.savefig(file_path)
          \n            plt.show()\n            # save metadata\n            save_metadata_sc(product_type,
          product_spectrum, sc_config,\n                      path, cumulus, node,
          recorder, deployment, parent=parent)\n\n        elif product_type == \"standard_deviation\":\n            file_path
          = os.path.join(path, \"std_soundscape.png\")\n            # product_id =
          hashlib.md5(file_path.encode(''utf-8'')).hexdigest()\n\n            plt.style.use(plt_style)\n            fig,
          ax = plt.subplots(figsize=figsize)\n            soundscape.sndscape.plot_cycle(rgb=indices,
          aggr=\"std\", time_format=''%H:%M'', \n                                           xticks=24,
          ax=ax)\n            plt.xticks(rotation = 90)\n            ax.grid(False)\n            plt.tight_layout()
          \n            plt.savefig(file_path)\n            plt.show()\n\n            #
          save metadata\n            save_metadata_sc(product_type, product_spectrum,
          sc_config,\n                      path, cumulus, node, recorder, deployment,
          parent)     \n\n        elif product_type == \"mean\": \n            file_path
          = os.path.join(path, \"mean_soundscape.png\")\n            # product_id
          = hashlib.md5(file_path.encode(''utf-8'')).hexdigest()\n\n            plt.style.use(plt_style)\n            fig,
          ax = plt.subplots(figsize=figsize)\n            soundscape.sndscape.plot_cycle(rgb=indices,
          aggr=\"mean\", time_format=''%H:%M'', \n                                           xticks=24,
          ax=ax)\n            plt.xticks(rotation = 90)\n            ax.grid(False)\n            plt.tight_layout()\n            plt.savefig(file_path)\n            plt.show()\n\n            #
          save metadata\n            save_metadata_sc(product_type, product_spectrum,
          sc_config,\n                      path, cumulus, node, recorder, deployment,
          parent)    \n\n        print(f\"File saved at {file_path}\")\n\n    def
          produce_clip(spec, frame_duration, min_freq, max_freq, start, stop, step,
          abs_start=None, \n                     colormap=cm.get_cmap(\"Greys\"),
          min_spec=0, spec_range=1.0, figsize=(5, 4), \n                     dpi=100,
          bands=None):\n        \\''\\''\\''Takes an individual frame and produces
          an image with references\\''\\''\\''\n        frame = spec.cut_array(start_time=start,
          end_time=stop, min_freq=min_freq, max_freq=max_freq, pad=True)\n        plt.style.use(''dark_background'')\n        frame
          = np.flip((frame - min_spec)/spec_range, axis=0)\n        fig, ax = plt.subplots(figsize=figsize)\n        ax.imshow(frame,
          cmap=colormap, extent=[0, frame_duration, min_freq/1000, max_freq/1000],
          \n                  aspect=\"auto\", vmin = 0, vmax = 1.0)\n\n        if
          bands is not None:\n            band_arr = np.flip(resize(np.expand_dims(bands,
          axis=1), (frame.shape[0], frame.shape[1])), axis=0)\n            ax.imshow(band_arr,
          extent=[0, frame_duration, min_freq/1000, max_freq/1000], aspect=\"auto\",
          vmin = 0, \n                      vmax = 1.0, alpha=0.5)\n\n        ax.tick_params(axis=''both'',
          which=''major'', labelsize=8)\n        ax.tick_params(axis=''both'', which=''minor'',
          labelsize=8)\n        mid = frame_duration/2.0\n        ax.axvline(x=mid,
          color=\"red\")\n        ax.set_ylabel(''F (kHz)'')\n        ax.set_xticks([])\n        ax.set_xticks([],
          minor=True)\n\n        if abs_start is not None:\n            time_text
          = (abs_start + datetime.timedelta(seconds=start+mid)).strftime(''%H:%M:%S.%f'').strip()[:-4]\n            ax.text(mid-0.3,
          -0.6, time_text)\n\n        buf = io.BytesIO()\n        fig.tight_layout()\n        fig.savefig(buf,
          dpi=dpi)\n        buf.seek(0)\n        im = Image.open(buf)\n        im.format
          = \"PNG\"\n        plt.close(fig)\n\n        return ImageClip(np.asarray(im),\n                         duration=step)\n\n    def
          remove_empty_folders(path_abs):\n        walk = list(os.walk(path_abs))\n        for
          path, _, _ in walk[::-1]:\n            if len(os.listdir(path)) == 0:\n                os.rmdir(path)            \n\n    def
          save_metadata_sc(product_type, product_spectrum, sc_config,\n                      path,
          cumulus, node, recorder, deployment, parent=\"Null\"):\n        if product_type
          == \"soundscape\":\n            product_name = \"Soundscape\"\n            file_path
          = os.path.join(path, \"hashed_soundscape.parquet\")\n            metadata_filename
          = os.path.join(path, \"soundscape_metadata.json\")\n        elif product_type
          == \"sequence\":\n            product_name = \"Soundscape sequential plot\"\n            file_path
          = os.path.join(path, \"soundscape_seq.png\")\n            metadata_filename
          = os.path.join(path, \"soundscape_seq_metadata.json\")\n        elif product_type
          == \"standard_deviation\":\n            product_name = \"Soundscape standard
          deviation plot\"\n            file_path = os.path.join(path, \"std_soundscape.png\")\n            metadata_filename
          = os.path.join(path, \"std_soundscape_metadata.json\")\n        elif product_type
          == \"mean\":\n            product_name = \"Soundscape mean plot\"\n            file_path
          = os.path.join(path, \"mean_soundscape.png\")\n            metadata_filename
          = os.path.join(path, \"mean_soundscape_metadata.json\")\n\n        if int(node.split(\"_\")[2])
          == 0:\n            node_category = \"Degradado\"\n        elif int(node.split(\"_\")[2])
          == 1:\n            node_category = \"Integro\"\n\n        metadata = {\n            \"product_parent\":
          parent,\n            \"product_name\": product_name,\n            \"product_configs\":
          sc_config,\n            \"product_path\": file_path,\n            \"product_spectrum\":
          product_spectrum,\n            \"CumulusName\": cumulus,\n            \"NodeCategoryIntegrity\":
          node_category,\n            \"NomenclatureNode\": node,\n            \"SerialNumber\":
          recorder,\n            \"DateDeployment\": deployment\n        }\n\n        with
          open(metadata_filename, ''w'', encoding=''utf-8'') as f:\n            json.dump(metadata,
          f, ensure_ascii=False, indent=4)\n\n    def save_metadata_spectrogram(audio_id,
          product_spectrum,\n                      path, cumulus, node, recorder,
          deployment, parent=\"Null\"):\n        # identifier is being used as audio_id
          in alfresco\n        product_name = \"Spectrogram\"\n        file_path =
          os.path.join(path, f\"{audio_id}.png\")\n        metadata_filename = os.path.join(path,
          f\"{audio_id}_spectrogram_metadata.json\")\n\n        if int(node.split(\"_\")[2])
          == 0:\n            node_category = \"Degradado\"\n        elif int(node.split(\"_\")[2])
          == 1:\n            node_category = \"Integro\"\n\n        metadata = {\n            \"product_parent\":
          parent,\n            \"product_name\": product_name,\n            \"product_path\":
          file_path,\n            \"product_spectrum\": product_spectrum,\n            \"CumulusName\":
          cumulus,\n            \"NodeCategoryIntegrity\": node_category,\n            \"NomenclatureNode\":
          node,\n            \"SerialNumber\": recorder,\n            \"DateDeployment\":
          deployment,\n            \"AudioID\": audio_id\n        }\n        with
          open(metadata_filename, ''w'', encoding=''utf-8'') as f:\n            json.dump(metadata,
          f, ensure_ascii=False, indent=4)\n\n        print(f\"{file_path} saved.\")\n        print(f\"{metadata_filename}
          saved.\")\n\n    def save_metadata_videoclip(audio_id, product_spectrum,
          path, cumulus, node, recorder, \n                                deployment,
          clip_start, clip_end, parent=\"Null\"):\n        # identifier is being used
          as audio_id in alfresco\n        product_name = \"spectrogram_video\"\n        file_path
          = os.path.join(path, f\"{audio_id}.mp4\")\n        metadata_filename = os.path.join(path,
          f\"{audio_id}_spectrogram_video_metadata.json\")\n\n        if int(node.split(\"_\")[2])
          == 0:\n            node_category = \"Degradado\"\n        elif int(node.split(\"_\")[2])
          == 1:\n            node_category = \"Integro\"\n\n        metadata = {\n            \"product_parent\":
          parent,\n            \"product_name\": product_name,\n            \"product_description\":
          \"Spectrogram Video. Time is show in local timezone\",\n            \"product_path\":
          file_path,\n            \"product_spectrum\": product_spectrum,\n            \"CumulusName\":
          cumulus,\n            \"NodeCategoryIntegrity\": node_category,\n            \"NomenclatureNode\":
          node,\n            \"SerialNumber\": recorder,\n            \"DateDeployment\":
          deployment,\n            \"ClipStart\": clip_start,\n            \"ClipEnd\":
          clip_end,\n            \"AudioID\": audio_id\n        }\n\n        with
          open(metadata_filename, ''w'', encoding=''utf-8'') as f:\n            json.dump(metadata,
          f, ensure_ascii=False, indent=4)\n\n        print(f\"{file_path} saved.\")\n        print(f\"{metadata_filename}
          saved.\")\n\n    def upload(session, node_id, data, file):\n        \"\"\"\n        Uploads
          a file to a specific folder.\n        Parameters:\n            session (Session):          A
          session object to make\n                                        requests
          to alfresco.\n            node_id (string):           Node id to which the
          file is going to be created\n            data (dict):                Dict
          that contains file options\n            file (object):              File
          to upload\n\n        Returns:\n            (list):     A list containing
          status code and status data\n        \"\"\"\n\n        try:\n            response
          = session.post(os.getenv(\"ALFRESCO_URL\")\n                        + BASE_ENDPOINT
          + \"/nodes/\" + node_id + \"/children\",\n                        data =
          data,\n                        files = file\n                        )\n\n            return
          [response.json(), response.status_code];\n        except Exception as e:
          \n            print(\"File \" + data[\"name\"] + \" could not be uploaded:
          \", e)\n\n    def upload_files(file_patterns, session, node_id, dir_path,
          recursive, file_identifier=\"\"):\n        \"\"\"\n        Uploads the files
          stored in a specific dir\n        to alfresco\n        Parameters:\n            session
          (Session):          A session object to make\n                                        requests
          to alfresco.\n            node_id (string):           Node id to which the
          file is going to be created\n            dir_path (string):          The
          name and path of the dir where files are stored\n            recursive (boolean):        A
          boolean to know if upload  must be recursive\n                                        in
          the specifed dir, and should preserve the\n                                        structure
          of dirs inside.\n            file_identifier (string):   File identifier
          for all files inside a dir\n        Returns:\n            (string):           Returns
          the info of recent created site.\n        \"\"\"\n\n        if recursive:\n            expression
          = \"/**/*\"\n        else:\n            expression = \"/*\"\n\n        files_in_dir
          = list(\n            itertools.chain.from_iterable(\n                glob.iglob(dir_path
          + expression + pattern, recursive=recursive)\n                for pattern
          in file_patterns\n            )\n        )\n        filename = \"logs/upload_log\"
          + dir_path.replace(''/'',''-'') + ''.txt''\n\n        os.makedirs(os.path.dirname(filename),
          exist_ok=True)\n\n        total_files = len(files_in_dir)\n        starttime
          = time.time()\n\n        try:\n            files_uploaded = []\n            for
          idx, file_with_path in enumerate(files_in_dir):\n\n                # total
          time since last login or script start\n                total_time = round((time.time()
          - starttime), 2)\n\n                if total_time > 2400:\n                    \"\"\"\n                    if
          total time is bigger than 2400\n                    or 40 minutes relogin
          to avoid ticket\n                    expiration\n                    \"\"\"\n                    time.sleep(5)\n\n                    print(\"Re-logging
          in to alfresco...\")\n\n                    session = login.login()\n                    #
          restart time\n                    starttime = time.time()\n                    time.sleep(5)\n                    print(\"Login
          sucessful, continuing upload\\\\n\")\n\n                len_of_path = len(file_with_path.split(\"/\"))\n                name_of_file
          = file_with_path.split(\"/\")[len_of_path - 1]\n                root_dir_path
          = file_with_path.replace(dir_path, \"\").replace(\n                    file_with_path.split(\"/\")[len_of_path
          - 1], \"\"\n                )\n\n                data = {\n                    \"name\":
          (\n                        name_of_file[0 : len(name_of_file) - 4]\n                        +
          file_identifier\n                        + name_of_file[len(name_of_file)
          - 4 : len(name_of_file)]\n                    ),\n                    \"nodeType\":
          \"cm:content\",\n                }\n\n                data[\"relativePath\"]
          = root_dir_path\n\n                data[\"properties\"] = {\n                    \"cm:title\":
          (\n                        name_of_file[0 : len(name_of_file) - 4]\n                        +
          file_identifier\n                        + name_of_file[len(name_of_file)
          - 4 : len(name_of_file)]\n                    )\n                }\n\n                print(\"Uploading
          \" + data[\"name\"] + \" file...\")\n\n                files = {\"filedata\":
          open(file_with_path, \"rb\")}\n                upload_response = upload(session,
          node_id, data, files)\n                if upload_response[1] and upload_response[1]
          == 201:\n                    files_uploaded.append(upload_response[0])\n                    print(\"Uploaded
          \" + data[\"name\"])\n\n                    filename = \"logs/upload_log\"
          + dir_path.replace(''/'',''-'') + ''.txt''\n                    with open(filename,
          ''a'') as log_file:\n                        log_file.writelines(\"%s\\\\n\"
          % file_with_path)\n\n                elif upload_response[1] and upload_response[1]
          == 409:\n                    if \"already exists\" in upload_response[0][\"error\"][\"errorKey\"]:\n                        print(\"File
          \" + data[\"name\"] + \" already uploaded\")\n\n                else:\n                    print(\"An
          error ocurred, file \" + data[\"name\"] + \" cannot be uploaded\")\n\n                print(\"Uploaded
          file \" + str(idx + 1) + \" of \" + str(total_files))\n                print(\"\\\\n\\\\n\")\n\n            return
          files_uploaded\n        except Exception as e:\n            print(\"An error
          ocurred in file upload: \", e)\n\n    def vectorize_soundscape(df, hash_name,
          indices):\n        \\''\\''\\''Return dataframe with array column containing
          indices by frequency\\''\\''\\''\n        return (df\n                .groupby(by=[\"id\",
          hash_name, \"start_time\", \"end_time\"])\n                .apply(get_vectors,
          indices)\n                .reset_index()\n                .rename(columns={0:\"index_vector\"}))\n    ''''''\n\n    _kale_block3
          = ''''''\n    plt.style.use(''dark_background'')\n    warnings.filterwarnings(''ignore'')\n\n    sub_folder_results
          = find_subfolders(RESULTS_DIR)\n\n    for sc_path in sub_folder_results:\n        #
          parquet_file_path = os.path.join(sc_path, \"hashed_soundscape.parquet\")\n        if
          \"hashed_soundscape.parquet\" in os.listdir(sc_path):\n            print(f\"Processing
          results folder {sc_path}\")\n\n            # filter dataframe by hour\n            ids_audios
          = get_audio_ids(sc_path, indices = [RED_IDX, GREEN_IDX, BLUE_IDX], nsamples=VIDS_PER_HOUR)\n            for
          id_audio in ids_audios:\n                print(f\"Processing audio {id_audio}\")\n                try:\n                    plot_spectrogram(id_audio,
          recs, sc_path, SPECTRUM, CUMULO)   \n                    audio2video(id_audio,
          id_audio, recs, sc_path, SPECTRUM, CUMULO)\n                except:\n                    pass\n\n        else:\n            print(f\"hashed_soundscape.parquet
          not found in {sc_path}\")\n    ''''''\n\n    _kale_data_saving_block = ''''''\n    #
          -----------------------DATA SAVING START---------------------------------\n    from
          kale import marshal as _kale_marshal\n    _kale_marshal.set_data_dir(\"/shared_volume/audio/.sndscs_spec_specvid-sipecam-cumulus-node-recorder-deployment-aws.ipynb.kale.marshal.dir\")\n    _kale_marshal.save(sub_folder_results,
          \"sub_folder_results\")\n    # -----------------------DATA SAVING END-----------------------------------\n    ''''''\n\n    #
          run the code blocks inside a jupyter kernel\n    from kale.common.jputils
          import run_code as _kale_run_code\n    from kale.common.kfputils import
          \\\n        update_uimetadata as _kale_update_uimetadata\n    _kale_blocks
          = (_kale_pipeline_parameters_block, _kale_data_loading_block,\n                    _kale_block1,\n                    _kale_block2,\n                    _kale_block3,\n                    _kale_data_saving_block)\n    _kale_html_artifact
          = _kale_run_code(_kale_blocks)\n    with open(\"/spec_n_specvid.html\",
          \"w\") as f:\n        f.write(_kale_html_artifact)\n    _kale_update_uimetadata(''spec_n_specvid'')\n\n    _kale_mlmdutils.call(\"mark_execution_complete\")\n\nimport
          argparse\n_parser = argparse.ArgumentParser(prog=''Spec n specvid'', description='''')\n_parser.add_argument(\"--AUTH-ENDPOINT\",
          dest=\"AUTH_ENDPOINT\", type=str, required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"--BASE-ENDPOINT\",
          dest=\"BASE_ENDPOINT\", type=str, required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"--BLUE-IDX\",
          dest=\"BLUE_IDX\", type=str, required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"--CUMULO\",
          dest=\"CUMULO\", type=int, required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"--GREEN-IDX\",
          dest=\"GREEN_IDX\", type=str, required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"--RED-IDX\",
          dest=\"RED_IDX\", type=str, required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"--RESULTS-DIR\",
          dest=\"RESULTS_DIR\", type=str, required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"--SPECTRUM\",
          dest=\"SPECTRUM\", type=str, required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"--VIDS-PER-HOUR\",
          dest=\"VIDS_PER_HOUR\", type=int, required=True, default=argparse.SUPPRESS)\n_parsed_args
          = vars(_parser.parse_args())\n\n_outputs = spec_n_specvid(**_parsed_args)\n"],
          "image": "sipecam/audio-dgpi-kale-tensorflow-yuntu-dask-cert:0.6.1_dev"}},
          "inputs": [{"name": "AUTH_ENDPOINT", "type": "String"}, {"name": "BASE_ENDPOINT",
          "type": "String"}, {"name": "BLUE_IDX", "type": "String"}, {"name": "CUMULO",
          "type": "Integer"}, {"name": "GREEN_IDX", "type": "String"}, {"name": "RED_IDX",
          "type": "String"}, {"name": "RESULTS_DIR", "type": "String"}, {"name": "SPECTRUM",
          "type": "String"}, {"name": "VIDS_PER_HOUR", "type": "Integer"}], "name":
          "Spec n specvid"}', pipelines.kubeflow.org/component_ref: '{}', pipelines.kubeflow.org/arguments.parameters: '{"AUTH_ENDPOINT":
          "{{inputs.parameters.AUTH_ENDPOINT}}", "BASE_ENDPOINT": "{{inputs.parameters.BASE_ENDPOINT}}",
          "BLUE_IDX": "{{inputs.parameters.BLUE_IDX}}", "CUMULO": "{{inputs.parameters.CUMULO}}",
          "GREEN_IDX": "{{inputs.parameters.GREEN_IDX}}", "RED_IDX": "{{inputs.parameters.RED_IDX}}",
          "RESULTS_DIR": "{{inputs.parameters.RESULTS_DIR}}", "SPECTRUM": "{{inputs.parameters.SPECTRUM}}",
          "VIDS_PER_HOUR": "{{inputs.parameters.VIDS_PER_HOUR}}"}'}
      labels:
        pipelines.kubeflow.org/metadata_written: "true"
        pipelines.kubeflow.org/kfp_sdk_version: 1.8.11
        pipelines.kubeflow.org/pipeline-sdk-type: kfp
        pipelines.kubeflow.org/enable_caching: "true"
    volumes:
    - name: pvolume-ef6fe65091618f865041935b363277953274adf6b420fd4a7b8277d
      persistentVolumeClaim: {claimName: '{{inputs.parameters.vol_shared_volume}}'}
  - name: upload-alfresco-model-data
    container:
      args: [--ALFRESCO-NODE-ID, '{{inputs.parameters.ALFRESCO_NODE_ID}}', --AUTH-ENDPOINT,
        '{{inputs.parameters.AUTH_ENDPOINT}}', --BASE-ENDPOINT, '{{inputs.parameters.BASE_ENDPOINT}}']
      command:
      - sh
      - -ec
      - |
        program_path=$(mktemp)
        printf "%s" "$0" > "$program_path"
        python3 -u "$program_path" "$@"
      - "def upload_alfresco_model_data(ALFRESCO_NODE_ID, AUTH_ENDPOINT, BASE_ENDPOINT):\n\
        \    _kale_pipeline_parameters_block = '''\n    ALFRESCO_NODE_ID = \"{}\"\n\
        \    AUTH_ENDPOINT = \"{}\"\n    BASE_ENDPOINT = \"{}\"\n    '''.format(ALFRESCO_NODE_ID,\
        \ AUTH_ENDPOINT, BASE_ENDPOINT)\n\n    from kale.common import mlmdutils as\
        \ _kale_mlmdutils\n    _kale_mlmdutils.init_metadata()\n\n    _kale_data_loading_block\
        \ = '''\n    # -----------------------DATA LOADING START--------------------------------\n\
        \    from kale import marshal as _kale_marshal\n    _kale_marshal.set_data_dir(\"\
        /shared_volume/audio/.sndscs_spec_specvid-sipecam-cumulus-node-recorder-deployment-aws.ipynb.kale.marshal.dir\"\
        )\n    sub_folder_results = _kale_marshal.load(\"sub_folder_results\")\n \
        \   # -----------------------DATA LOADING END----------------------------------\n\
        \    '''\n\n    _kale_block1 = '''\n    import base64\n    import datetime\n\
        \    import glob\n    import hashlib\n    import io\n    import itertools\n\
        \    import json\n    import matplotlib.pyplot as plt\n    import multiprocessing\
        \ \n    import numpy as np\n    import os\n    import pandas as pd\n    import\
        \ psutil\n    import requests\n    import shutil\n    import subprocess\n\
        \    import time\n    import warnings\n\n    from dask.distributed import\
        \ Client, LocalCluster\n    from datetime import timedelta\n    from dotenv\
        \ import load_dotenv\n    from matplotlib import cm\n    from moviepy.editor\
        \ import concatenate, VideoFileClip, AudioFileClip\n    from moviepy.audio.AudioClip\
        \ import AudioArrayClip\n    from moviepy.video.VideoClip import ImageClip\n\
        \    from os.path import exists as file_exists\n    from PIL import Image\n\
        \    from skimage.transform import resize\n\n    from yuntu import Audio\n\
        \    from yuntu.soundscape.utils import aware_time\n    from yuntu.collection.methods\
        \ import collection\n    from yuntu.soundscape.hashers.crono import DEFAULT_HASHER_CONFIG\n\
        \    from yuntu.soundscape.processors.indices.direct import ICOMPLEXITY, TAIL\n\
        \    from yuntu.soundscape.pipelines.build_soundscape import CronoSoundscape,\
        \ HASHER_CONFIG\n    '''\n\n    _kale_block2 = '''\n    def audio2video(audio_id,\n\
        \                    audio_df,\n                    save_path_folder,\n  \
        \                  product_spectrum,\n                    cumulus,\n     \
        \               abs_start=None,\n                    fps=60,\n           \
        \         spec_configs={'hop_length': 512, 'n_fft': 1024, 'window_function':\
        \ 'hann'},\n                    rate=24,\n                    frame_duration=3.0,\n\
        \                    min_freq=0,\n                    max_freq=None,\n   \
        \                 cmap=\"Greys\",\n                    figsize=(5, 8),\n \
        \                   dpi=100,\n                    bands=None):\n        \\\
        '\\'\\'Takes and audio object and produces a mp4 video of the spectrogram\
        \ with audio\\'\\'\\'\n\n        sub_audio_df = audio_df[audio_df[\"id\"]==audio_id]\n\
        \        id_audio = sub_audio_df['id'].values[0]\n        node = sub_audio_df['node'].values[0]\n\
        \        recorder = sub_audio_df['recorder'].values[0]\n        deployment\
        \ = sub_audio_df['deployment'].values[0]\n        audio = sub_audio_df.audio[0]\n\
        \n        colormap = cm.get_cmap(cmap)\n        duration = audio.duration\n\
        \        step = 1/rate\n        start = -(frame_duration/2.0)\n        stop\
        \ = start + frame_duration\n        clips = []\n        last_stop = None\n\
        \n        if max_freq is None:\n            max_freq = audio.samplerate /\
        \ 2.0\n\n        if min_freq is None:\n            min_freq = 0\n\n      \
        \  with audio.features.db_spectrogram(**spec_configs) as spec:\n         \
        \   min_spec = np.amin(spec)\n            max_spec = np.amax(spec)\n     \
        \       spec_range = (max_spec-min_spec)\n\n            while stop <= duration+(frame_duration/2.0):\n\
        \                clip = produce_clip(spec, frame_duration, min_freq, max_freq,\
        \ start, stop, step, abs_start, colormap,\n                              \
        \      min_spec, spec_range, figsize, dpi, bands=bands)\n                clips.append(clip)\n\
        \n                if start + step + frame_duration > duration:\n         \
        \           last_stop = stop\n\n                start = start + step\n   \
        \             stop = start + frame_duration\n\n        video = concatenate(clips)\n\
        \        # edaudio = AudioArrayClip(audio_array, fps=audio.samplerate)\n \
        \       edaudio = AudioFileClip(audio.path).set_end(audio.duration)\n    \
        \    video = video.set_audio(edaudio)\n        file_path = os.path.join(save_path_folder,\
        \ f\"{audio_id}.mp4\")\n        video.write_videofile(file_path, fps=fps)\n\
        \n        save_metadata_videoclip(audio_id, product_spectrum,\n          \
        \            save_path_folder, cumulus, node, recorder, deployment, 0.0, audio.duration)\n\
        \        video.close()\n        edaudio.close()\n\n        for c in clips:\n\
        \            c.close()\n\n    def change_type_sipecam_sc(session, root_folder_id,\
        \ path, file_type, node_type):\n        if file_type == \"sequence.png\":\n\
        \            metadata_name = \"soundscape_seq_metadata.json\"\n          \
        \  aggr_type = \"None\"\n        elif file_type == \"mean_soundscape.png\"\
        :\n            metadata_name = \"mean_soundscape_metadata.json\"\n       \
        \     aggr_type = \"Mean\"\n        elif file_type ==  \"std_soundscape.png\"\
        :\n            metadata_name = \"std_soundscape_metadata.json\" \n       \
        \     aggr_type = \"Standard deviation\"\n        elif file_type == \"hashed_soundscape.parquet\"\
        :\n            metadata_name = \"soundscape_metadata.json\" \n           \
        \ aggr_type = \"None\"\n        elif \".png\" in file_type and (file_type\
        \ not in [\"sequence.png\", \"mean_soundscape.png\", \"std_soundscape.png\"\
        ]):\n            metadata_name = file_type.split(\".\")[0] + \"_spectrogram_metadata.json\"\
        \n            aggr_type = \"Null\"\n        elif \".mp4\" in file_type and\
        \ (file_type not in [\"sequence.png\", \"mean_soundscape.png\", \"std_soundscape.png\"\
        ]):\n            metadata_name = file_type.split(\".\")[0] + \"_spectrogram_video_metadata.json\"\
        \n            aggr_type = \"Null\"\n\n        try:\n            semi_path\
        \ = path.split(\"soundscapes/\")[-1]\n            semi_path_file = os.path.join(semi_path,\
        \ file_type)\n            local_path_file_metadata = os.path.join(path, metadata_name)\n\
        \            print(f\"Changing type for {os.path.join(semi_path)}\")\n   \
        \         alfresco_path = os.path.join(\"/Company Home/Sites/sipecam-soundscape/documentLibrary/\"\
        , semi_path)\n\n            response = session.get(\n                os.getenv(\"\
        ALFRESCO_URL\")\n                + BASE_ENDPOINT\n                + \"/nodes/\"\
        \n                + root_folder_id\n                + \"/children?relativePath=\"\
        +semi_path+\"&include=aspectNames&skipCount=0\"\n            )        \n \
        \           # if request is successful then continue\n            if response.status_code\
        \ == 200:\n\n                data_file = open(local_path_file_metadata)\n\
        \                data_json = json.load(data_file)\n                response_entries\
        \ = response.json()[\"list\"][\"entries\"]\n\n                for entry in\
        \ response_entries:\n                    if entry['entry']['name']==file_type\
        \ and entry['entry']['isFile']:\n                        prop_dict = {}\n\n\
        \                        if entry['entry']['name']==file_type:\n\n       \
        \                     if entry['entry']['name'] in [\"sequence.png\", \"mean_soundscape.png\"\
        , \"std_soundscape.png\"]:\n                                prop_dict[\"soundscape:CumulusName\"\
        ] = str(data_json[\"CumulusName\"])\n                                prop_dict[\"\
        soundscape:DateDeployment\"] = data_json[\"DateDeployment\"]\n           \
        \                     prop_dict[\"soundscape:NodeCategoryIntegrity\"] = str(data_json[\"\
        NodeCategoryIntegrity\"])\n                                prop_dict[\"soundscape:NomenclatureNode\"\
        ] = str(data_json[\"NomenclatureNode\"])\n                               \
        \ prop_dict[\"soundscape:SerialNumber\"] = str(data_json[\"SerialNumber\"\
        ])\n                                prop_dict[\"soundscape:aggr\"] = str(aggr_type)\n\
        \                                prop_dict[\"soundscape:cycle_config_aware_start\"\
        ] = str(data_json[\"product_configs\"]['hasher_config']['kwargs']['aware_start'])\n\
        \                                prop_dict[\"soundscape:cycle_config_start_format\"\
        ] = str(data_json[\"product_configs\"]['hasher_config']['kwargs']['start_format'])\n\
        \                                prop_dict[\"soundscape:cycle_config_start_time\"\
        ] =  datetime.datetime.strptime(data_json[\"product_configs\"]['hasher_config']['kwargs']['start_time'],\
        \ \n                                                                     \
        \                                   \"%Y-%m-%d %H:%M:%S\").strftime(\"%Y-%m-%dT%H:%M:%S.%f%z\"\
        )\n                                prop_dict[\"soundscape:cycle_config_start_tzone\"\
        ] = str(data_json[\"product_configs\"]['hasher_config']['kwargs']['start_tzone'])\n\
        \                                prop_dict[\"soundscape:cycle_config_time_module\"\
        ] = int(data_json[\"product_configs\"]['hasher_config']['kwargs']['time_module'])\n\
        \                                prop_dict[\"soundscape:cycle_config_time_unit\"\
        ] = str(data_json[\"product_configs\"]['hasher_config']['kwargs']['time_unit'])\n\
        \                                prop_dict[\"soundscape:cycle_config_time_utc_column\"\
        ] = str(data_json[\"product_configs\"]['hasher_config']['kwargs']['time_utc_column'])\n\
        \                                prop_dict[\"soundscape:frequency_bins\"]\
        \ = int(data_json[\"product_configs\"][\"slice_config\"][\"frequency_bins\"\
        ])\n                                prop_dict[\"soundscape:frequency_hop\"\
        ] = int(data_json[\"product_configs\"][\"slice_config\"][\"frequency_hop\"\
        ])\n                                prop_dict[\"soundscape:frequency_limits\"\
        ] = str(data_json[\"product_configs\"][\"slice_config\"][\"frequency_limits\"\
        ])\n                                prop_dict[\"soundscape:hash_name\"] =\
        \ str(data_json[\"product_configs\"][\"hash_name\"])\n                   \
        \             prop_dict[\"soundscape:hop_length\"] = int(data_json[\"product_configs\"\
        ][\"slice_config\"][\"feature_config\"][\"hop_length\"])\n               \
        \                 prop_dict[\"soundscape:indices\"] =  \", \".join(map(str,\
        \ data_json['product_configs']['indices']))\n                            \
        \    prop_dict[\"soundscape:n_fft\"] = int(data_json[\"product_configs\"][\"\
        slice_config\"][\"feature_config\"][\"n_fft\"])\n                        \
        \        prop_dict[\"soundscape:npartitions\"] = int(data_json[\"product_configs\"\
        ]['npartitions'])\n                                prop_dict[\"soundscape:product_name\"\
        ] = str(data_json[\"product_name\"])\n                                prop_dict[\"\
        soundscape:product_parent\"] = str(data_json[\"product_parent\"])\n      \
        \                          prop_dict[\"soundscape:product_path\"] = str(alfresco_path)\n\
        \                                prop_dict[\"soundscape:product_spectrum\"\
        ] = str(data_json[\"product_spectrum\"])\n                               \
        \ prop_dict[\"soundscape:slice_config_feature_type\"] = str(data_json[\"product_configs\"\
        ][\"slice_config\"][\"feature_type\"])\n                                prop_dict[\"\
        soundscape:slice_config_frequency_bins\"] = int(data_json[\"product_configs\"\
        ][\"slice_config\"][\"frequency_bins\"])\n                               \
        \ prop_dict[\"soundscape:slice_config_time_unit\"] = int(data_json[\"product_configs\"\
        ][\"slice_config\"][\"time_unit\"])\n                                prop_dict[\"\
        soundscape:time_hop\"] = int(data_json[\"product_configs\"][\"slice_config\"\
        ][\"time_hop\"])\n                                prop_dict[\"soundscape:window_function\"\
        ] = str(data_json[\"product_configs\"][\"slice_config\"][\"feature_config\"\
        ][\"window_function\"])  \n\n                            elif (\"spectrogram\"\
        \ or \"video\") in entry['entry']['name']:\n                             \
        \   prop_dict[\"soundscape:product_name\"] = str(data_json[\"product_name\"\
        ])\n                                prop_dict[\"soundscape:product_parent\"\
        ] = str(data_json[\"product_parent\"])\n                                prop_dict[\"\
        soundscape:product_path\"] = str(alfresco_path)\n                        \
        \        prop_dict[\"soundscape:product_spectrum\"] = str(data_json[\"product_spectrum\"\
        ])\n                                prop_dict[\"soundscape:CumulusName\"]\
        \ = str(data_json[\"CumulusName\"])\n                                prop_dict[\"\
        soundscape:NodeCategoryIntegrity\"] = str(data_json[\"NodeCategoryIntegrity\"\
        ])\n                                prop_dict[\"soundscape:NomenclatureNode\"\
        ] = str(data_json[\"NomenclatureNode\"])\n                               \
        \ prop_dict[\"soundscape:SerialNumber\"] = str(data_json[\"SerialNumber\"\
        ])\n                                prop_dict[\"soundscape:DateDeployment\"\
        ] = data_json[\"DateDeployment\"]\n                                prop_dict[\"\
        soundscape:AudioID\"] = data_json[\"AudioID\"]\n\n                       \
        \ aspects = entry['entry']['aspectNames']\n                        data =\
        \ {\"aspectNames\": aspects, \"nodeType\": node_type, \"properties\": prop_dict}\n\
        \                        # update properties request\n                   \
        \     update = session.put(\n                            os.getenv(\"ALFRESCO_URL\"\
        )\n                            + BASE_ENDPOINT\n                         \
        \   + \"/nodes/\"\n                            + entry['entry']['id'],\n \
        \                           data=json.dumps(data),\n                     \
        \   )\n\n                        if update.status_code == 200:\n         \
        \                   print(\"Updated \" + entry['entry']['id'])           \
        \         \n\n        except Exception as e:\n            print(\"Could not\
        \ add any aspect to this file: \", e)\n\n    def create_results_folder_str(results_dir,\
        \ cumulo, nodes_list, rec_list, dep_list): \n        # results directory\n\
        \        os.makedirs(results_dir, exist_ok=True)\n        # cumulus subdir\n\
        \        cum_subdir = os.path.join(results_dir, str(cumulo))\n        os.makedirs(cum_subdir,\
        \ exist_ok=True)\n        # node subdirs\n        for node in nodes_list:\n\
        \            node_subdir = os.path.join(cum_subdir, node)\n            os.makedirs(node_subdir,\
        \ exist_ok=True)\n            # recorder subdirs\n            for rec in rec_list:\n\
        \                rec_subdir = os.path.join(node_subdir, rec)\n           \
        \     os.makedirs(rec_subdir, exist_ok=True)\n                # deployment\
        \ subdirs\n                for dep in dep_list:\n                    dep_subdir\
        \ = os.path.join(rec_subdir, dep)\n                    os.makedirs(dep_subdir,\
        \ exist_ok=True)\n\n    def distance_to_mean(vector, mean):\n        \\'\\\
        '\\'Return euclidean distance to mean\\'\\'\\'\n        return np.sqrt(np.sum(np.square(mean\
        \ - vector)))\n\n    def find_subfolders(path_abs):\n        subdir_list =\
        \ []\n        walk = list(os.walk(path_abs))\n        for path, _, _ in walk[::-1]:\n\
        \            len_path = path.split(\"/\")\n            if len(len_path) ==\
        \ 8:\n                subdir_list.append(path)  \n\n        return subdir_list\n\
        \n    def get_audio_ids(soundscape_path, indices, nsamples):\n        df =\
        \ pd.read_parquet(os.path.join(soundscape_path, \"hashed_soundscape.parquet\"\
        ))\n\n        df[\"time_raw_hour\"] = df[\"time_raw\"].apply(lambda x: datetime.datetime.strptime(x,'%H:%M:%S\
        \ %d/%m/%Y (%z)').strftime(\"%H\"))\n        hours_list = list(df.time_raw_hour.unique())\n\
        \        hours_list.sort(key = int)\n\n        with open(os.path.join(soundscape_path,\
        \ \"soundscape_metadata.json\")) as f:\n            metadata = json.load(f)\n\
        \            f.close()\n\n        # indices = metadata[\"product_configs\"\
        ][\"indices\"]\n        # indices = [\"EXAG\", \"ICOMPLEXITY\", \"CORE\"]\n\
        \        hash_name = metadata[\"product_configs\"][\"hash_name\"]\n      \
        \  cycle_config = metadata[\"product_configs\"][\"hasher_config\"][\"kwargs\"\
        ]\n        time_unit = cycle_config[\"time_unit\"]\n        zero_t = aware_time(cycle_config[\"\
        start_time\"], cycle_config[\"start_tzone\"], cycle_config[\"start_format\"\
        ]) \n\n        # iterate over hours\n        audio_id_list = []\n        for\
        \ hour in hours_list:\n            subdf = df.query(f\"time_raw_hour == '{hour}'\"\
        )\n            # sample\n            samples_df = get_recording_samples(subdf,\
        \ hash_name, indices, time_unit, zero_t, nsamples=3)\n            unique_crono_hash_list\
        \ = list(samples_df.crono_hash_30m.unique())\n            sub_df = samples_df[samples_df.crono_hash_30m\
        \ == min(unique_crono_hash_list)]\n            audio_id_list += list(sub_df.id.tolist())\n\
        \n        return audio_id_list\n\n    def get_recording_samples(df, hash_name,\
        \ indices, time_unit, zero_t, nsamples=5):\n        \\'\\'\\'Return dataframe\
        \ of 'nsamples' samples for each tag in 'hash_name' column that are closest\
        \ to the mean vector by tag\\'\\'\\'\n        proj_df = df[(df.max_freq <=\
        \ 10000)]\n        crono_tags = proj_df.crono_hash_30m.unique()\n        proj_df.loc[:\
        \ , f\"{hash_name}_time\"] = proj_df[hash_name].apply(lambda x: zero_t + datetime.timedelta(seconds=float(x*time_unit)))\n\
        \        vectors = vectorize_soundscape(proj_df, hash_name, indices)\n   \
        \     min_index_vector = np.amin(np.stack(list(vectors.index_vector.values)),\
        \ axis=(0,1))\n        max_index_vector = np.amax(np.stack(list(vectors.index_vector.values)),\
        \ axis=(0,1))\n        index_range = (max_index_vector - min_index_vector)\n\
        \        vectors.loc[:, \"normalized_index_vector\"] = vectors.index_vector.apply(lambda\
        \ x: (x-min_index_vector)/index_range)\n        all_samples = []\n\n     \
        \   for crono_tag in crono_tags:\n            unit_vectors = vectors[vectors[hash_name]\
        \ == crono_tag]\n            mean_unit_vector = unit_vectors.normalized_index_vector.mean()\n\
        \            unit_vectors.loc[:, \"distance\"] = unit_vectors.normalized_index_vector.apply(lambda\
        \ x: distance_to_mean(x, mean_unit_vector))\n            all_samples.append(unit_vectors.sort_values(by=\"\
        distance\").head(nsamples))\n        return pd.concat(all_samples)\n\n   \
        \ def get_vectors(group, indices):\n        \\'\\'\\'Return array of indices\
        \ by frequency\\'\\'\\'\n        return group.sort_values(by=\"max_freq\"\
        )[indices].values\n\n    def login():\n        \"\"\"\n        Tries a login\
        \ to alfresco api and returns a session\n        object with credentials \n\
        \        Returns: \n            session (Session):  A session object to make\
        \ \n                                requests to zendro.\n        \"\"\"\n\
        \        try:\n            auth = {\n                \"userId\": os.getenv(\"\
        ALFRESCO_USER\"),\n                \"password\": os.getenv(\"ALFRESCO_PASSWORD\"\
        ),\n            }\n\n            login = requests.post(os.getenv(\"ALFRESCO_URL\"\
        ) + AUTH_ENDPOINT + \"/tickets\",data=json.dumps(auth))\n\n            base64_login\
        \ = base64.b64encode(bytes(login.json()[\"entry\"][\"id\"], 'utf-8')).decode()\n\
        \n            # se crea un objeto de Session para hacer requests\n       \
        \     session = requests.Session()\n            # se establece bearer token\n\
        \            session.headers.update({'Authorization': 'Basic ' + base64_login})\n\
        \n            return session\n        except Exception as e:\n           \
        \ print(\"Login failed: \", e)\n\n    def plot_spectrogram(audio_id, audio_df,\
        \ save_path_folder, spectrum, cumulus):\n        sub_audio_df = audio_df[audio_df[\"\
        id\"]==audio_id]\n        node = sub_audio_df['node'].values[0]\n        recorder\
        \ = sub_audio_df['recorder'].values[0]\n        deployment = sub_audio_df['deployment'].values[0]\n\
        \        # plot\n        fig, ax = plt.subplots(2,1,figsize=(20,10), sharex=True)\n\
        \        sub_audio_df.audio[0].plot(ax=ax[0], color='grey')\n        sub_audio_df.audio[0].features.db_spectrogram().plot(ax=ax[1])\n\
        \        ax[0].set_ylabel('Amplitude')\n        ax[0].grid(False)\n      \
        \  ax[1].set_ylabel('F (KHz)')\n        ax[1].set_xlabel('Time (seconds)')\n\
        \        fig.text(0.75, 0.04, f\"Cumulus: {cumulus} - Node: {node} - Recorder:\
        \ {recorder}\", va='center')\n        plt.tight_layout()\n        if save_path_folder:\n\
        \            file_path = os.path.join(save_path_folder, f\"{audio_id}.png\"\
        )\n            fig.savefig(file_path)\n        plt.show()\n\n        save_metadata_spectrogram(audio_id,\
        \ spectrum, save_path_folder, \n                                  cumulus,\
        \ node, recorder, deployment, parent=\"Null\")\n\n    def plot_soundscape(soundscape,\
        \ product_type, product_spectrum, sc_config, path, \n                    \
        \    cumulus, node, recorder, deployment, parent, indices, min_freq=None,\n\
        \                      figsize=(20,15), plt_style='ggplot'):\n\n        if\
        \ min_freq:\n            soundscape = soundscape[soundscape['min_freq']<=min_freq]\n\
        \n        if product_type == \"sequence\":\n            file_path = os.path.join(path,\
        \ \"sequence.png\")\n            # product_id = hashlib.md5(file_path.encode('utf-8')).hexdigest()\n\
        \n            plt.style.use(plt_style)\n            fig, ax = plt.subplots(figsize=figsize)\n\
        \            soundscape.sndscape.plot_sequence(rgb=indices, time_format='%Y-%m\
        \ %H:%M', ax=ax)\n            plt.xticks(rotation = 90)\n            ax.grid(False)\n\
        \            plt.tight_layout()\n            plt.savefig(file_path) \n   \
        \         plt.show()\n            # save metadata\n            save_metadata_sc(product_type,\
        \ product_spectrum, sc_config,\n                      path, cumulus, node,\
        \ recorder, deployment, parent=parent)\n\n        elif product_type == \"\
        standard_deviation\":\n            file_path = os.path.join(path, \"std_soundscape.png\"\
        )\n            # product_id = hashlib.md5(file_path.encode('utf-8')).hexdigest()\n\
        \n            plt.style.use(plt_style)\n            fig, ax = plt.subplots(figsize=figsize)\n\
        \            soundscape.sndscape.plot_cycle(rgb=indices, aggr=\"std\", time_format='%H:%M',\
        \ \n                                           xticks=24, ax=ax)\n       \
        \     plt.xticks(rotation = 90)\n            ax.grid(False)\n            plt.tight_layout()\
        \ \n            plt.savefig(file_path)\n            plt.show()\n\n       \
        \     # save metadata\n            save_metadata_sc(product_type, product_spectrum,\
        \ sc_config,\n                      path, cumulus, node, recorder, deployment,\
        \ parent)     \n\n        elif product_type == \"mean\": \n            file_path\
        \ = os.path.join(path, \"mean_soundscape.png\")\n            # product_id\
        \ = hashlib.md5(file_path.encode('utf-8')).hexdigest()\n\n            plt.style.use(plt_style)\n\
        \            fig, ax = plt.subplots(figsize=figsize)\n            soundscape.sndscape.plot_cycle(rgb=indices,\
        \ aggr=\"mean\", time_format='%H:%M', \n                                 \
        \          xticks=24, ax=ax)\n            plt.xticks(rotation = 90)\n    \
        \        ax.grid(False)\n            plt.tight_layout()\n            plt.savefig(file_path)\n\
        \            plt.show()\n\n            # save metadata\n            save_metadata_sc(product_type,\
        \ product_spectrum, sc_config,\n                      path, cumulus, node,\
        \ recorder, deployment, parent)    \n\n        print(f\"File saved at {file_path}\"\
        )\n\n    def produce_clip(spec, frame_duration, min_freq, max_freq, start,\
        \ stop, step, abs_start=None, \n                     colormap=cm.get_cmap(\"\
        Greys\"), min_spec=0, spec_range=1.0, figsize=(5, 4), \n                 \
        \    dpi=100, bands=None):\n        \\'\\'\\'Takes an individual frame and\
        \ produces an image with references\\'\\'\\'\n        frame = spec.cut_array(start_time=start,\
        \ end_time=stop, min_freq=min_freq, max_freq=max_freq, pad=True)\n       \
        \ plt.style.use('dark_background')\n        frame = np.flip((frame - min_spec)/spec_range,\
        \ axis=0)\n        fig, ax = plt.subplots(figsize=figsize)\n        ax.imshow(frame,\
        \ cmap=colormap, extent=[0, frame_duration, min_freq/1000, max_freq/1000],\
        \ \n                  aspect=\"auto\", vmin = 0, vmax = 1.0)\n\n        if\
        \ bands is not None:\n            band_arr = np.flip(resize(np.expand_dims(bands,\
        \ axis=1), (frame.shape[0], frame.shape[1])), axis=0)\n            ax.imshow(band_arr,\
        \ extent=[0, frame_duration, min_freq/1000, max_freq/1000], aspect=\"auto\"\
        , vmin = 0, \n                      vmax = 1.0, alpha=0.5)\n\n        ax.tick_params(axis='both',\
        \ which='major', labelsize=8)\n        ax.tick_params(axis='both', which='minor',\
        \ labelsize=8)\n        mid = frame_duration/2.0\n        ax.axvline(x=mid,\
        \ color=\"red\")\n        ax.set_ylabel('F (kHz)')\n        ax.set_xticks([])\n\
        \        ax.set_xticks([], minor=True)\n\n        if abs_start is not None:\n\
        \            time_text = (abs_start + datetime.timedelta(seconds=start+mid)).strftime('%H:%M:%S.%f').strip()[:-4]\n\
        \            ax.text(mid-0.3, -0.6, time_text)\n\n        buf = io.BytesIO()\n\
        \        fig.tight_layout()\n        fig.savefig(buf, dpi=dpi)\n        buf.seek(0)\n\
        \        im = Image.open(buf)\n        im.format = \"PNG\"\n        plt.close(fig)\n\
        \n        return ImageClip(np.asarray(im),\n                         duration=step)\n\
        \n    def remove_empty_folders(path_abs):\n        walk = list(os.walk(path_abs))\n\
        \        for path, _, _ in walk[::-1]:\n            if len(os.listdir(path))\
        \ == 0:\n                os.rmdir(path)            \n\n    def save_metadata_sc(product_type,\
        \ product_spectrum, sc_config,\n                      path, cumulus, node,\
        \ recorder, deployment, parent=\"Null\"):\n        if product_type == \"soundscape\"\
        :\n            product_name = \"Soundscape\"\n            file_path = os.path.join(path,\
        \ \"hashed_soundscape.parquet\")\n            metadata_filename = os.path.join(path,\
        \ \"soundscape_metadata.json\")\n        elif product_type == \"sequence\"\
        :\n            product_name = \"Soundscape sequential plot\"\n           \
        \ file_path = os.path.join(path, \"soundscape_seq.png\")\n            metadata_filename\
        \ = os.path.join(path, \"soundscape_seq_metadata.json\")\n        elif product_type\
        \ == \"standard_deviation\":\n            product_name = \"Soundscape standard\
        \ deviation plot\"\n            file_path = os.path.join(path, \"std_soundscape.png\"\
        )\n            metadata_filename = os.path.join(path, \"std_soundscape_metadata.json\"\
        )\n        elif product_type == \"mean\":\n            product_name = \"Soundscape\
        \ mean plot\"\n            file_path = os.path.join(path, \"mean_soundscape.png\"\
        )\n            metadata_filename = os.path.join(path, \"mean_soundscape_metadata.json\"\
        )\n\n        if int(node.split(\"_\")[2]) == 0:\n            node_category\
        \ = \"Degradado\"\n        elif int(node.split(\"_\")[2]) == 1:\n        \
        \    node_category = \"Integro\"\n\n        metadata = {\n            \"product_parent\"\
        : parent,\n            \"product_name\": product_name,\n            \"product_configs\"\
        : sc_config,\n            \"product_path\": file_path,\n            \"product_spectrum\"\
        : product_spectrum,\n            \"CumulusName\": cumulus,\n            \"\
        NodeCategoryIntegrity\": node_category,\n            \"NomenclatureNode\"\
        : node,\n            \"SerialNumber\": recorder,\n            \"DateDeployment\"\
        : deployment\n        }\n\n        with open(metadata_filename, 'w', encoding='utf-8')\
        \ as f:\n            json.dump(metadata, f, ensure_ascii=False, indent=4)\n\
        \n    def save_metadata_spectrogram(audio_id, product_spectrum,\n        \
        \              path, cumulus, node, recorder, deployment, parent=\"Null\"\
        ):\n        # identifier is being used as audio_id in alfresco\n        product_name\
        \ = \"Spectrogram\"\n        file_path = os.path.join(path, f\"{audio_id}.png\"\
        )\n        metadata_filename = os.path.join(path, f\"{audio_id}_spectrogram_metadata.json\"\
        )\n\n        if int(node.split(\"_\")[2]) == 0:\n            node_category\
        \ = \"Degradado\"\n        elif int(node.split(\"_\")[2]) == 1:\n        \
        \    node_category = \"Integro\"\n\n        metadata = {\n            \"product_parent\"\
        : parent,\n            \"product_name\": product_name,\n            \"product_path\"\
        : file_path,\n            \"product_spectrum\": product_spectrum,\n      \
        \      \"CumulusName\": cumulus,\n            \"NodeCategoryIntegrity\": node_category,\n\
        \            \"NomenclatureNode\": node,\n            \"SerialNumber\": recorder,\n\
        \            \"DateDeployment\": deployment,\n            \"AudioID\": audio_id\n\
        \        }\n        with open(metadata_filename, 'w', encoding='utf-8') as\
        \ f:\n            json.dump(metadata, f, ensure_ascii=False, indent=4)\n\n\
        \        print(f\"{file_path} saved.\")\n        print(f\"{metadata_filename}\
        \ saved.\")\n\n    def save_metadata_videoclip(audio_id, product_spectrum,\
        \ path, cumulus, node, recorder, \n                                deployment,\
        \ clip_start, clip_end, parent=\"Null\"):\n        # identifier is being used\
        \ as audio_id in alfresco\n        product_name = \"spectrogram_video\"\n\
        \        file_path = os.path.join(path, f\"{audio_id}.mp4\")\n        metadata_filename\
        \ = os.path.join(path, f\"{audio_id}_spectrogram_video_metadata.json\")\n\n\
        \        if int(node.split(\"_\")[2]) == 0:\n            node_category = \"\
        Degradado\"\n        elif int(node.split(\"_\")[2]) == 1:\n            node_category\
        \ = \"Integro\"\n\n        metadata = {\n            \"product_parent\": parent,\n\
        \            \"product_name\": product_name,\n            \"product_description\"\
        : \"Spectrogram Video. Time is show in local timezone\",\n            \"product_path\"\
        : file_path,\n            \"product_spectrum\": product_spectrum,\n      \
        \      \"CumulusName\": cumulus,\n            \"NodeCategoryIntegrity\": node_category,\n\
        \            \"NomenclatureNode\": node,\n            \"SerialNumber\": recorder,\n\
        \            \"DateDeployment\": deployment,\n            \"ClipStart\": clip_start,\n\
        \            \"ClipEnd\": clip_end,\n            \"AudioID\": audio_id\n \
        \       }\n\n        with open(metadata_filename, 'w', encoding='utf-8') as\
        \ f:\n            json.dump(metadata, f, ensure_ascii=False, indent=4)\n\n\
        \        print(f\"{file_path} saved.\")\n        print(f\"{metadata_filename}\
        \ saved.\")\n\n    def upload(session, node_id, data, file):\n        \"\"\
        \"\n        Uploads a file to a specific folder.\n        Parameters:\n  \
        \          session (Session):          A session object to make\n        \
        \                                requests to alfresco.\n            node_id\
        \ (string):           Node id to which the file is going to be created\n \
        \           data (dict):                Dict that contains file options\n\
        \            file (object):              File to upload\n\n        Returns:\n\
        \            (list):     A list containing status code and status data\n \
        \       \"\"\"\n\n        try:\n            response = session.post(os.getenv(\"\
        ALFRESCO_URL\")\n                        + BASE_ENDPOINT + \"/nodes/\" + node_id\
        \ + \"/children\",\n                        data = data,\n               \
        \         files = file\n                        )\n\n            return [response.json(),\
        \ response.status_code];\n        except Exception as e: \n            print(\"\
        File \" + data[\"name\"] + \" could not be uploaded: \", e)\n\n    def upload_files(file_patterns,\
        \ session, node_id, dir_path, recursive, file_identifier=\"\"):\n        \"\
        \"\"\n        Uploads the files stored in a specific dir\n        to alfresco\n\
        \        Parameters:\n            session (Session):          A session object\
        \ to make\n                                        requests to alfresco.\n\
        \            node_id (string):           Node id to which the file is going\
        \ to be created\n            dir_path (string):          The name and path\
        \ of the dir where files are stored\n            recursive (boolean):    \
        \    A boolean to know if upload  must be recursive\n                    \
        \                    in the specifed dir, and should preserve the\n      \
        \                                  structure of dirs inside.\n           \
        \ file_identifier (string):   File identifier for all files inside a dir\n\
        \        Returns:\n            (string):           Returns the info of recent\
        \ created site.\n        \"\"\"\n\n        if recursive:\n            expression\
        \ = \"/**/*\"\n        else:\n            expression = \"/*\"\n\n        files_in_dir\
        \ = list(\n            itertools.chain.from_iterable(\n                glob.iglob(dir_path\
        \ + expression + pattern, recursive=recursive)\n                for pattern\
        \ in file_patterns\n            )\n        )\n        filename = \"logs/upload_log\"\
        \ + dir_path.replace('/','-') + '.txt'\n\n        os.makedirs(os.path.dirname(filename),\
        \ exist_ok=True)\n\n        total_files = len(files_in_dir)\n        starttime\
        \ = time.time()\n\n        try:\n            files_uploaded = []\n       \
        \     for idx, file_with_path in enumerate(files_in_dir):\n\n            \
        \    # total time since last login or script start\n                total_time\
        \ = round((time.time() - starttime), 2)\n\n                if total_time >\
        \ 2400:\n                    \"\"\"\n                    if total time is\
        \ bigger than 2400\n                    or 40 minutes relogin to avoid ticket\n\
        \                    expiration\n                    \"\"\"\n            \
        \        time.sleep(5)\n\n                    print(\"Re-logging in to alfresco...\"\
        )\n\n                    session = login.login()\n                    # restart\
        \ time\n                    starttime = time.time()\n                    time.sleep(5)\n\
        \                    print(\"Login sucessful, continuing upload\\\\n\")\n\n\
        \                len_of_path = len(file_with_path.split(\"/\"))\n        \
        \        name_of_file = file_with_path.split(\"/\")[len_of_path - 1]\n   \
        \             root_dir_path = file_with_path.replace(dir_path, \"\").replace(\n\
        \                    file_with_path.split(\"/\")[len_of_path - 1], \"\"\n\
        \                )\n\n                data = {\n                    \"name\"\
        : (\n                        name_of_file[0 : len(name_of_file) - 4]\n   \
        \                     + file_identifier\n                        + name_of_file[len(name_of_file)\
        \ - 4 : len(name_of_file)]\n                    ),\n                    \"\
        nodeType\": \"cm:content\",\n                }\n\n                data[\"\
        relativePath\"] = root_dir_path\n\n                data[\"properties\"] =\
        \ {\n                    \"cm:title\": (\n                        name_of_file[0\
        \ : len(name_of_file) - 4]\n                        + file_identifier\n  \
        \                      + name_of_file[len(name_of_file) - 4 : len(name_of_file)]\n\
        \                    )\n                }\n\n                print(\"Uploading\
        \ \" + data[\"name\"] + \" file...\")\n\n                files = {\"filedata\"\
        : open(file_with_path, \"rb\")}\n                upload_response = upload(session,\
        \ node_id, data, files)\n                if upload_response[1] and upload_response[1]\
        \ == 201:\n                    files_uploaded.append(upload_response[0])\n\
        \                    print(\"Uploaded \" + data[\"name\"])\n\n           \
        \         filename = \"logs/upload_log\" + dir_path.replace('/','-') + '.txt'\n\
        \                    with open(filename, 'a') as log_file:\n             \
        \           log_file.writelines(\"%s\\\\n\" % file_with_path)\n\n        \
        \        elif upload_response[1] and upload_response[1] == 409:\n        \
        \            if \"already exists\" in upload_response[0][\"error\"][\"errorKey\"\
        ]:\n                        print(\"File \" + data[\"name\"] + \" already\
        \ uploaded\")\n\n                else:\n                    print(\"An error\
        \ ocurred, file \" + data[\"name\"] + \" cannot be uploaded\")\n\n       \
        \         print(\"Uploaded file \" + str(idx + 1) + \" of \" + str(total_files))\n\
        \                print(\"\\\\n\\\\n\")\n\n            return files_uploaded\n\
        \        except Exception as e:\n            print(\"An error ocurred in file\
        \ upload: \", e)\n\n    def vectorize_soundscape(df, hash_name, indices):\n\
        \        \\'\\'\\'Return dataframe with array column containing indices by\
        \ frequency\\'\\'\\'\n        return (df\n                .groupby(by=[\"\
        id\", hash_name, \"start_time\", \"end_time\"])\n                .apply(get_vectors,\
        \ indices)\n                .reset_index()\n                .rename(columns={0:\"\
        index_vector\"}))\n    '''\n\n    _kale_block3 = '''\n    load_dotenv()\n\
        \    session = login()\n    for sc_path in sub_folder_results:\n        for\
        \ file in os.listdir(sc_path):\n            if file.split(\".\")[-1] in [\"\
        png\", \"mp4\"]:\n                print(file)\n                change_type_sipecam_sc(session,\
        \ ALFRESCO_NODE_ID, sc_path, file, 'soundscape:product')\n    '''\n\n    #\
        \ run the code blocks inside a jupyter kernel\n    from kale.common.jputils\
        \ import run_code as _kale_run_code\n    from kale.common.kfputils import\
        \ \\\n        update_uimetadata as _kale_update_uimetadata\n    _kale_blocks\
        \ = (_kale_pipeline_parameters_block, _kale_data_loading_block,\n        \
        \            _kale_block1,\n                    _kale_block2,\n          \
        \          _kale_block3,\n                    )\n    _kale_html_artifact =\
        \ _kale_run_code(_kale_blocks)\n    with open(\"/upload_alfresco_model_data.html\"\
        , \"w\") as f:\n        f.write(_kale_html_artifact)\n    _kale_update_uimetadata('upload_alfresco_model_data')\n\
        \n    _kale_mlmdutils.call(\"mark_execution_complete\")\n\nimport argparse\n\
        _parser = argparse.ArgumentParser(prog='Upload alfresco model data', description='')\n\
        _parser.add_argument(\"--ALFRESCO-NODE-ID\", dest=\"ALFRESCO_NODE_ID\", type=str,\
        \ required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"--AUTH-ENDPOINT\"\
        , dest=\"AUTH_ENDPOINT\", type=str, required=True, default=argparse.SUPPRESS)\n\
        _parser.add_argument(\"--BASE-ENDPOINT\", dest=\"BASE_ENDPOINT\", type=str,\
        \ required=True, default=argparse.SUPPRESS)\n_parsed_args = vars(_parser.parse_args())\n\
        \n_outputs = upload_alfresco_model_data(**_parsed_args)\n"
      image: sipecam/audio-dgpi-kale-tensorflow-yuntu-dask-cert:0.6.1_dev
      securityContext: {runAsUser: 0}
      volumeMounts:
      - {mountPath: /shared_volume, name: pvolume-ef6fe65091618f865041935b363277953274adf6b420fd4a7b8277d}
      workingDir: //shared_volume/audio
    inputs:
      parameters:
      - {name: ALFRESCO_NODE_ID}
      - {name: AUTH_ENDPOINT}
      - {name: BASE_ENDPOINT}
      - {name: vol_shared_volume}
    outputs:
      artifacts:
      - {name: mlpipeline-ui-metadata, path: /tmp/mlpipeline-ui-metadata.json}
      - {name: upload_alfresco_model_data, path: /upload_alfresco_model_data.html}
    metadata:
      annotations: {kubeflow-kale.org/dependent-templates: '["upload-to-alfresco"]',
        pipelines.kubeflow.org/component_spec: '{"implementation": {"container": {"args":
          ["--ALFRESCO-NODE-ID", {"inputValue": "ALFRESCO_NODE_ID"}, "--AUTH-ENDPOINT",
          {"inputValue": "AUTH_ENDPOINT"}, "--BASE-ENDPOINT", {"inputValue": "BASE_ENDPOINT"}],
          "command": ["sh", "-ec", "program_path=$(mktemp)\nprintf \"%s\" \"$0\" >
          \"$program_path\"\npython3 -u \"$program_path\" \"$@\"\n", "def upload_alfresco_model_data(ALFRESCO_NODE_ID,
          AUTH_ENDPOINT, BASE_ENDPOINT):\n    _kale_pipeline_parameters_block = ''''''\n    ALFRESCO_NODE_ID
          = \"{}\"\n    AUTH_ENDPOINT = \"{}\"\n    BASE_ENDPOINT = \"{}\"\n    ''''''.format(ALFRESCO_NODE_ID,
          AUTH_ENDPOINT, BASE_ENDPOINT)\n\n    from kale.common import mlmdutils as
          _kale_mlmdutils\n    _kale_mlmdutils.init_metadata()\n\n    _kale_data_loading_block
          = ''''''\n    # -----------------------DATA LOADING START--------------------------------\n    from
          kale import marshal as _kale_marshal\n    _kale_marshal.set_data_dir(\"/shared_volume/audio/.sndscs_spec_specvid-sipecam-cumulus-node-recorder-deployment-aws.ipynb.kale.marshal.dir\")\n    sub_folder_results
          = _kale_marshal.load(\"sub_folder_results\")\n    # -----------------------DATA
          LOADING END----------------------------------\n    ''''''\n\n    _kale_block1
          = ''''''\n    import base64\n    import datetime\n    import glob\n    import
          hashlib\n    import io\n    import itertools\n    import json\n    import
          matplotlib.pyplot as plt\n    import multiprocessing \n    import numpy
          as np\n    import os\n    import pandas as pd\n    import psutil\n    import
          requests\n    import shutil\n    import subprocess\n    import time\n    import
          warnings\n\n    from dask.distributed import Client, LocalCluster\n    from
          datetime import timedelta\n    from dotenv import load_dotenv\n    from
          matplotlib import cm\n    from moviepy.editor import concatenate, VideoFileClip,
          AudioFileClip\n    from moviepy.audio.AudioClip import AudioArrayClip\n    from
          moviepy.video.VideoClip import ImageClip\n    from os.path import exists
          as file_exists\n    from PIL import Image\n    from skimage.transform import
          resize\n\n    from yuntu import Audio\n    from yuntu.soundscape.utils import
          aware_time\n    from yuntu.collection.methods import collection\n    from
          yuntu.soundscape.hashers.crono import DEFAULT_HASHER_CONFIG\n    from yuntu.soundscape.processors.indices.direct
          import ICOMPLEXITY, TAIL\n    from yuntu.soundscape.pipelines.build_soundscape
          import CronoSoundscape, HASHER_CONFIG\n    ''''''\n\n    _kale_block2 =
          ''''''\n    def audio2video(audio_id,\n                    audio_df,\n                    save_path_folder,\n                    product_spectrum,\n                    cumulus,\n                    abs_start=None,\n                    fps=60,\n                    spec_configs={''hop_length'':
          512, ''n_fft'': 1024, ''window_function'': ''hann''},\n                    rate=24,\n                    frame_duration=3.0,\n                    min_freq=0,\n                    max_freq=None,\n                    cmap=\"Greys\",\n                    figsize=(5,
          8),\n                    dpi=100,\n                    bands=None):\n        \\''\\''\\''Takes
          and audio object and produces a mp4 video of the spectrogram with audio\\''\\''\\''\n\n        sub_audio_df
          = audio_df[audio_df[\"id\"]==audio_id]\n        id_audio = sub_audio_df[''id''].values[0]\n        node
          = sub_audio_df[''node''].values[0]\n        recorder = sub_audio_df[''recorder''].values[0]\n        deployment
          = sub_audio_df[''deployment''].values[0]\n        audio = sub_audio_df.audio[0]\n\n        colormap
          = cm.get_cmap(cmap)\n        duration = audio.duration\n        step = 1/rate\n        start
          = -(frame_duration/2.0)\n        stop = start + frame_duration\n        clips
          = []\n        last_stop = None\n\n        if max_freq is None:\n            max_freq
          = audio.samplerate / 2.0\n\n        if min_freq is None:\n            min_freq
          = 0\n\n        with audio.features.db_spectrogram(**spec_configs) as spec:\n            min_spec
          = np.amin(spec)\n            max_spec = np.amax(spec)\n            spec_range
          = (max_spec-min_spec)\n\n            while stop <= duration+(frame_duration/2.0):\n                clip
          = produce_clip(spec, frame_duration, min_freq, max_freq, start, stop, step,
          abs_start, colormap,\n                                    min_spec, spec_range,
          figsize, dpi, bands=bands)\n                clips.append(clip)\n\n                if
          start + step + frame_duration > duration:\n                    last_stop
          = stop\n\n                start = start + step\n                stop = start
          + frame_duration\n\n        video = concatenate(clips)\n        # edaudio
          = AudioArrayClip(audio_array, fps=audio.samplerate)\n        edaudio = AudioFileClip(audio.path).set_end(audio.duration)\n        video
          = video.set_audio(edaudio)\n        file_path = os.path.join(save_path_folder,
          f\"{audio_id}.mp4\")\n        video.write_videofile(file_path, fps=fps)\n\n        save_metadata_videoclip(audio_id,
          product_spectrum,\n                      save_path_folder, cumulus, node,
          recorder, deployment, 0.0, audio.duration)\n        video.close()\n        edaudio.close()\n\n        for
          c in clips:\n            c.close()\n\n    def change_type_sipecam_sc(session,
          root_folder_id, path, file_type, node_type):\n        if file_type == \"sequence.png\":\n            metadata_name
          = \"soundscape_seq_metadata.json\"\n            aggr_type = \"None\"\n        elif
          file_type == \"mean_soundscape.png\":\n            metadata_name = \"mean_soundscape_metadata.json\"\n            aggr_type
          = \"Mean\"\n        elif file_type ==  \"std_soundscape.png\":\n            metadata_name
          = \"std_soundscape_metadata.json\" \n            aggr_type = \"Standard
          deviation\"\n        elif file_type == \"hashed_soundscape.parquet\":\n            metadata_name
          = \"soundscape_metadata.json\" \n            aggr_type = \"None\"\n        elif
          \".png\" in file_type and (file_type not in [\"sequence.png\", \"mean_soundscape.png\",
          \"std_soundscape.png\"]):\n            metadata_name = file_type.split(\".\")[0]
          + \"_spectrogram_metadata.json\"\n            aggr_type = \"Null\"\n        elif
          \".mp4\" in file_type and (file_type not in [\"sequence.png\", \"mean_soundscape.png\",
          \"std_soundscape.png\"]):\n            metadata_name = file_type.split(\".\")[0]
          + \"_spectrogram_video_metadata.json\"\n            aggr_type = \"Null\"\n\n        try:\n            semi_path
          = path.split(\"soundscapes/\")[-1]\n            semi_path_file = os.path.join(semi_path,
          file_type)\n            local_path_file_metadata = os.path.join(path, metadata_name)\n            print(f\"Changing
          type for {os.path.join(semi_path)}\")\n            alfresco_path = os.path.join(\"/Company
          Home/Sites/sipecam-soundscape/documentLibrary/\", semi_path)\n\n            response
          = session.get(\n                os.getenv(\"ALFRESCO_URL\")\n                +
          BASE_ENDPOINT\n                + \"/nodes/\"\n                + root_folder_id\n                +
          \"/children?relativePath=\"+semi_path+\"&include=aspectNames&skipCount=0\"\n            )        \n            #
          if request is successful then continue\n            if response.status_code
          == 200:\n\n                data_file = open(local_path_file_metadata)\n                data_json
          = json.load(data_file)\n                response_entries = response.json()[\"list\"][\"entries\"]\n\n                for
          entry in response_entries:\n                    if entry[''entry''][''name'']==file_type
          and entry[''entry''][''isFile'']:\n                        prop_dict = {}\n\n                        if
          entry[''entry''][''name'']==file_type:\n\n                            if
          entry[''entry''][''name''] in [\"sequence.png\", \"mean_soundscape.png\",
          \"std_soundscape.png\"]:\n                                prop_dict[\"soundscape:CumulusName\"]
          = str(data_json[\"CumulusName\"])\n                                prop_dict[\"soundscape:DateDeployment\"]
          = data_json[\"DateDeployment\"]\n                                prop_dict[\"soundscape:NodeCategoryIntegrity\"]
          = str(data_json[\"NodeCategoryIntegrity\"])\n                                prop_dict[\"soundscape:NomenclatureNode\"]
          = str(data_json[\"NomenclatureNode\"])\n                                prop_dict[\"soundscape:SerialNumber\"]
          = str(data_json[\"SerialNumber\"])\n                                prop_dict[\"soundscape:aggr\"]
          = str(aggr_type)\n                                prop_dict[\"soundscape:cycle_config_aware_start\"]
          = str(data_json[\"product_configs\"][''hasher_config''][''kwargs''][''aware_start''])\n                                prop_dict[\"soundscape:cycle_config_start_format\"]
          = str(data_json[\"product_configs\"][''hasher_config''][''kwargs''][''start_format''])\n                                prop_dict[\"soundscape:cycle_config_start_time\"]
          =  datetime.datetime.strptime(data_json[\"product_configs\"][''hasher_config''][''kwargs''][''start_time''],
          \n                                                                                                        \"%Y-%m-%d
          %H:%M:%S\").strftime(\"%Y-%m-%dT%H:%M:%S.%f%z\")\n                                prop_dict[\"soundscape:cycle_config_start_tzone\"]
          = str(data_json[\"product_configs\"][''hasher_config''][''kwargs''][''start_tzone''])\n                                prop_dict[\"soundscape:cycle_config_time_module\"]
          = int(data_json[\"product_configs\"][''hasher_config''][''kwargs''][''time_module''])\n                                prop_dict[\"soundscape:cycle_config_time_unit\"]
          = str(data_json[\"product_configs\"][''hasher_config''][''kwargs''][''time_unit''])\n                                prop_dict[\"soundscape:cycle_config_time_utc_column\"]
          = str(data_json[\"product_configs\"][''hasher_config''][''kwargs''][''time_utc_column''])\n                                prop_dict[\"soundscape:frequency_bins\"]
          = int(data_json[\"product_configs\"][\"slice_config\"][\"frequency_bins\"])\n                                prop_dict[\"soundscape:frequency_hop\"]
          = int(data_json[\"product_configs\"][\"slice_config\"][\"frequency_hop\"])\n                                prop_dict[\"soundscape:frequency_limits\"]
          = str(data_json[\"product_configs\"][\"slice_config\"][\"frequency_limits\"])\n                                prop_dict[\"soundscape:hash_name\"]
          = str(data_json[\"product_configs\"][\"hash_name\"])\n                                prop_dict[\"soundscape:hop_length\"]
          = int(data_json[\"product_configs\"][\"slice_config\"][\"feature_config\"][\"hop_length\"])\n                                prop_dict[\"soundscape:indices\"]
          =  \", \".join(map(str, data_json[''product_configs''][''indices'']))\n                                prop_dict[\"soundscape:n_fft\"]
          = int(data_json[\"product_configs\"][\"slice_config\"][\"feature_config\"][\"n_fft\"])\n                                prop_dict[\"soundscape:npartitions\"]
          = int(data_json[\"product_configs\"][''npartitions''])\n                                prop_dict[\"soundscape:product_name\"]
          = str(data_json[\"product_name\"])\n                                prop_dict[\"soundscape:product_parent\"]
          = str(data_json[\"product_parent\"])\n                                prop_dict[\"soundscape:product_path\"]
          = str(alfresco_path)\n                                prop_dict[\"soundscape:product_spectrum\"]
          = str(data_json[\"product_spectrum\"])\n                                prop_dict[\"soundscape:slice_config_feature_type\"]
          = str(data_json[\"product_configs\"][\"slice_config\"][\"feature_type\"])\n                                prop_dict[\"soundscape:slice_config_frequency_bins\"]
          = int(data_json[\"product_configs\"][\"slice_config\"][\"frequency_bins\"])\n                                prop_dict[\"soundscape:slice_config_time_unit\"]
          = int(data_json[\"product_configs\"][\"slice_config\"][\"time_unit\"])\n                                prop_dict[\"soundscape:time_hop\"]
          = int(data_json[\"product_configs\"][\"slice_config\"][\"time_hop\"])\n                                prop_dict[\"soundscape:window_function\"]
          = str(data_json[\"product_configs\"][\"slice_config\"][\"feature_config\"][\"window_function\"])  \n\n                            elif
          (\"spectrogram\" or \"video\") in entry[''entry''][''name'']:\n                                prop_dict[\"soundscape:product_name\"]
          = str(data_json[\"product_name\"])\n                                prop_dict[\"soundscape:product_parent\"]
          = str(data_json[\"product_parent\"])\n                                prop_dict[\"soundscape:product_path\"]
          = str(alfresco_path)\n                                prop_dict[\"soundscape:product_spectrum\"]
          = str(data_json[\"product_spectrum\"])\n                                prop_dict[\"soundscape:CumulusName\"]
          = str(data_json[\"CumulusName\"])\n                                prop_dict[\"soundscape:NodeCategoryIntegrity\"]
          = str(data_json[\"NodeCategoryIntegrity\"])\n                                prop_dict[\"soundscape:NomenclatureNode\"]
          = str(data_json[\"NomenclatureNode\"])\n                                prop_dict[\"soundscape:SerialNumber\"]
          = str(data_json[\"SerialNumber\"])\n                                prop_dict[\"soundscape:DateDeployment\"]
          = data_json[\"DateDeployment\"]\n                                prop_dict[\"soundscape:AudioID\"]
          = data_json[\"AudioID\"]\n\n                        aspects = entry[''entry''][''aspectNames'']\n                        data
          = {\"aspectNames\": aspects, \"nodeType\": node_type, \"properties\": prop_dict}\n                        #
          update properties request\n                        update = session.put(\n                            os.getenv(\"ALFRESCO_URL\")\n                            +
          BASE_ENDPOINT\n                            + \"/nodes/\"\n                            +
          entry[''entry''][''id''],\n                            data=json.dumps(data),\n                        )\n\n                        if
          update.status_code == 200:\n                            print(\"Updated
          \" + entry[''entry''][''id''])                    \n\n        except Exception
          as e:\n            print(\"Could not add any aspect to this file: \", e)\n\n    def
          create_results_folder_str(results_dir, cumulo, nodes_list, rec_list, dep_list):
          \n        # results directory\n        os.makedirs(results_dir, exist_ok=True)\n        #
          cumulus subdir\n        cum_subdir = os.path.join(results_dir, str(cumulo))\n        os.makedirs(cum_subdir,
          exist_ok=True)\n        # node subdirs\n        for node in nodes_list:\n            node_subdir
          = os.path.join(cum_subdir, node)\n            os.makedirs(node_subdir, exist_ok=True)\n            #
          recorder subdirs\n            for rec in rec_list:\n                rec_subdir
          = os.path.join(node_subdir, rec)\n                os.makedirs(rec_subdir,
          exist_ok=True)\n                # deployment subdirs\n                for
          dep in dep_list:\n                    dep_subdir = os.path.join(rec_subdir,
          dep)\n                    os.makedirs(dep_subdir, exist_ok=True)\n\n    def
          distance_to_mean(vector, mean):\n        \\''\\''\\''Return euclidean distance
          to mean\\''\\''\\''\n        return np.sqrt(np.sum(np.square(mean - vector)))\n\n    def
          find_subfolders(path_abs):\n        subdir_list = []\n        walk = list(os.walk(path_abs))\n        for
          path, _, _ in walk[::-1]:\n            len_path = path.split(\"/\")\n            if
          len(len_path) == 8:\n                subdir_list.append(path)  \n\n        return
          subdir_list\n\n    def get_audio_ids(soundscape_path, indices, nsamples):\n        df
          = pd.read_parquet(os.path.join(soundscape_path, \"hashed_soundscape.parquet\"))\n\n        df[\"time_raw_hour\"]
          = df[\"time_raw\"].apply(lambda x: datetime.datetime.strptime(x,''%H:%M:%S
          %d/%m/%Y (%z)'').strftime(\"%H\"))\n        hours_list = list(df.time_raw_hour.unique())\n        hours_list.sort(key
          = int)\n\n        with open(os.path.join(soundscape_path, \"soundscape_metadata.json\"))
          as f:\n            metadata = json.load(f)\n            f.close()\n\n        #
          indices = metadata[\"product_configs\"][\"indices\"]\n        # indices
          = [\"EXAG\", \"ICOMPLEXITY\", \"CORE\"]\n        hash_name = metadata[\"product_configs\"][\"hash_name\"]\n        cycle_config
          = metadata[\"product_configs\"][\"hasher_config\"][\"kwargs\"]\n        time_unit
          = cycle_config[\"time_unit\"]\n        zero_t = aware_time(cycle_config[\"start_time\"],
          cycle_config[\"start_tzone\"], cycle_config[\"start_format\"]) \n\n        #
          iterate over hours\n        audio_id_list = []\n        for hour in hours_list:\n            subdf
          = df.query(f\"time_raw_hour == ''{hour}''\")\n            # sample\n            samples_df
          = get_recording_samples(subdf, hash_name, indices, time_unit, zero_t, nsamples=3)\n            unique_crono_hash_list
          = list(samples_df.crono_hash_30m.unique())\n            sub_df = samples_df[samples_df.crono_hash_30m
          == min(unique_crono_hash_list)]\n            audio_id_list += list(sub_df.id.tolist())\n\n        return
          audio_id_list\n\n    def get_recording_samples(df, hash_name, indices, time_unit,
          zero_t, nsamples=5):\n        \\''\\''\\''Return dataframe of ''nsamples''
          samples for each tag in ''hash_name'' column that are closest to the mean
          vector by tag\\''\\''\\''\n        proj_df = df[(df.max_freq <= 10000)]\n        crono_tags
          = proj_df.crono_hash_30m.unique()\n        proj_df.loc[: , f\"{hash_name}_time\"]
          = proj_df[hash_name].apply(lambda x: zero_t + datetime.timedelta(seconds=float(x*time_unit)))\n        vectors
          = vectorize_soundscape(proj_df, hash_name, indices)\n        min_index_vector
          = np.amin(np.stack(list(vectors.index_vector.values)), axis=(0,1))\n        max_index_vector
          = np.amax(np.stack(list(vectors.index_vector.values)), axis=(0,1))\n        index_range
          = (max_index_vector - min_index_vector)\n        vectors.loc[:, \"normalized_index_vector\"]
          = vectors.index_vector.apply(lambda x: (x-min_index_vector)/index_range)\n        all_samples
          = []\n\n        for crono_tag in crono_tags:\n            unit_vectors =
          vectors[vectors[hash_name] == crono_tag]\n            mean_unit_vector =
          unit_vectors.normalized_index_vector.mean()\n            unit_vectors.loc[:,
          \"distance\"] = unit_vectors.normalized_index_vector.apply(lambda x: distance_to_mean(x,
          mean_unit_vector))\n            all_samples.append(unit_vectors.sort_values(by=\"distance\").head(nsamples))\n        return
          pd.concat(all_samples)\n\n    def get_vectors(group, indices):\n        \\''\\''\\''Return
          array of indices by frequency\\''\\''\\''\n        return group.sort_values(by=\"max_freq\")[indices].values\n\n    def
          login():\n        \"\"\"\n        Tries a login to alfresco api and returns
          a session\n        object with credentials \n        Returns: \n            session
          (Session):  A session object to make \n                                requests
          to zendro.\n        \"\"\"\n        try:\n            auth = {\n                \"userId\":
          os.getenv(\"ALFRESCO_USER\"),\n                \"password\": os.getenv(\"ALFRESCO_PASSWORD\"),\n            }\n\n            login
          = requests.post(os.getenv(\"ALFRESCO_URL\") + AUTH_ENDPOINT + \"/tickets\",data=json.dumps(auth))\n\n            base64_login
          = base64.b64encode(bytes(login.json()[\"entry\"][\"id\"], ''utf-8'')).decode()\n\n            #
          se crea un objeto de Session para hacer requests\n            session =
          requests.Session()\n            # se establece bearer token\n            session.headers.update({''Authorization'':
          ''Basic '' + base64_login})\n\n            return session\n        except
          Exception as e:\n            print(\"Login failed: \", e)\n\n    def plot_spectrogram(audio_id,
          audio_df, save_path_folder, spectrum, cumulus):\n        sub_audio_df =
          audio_df[audio_df[\"id\"]==audio_id]\n        node = sub_audio_df[''node''].values[0]\n        recorder
          = sub_audio_df[''recorder''].values[0]\n        deployment = sub_audio_df[''deployment''].values[0]\n        #
          plot\n        fig, ax = plt.subplots(2,1,figsize=(20,10), sharex=True)\n        sub_audio_df.audio[0].plot(ax=ax[0],
          color=''grey'')\n        sub_audio_df.audio[0].features.db_spectrogram().plot(ax=ax[1])\n        ax[0].set_ylabel(''Amplitude'')\n        ax[0].grid(False)\n        ax[1].set_ylabel(''F
          (KHz)'')\n        ax[1].set_xlabel(''Time (seconds)'')\n        fig.text(0.75,
          0.04, f\"Cumulus: {cumulus} - Node: {node} - Recorder: {recorder}\", va=''center'')\n        plt.tight_layout()\n        if
          save_path_folder:\n            file_path = os.path.join(save_path_folder,
          f\"{audio_id}.png\")\n            fig.savefig(file_path)\n        plt.show()\n\n        save_metadata_spectrogram(audio_id,
          spectrum, save_path_folder, \n                                  cumulus,
          node, recorder, deployment, parent=\"Null\")\n\n    def plot_soundscape(soundscape,
          product_type, product_spectrum, sc_config, path, \n                        cumulus,
          node, recorder, deployment, parent, indices, min_freq=None,\n                      figsize=(20,15),
          plt_style=''ggplot''):\n\n        if min_freq:\n            soundscape =
          soundscape[soundscape[''min_freq'']<=min_freq]\n\n        if product_type
          == \"sequence\":\n            file_path = os.path.join(path, \"sequence.png\")\n            #
          product_id = hashlib.md5(file_path.encode(''utf-8'')).hexdigest()\n\n            plt.style.use(plt_style)\n            fig,
          ax = plt.subplots(figsize=figsize)\n            soundscape.sndscape.plot_sequence(rgb=indices,
          time_format=''%Y-%m %H:%M'', ax=ax)\n            plt.xticks(rotation = 90)\n            ax.grid(False)\n            plt.tight_layout()\n            plt.savefig(file_path)
          \n            plt.show()\n            # save metadata\n            save_metadata_sc(product_type,
          product_spectrum, sc_config,\n                      path, cumulus, node,
          recorder, deployment, parent=parent)\n\n        elif product_type == \"standard_deviation\":\n            file_path
          = os.path.join(path, \"std_soundscape.png\")\n            # product_id =
          hashlib.md5(file_path.encode(''utf-8'')).hexdigest()\n\n            plt.style.use(plt_style)\n            fig,
          ax = plt.subplots(figsize=figsize)\n            soundscape.sndscape.plot_cycle(rgb=indices,
          aggr=\"std\", time_format=''%H:%M'', \n                                           xticks=24,
          ax=ax)\n            plt.xticks(rotation = 90)\n            ax.grid(False)\n            plt.tight_layout()
          \n            plt.savefig(file_path)\n            plt.show()\n\n            #
          save metadata\n            save_metadata_sc(product_type, product_spectrum,
          sc_config,\n                      path, cumulus, node, recorder, deployment,
          parent)     \n\n        elif product_type == \"mean\": \n            file_path
          = os.path.join(path, \"mean_soundscape.png\")\n            # product_id
          = hashlib.md5(file_path.encode(''utf-8'')).hexdigest()\n\n            plt.style.use(plt_style)\n            fig,
          ax = plt.subplots(figsize=figsize)\n            soundscape.sndscape.plot_cycle(rgb=indices,
          aggr=\"mean\", time_format=''%H:%M'', \n                                           xticks=24,
          ax=ax)\n            plt.xticks(rotation = 90)\n            ax.grid(False)\n            plt.tight_layout()\n            plt.savefig(file_path)\n            plt.show()\n\n            #
          save metadata\n            save_metadata_sc(product_type, product_spectrum,
          sc_config,\n                      path, cumulus, node, recorder, deployment,
          parent)    \n\n        print(f\"File saved at {file_path}\")\n\n    def
          produce_clip(spec, frame_duration, min_freq, max_freq, start, stop, step,
          abs_start=None, \n                     colormap=cm.get_cmap(\"Greys\"),
          min_spec=0, spec_range=1.0, figsize=(5, 4), \n                     dpi=100,
          bands=None):\n        \\''\\''\\''Takes an individual frame and produces
          an image with references\\''\\''\\''\n        frame = spec.cut_array(start_time=start,
          end_time=stop, min_freq=min_freq, max_freq=max_freq, pad=True)\n        plt.style.use(''dark_background'')\n        frame
          = np.flip((frame - min_spec)/spec_range, axis=0)\n        fig, ax = plt.subplots(figsize=figsize)\n        ax.imshow(frame,
          cmap=colormap, extent=[0, frame_duration, min_freq/1000, max_freq/1000],
          \n                  aspect=\"auto\", vmin = 0, vmax = 1.0)\n\n        if
          bands is not None:\n            band_arr = np.flip(resize(np.expand_dims(bands,
          axis=1), (frame.shape[0], frame.shape[1])), axis=0)\n            ax.imshow(band_arr,
          extent=[0, frame_duration, min_freq/1000, max_freq/1000], aspect=\"auto\",
          vmin = 0, \n                      vmax = 1.0, alpha=0.5)\n\n        ax.tick_params(axis=''both'',
          which=''major'', labelsize=8)\n        ax.tick_params(axis=''both'', which=''minor'',
          labelsize=8)\n        mid = frame_duration/2.0\n        ax.axvline(x=mid,
          color=\"red\")\n        ax.set_ylabel(''F (kHz)'')\n        ax.set_xticks([])\n        ax.set_xticks([],
          minor=True)\n\n        if abs_start is not None:\n            time_text
          = (abs_start + datetime.timedelta(seconds=start+mid)).strftime(''%H:%M:%S.%f'').strip()[:-4]\n            ax.text(mid-0.3,
          -0.6, time_text)\n\n        buf = io.BytesIO()\n        fig.tight_layout()\n        fig.savefig(buf,
          dpi=dpi)\n        buf.seek(0)\n        im = Image.open(buf)\n        im.format
          = \"PNG\"\n        plt.close(fig)\n\n        return ImageClip(np.asarray(im),\n                         duration=step)\n\n    def
          remove_empty_folders(path_abs):\n        walk = list(os.walk(path_abs))\n        for
          path, _, _ in walk[::-1]:\n            if len(os.listdir(path)) == 0:\n                os.rmdir(path)            \n\n    def
          save_metadata_sc(product_type, product_spectrum, sc_config,\n                      path,
          cumulus, node, recorder, deployment, parent=\"Null\"):\n        if product_type
          == \"soundscape\":\n            product_name = \"Soundscape\"\n            file_path
          = os.path.join(path, \"hashed_soundscape.parquet\")\n            metadata_filename
          = os.path.join(path, \"soundscape_metadata.json\")\n        elif product_type
          == \"sequence\":\n            product_name = \"Soundscape sequential plot\"\n            file_path
          = os.path.join(path, \"soundscape_seq.png\")\n            metadata_filename
          = os.path.join(path, \"soundscape_seq_metadata.json\")\n        elif product_type
          == \"standard_deviation\":\n            product_name = \"Soundscape standard
          deviation plot\"\n            file_path = os.path.join(path, \"std_soundscape.png\")\n            metadata_filename
          = os.path.join(path, \"std_soundscape_metadata.json\")\n        elif product_type
          == \"mean\":\n            product_name = \"Soundscape mean plot\"\n            file_path
          = os.path.join(path, \"mean_soundscape.png\")\n            metadata_filename
          = os.path.join(path, \"mean_soundscape_metadata.json\")\n\n        if int(node.split(\"_\")[2])
          == 0:\n            node_category = \"Degradado\"\n        elif int(node.split(\"_\")[2])
          == 1:\n            node_category = \"Integro\"\n\n        metadata = {\n            \"product_parent\":
          parent,\n            \"product_name\": product_name,\n            \"product_configs\":
          sc_config,\n            \"product_path\": file_path,\n            \"product_spectrum\":
          product_spectrum,\n            \"CumulusName\": cumulus,\n            \"NodeCategoryIntegrity\":
          node_category,\n            \"NomenclatureNode\": node,\n            \"SerialNumber\":
          recorder,\n            \"DateDeployment\": deployment\n        }\n\n        with
          open(metadata_filename, ''w'', encoding=''utf-8'') as f:\n            json.dump(metadata,
          f, ensure_ascii=False, indent=4)\n\n    def save_metadata_spectrogram(audio_id,
          product_spectrum,\n                      path, cumulus, node, recorder,
          deployment, parent=\"Null\"):\n        # identifier is being used as audio_id
          in alfresco\n        product_name = \"Spectrogram\"\n        file_path =
          os.path.join(path, f\"{audio_id}.png\")\n        metadata_filename = os.path.join(path,
          f\"{audio_id}_spectrogram_metadata.json\")\n\n        if int(node.split(\"_\")[2])
          == 0:\n            node_category = \"Degradado\"\n        elif int(node.split(\"_\")[2])
          == 1:\n            node_category = \"Integro\"\n\n        metadata = {\n            \"product_parent\":
          parent,\n            \"product_name\": product_name,\n            \"product_path\":
          file_path,\n            \"product_spectrum\": product_spectrum,\n            \"CumulusName\":
          cumulus,\n            \"NodeCategoryIntegrity\": node_category,\n            \"NomenclatureNode\":
          node,\n            \"SerialNumber\": recorder,\n            \"DateDeployment\":
          deployment,\n            \"AudioID\": audio_id\n        }\n        with
          open(metadata_filename, ''w'', encoding=''utf-8'') as f:\n            json.dump(metadata,
          f, ensure_ascii=False, indent=4)\n\n        print(f\"{file_path} saved.\")\n        print(f\"{metadata_filename}
          saved.\")\n\n    def save_metadata_videoclip(audio_id, product_spectrum,
          path, cumulus, node, recorder, \n                                deployment,
          clip_start, clip_end, parent=\"Null\"):\n        # identifier is being used
          as audio_id in alfresco\n        product_name = \"spectrogram_video\"\n        file_path
          = os.path.join(path, f\"{audio_id}.mp4\")\n        metadata_filename = os.path.join(path,
          f\"{audio_id}_spectrogram_video_metadata.json\")\n\n        if int(node.split(\"_\")[2])
          == 0:\n            node_category = \"Degradado\"\n        elif int(node.split(\"_\")[2])
          == 1:\n            node_category = \"Integro\"\n\n        metadata = {\n            \"product_parent\":
          parent,\n            \"product_name\": product_name,\n            \"product_description\":
          \"Spectrogram Video. Time is show in local timezone\",\n            \"product_path\":
          file_path,\n            \"product_spectrum\": product_spectrum,\n            \"CumulusName\":
          cumulus,\n            \"NodeCategoryIntegrity\": node_category,\n            \"NomenclatureNode\":
          node,\n            \"SerialNumber\": recorder,\n            \"DateDeployment\":
          deployment,\n            \"ClipStart\": clip_start,\n            \"ClipEnd\":
          clip_end,\n            \"AudioID\": audio_id\n        }\n\n        with
          open(metadata_filename, ''w'', encoding=''utf-8'') as f:\n            json.dump(metadata,
          f, ensure_ascii=False, indent=4)\n\n        print(f\"{file_path} saved.\")\n        print(f\"{metadata_filename}
          saved.\")\n\n    def upload(session, node_id, data, file):\n        \"\"\"\n        Uploads
          a file to a specific folder.\n        Parameters:\n            session (Session):          A
          session object to make\n                                        requests
          to alfresco.\n            node_id (string):           Node id to which the
          file is going to be created\n            data (dict):                Dict
          that contains file options\n            file (object):              File
          to upload\n\n        Returns:\n            (list):     A list containing
          status code and status data\n        \"\"\"\n\n        try:\n            response
          = session.post(os.getenv(\"ALFRESCO_URL\")\n                        + BASE_ENDPOINT
          + \"/nodes/\" + node_id + \"/children\",\n                        data =
          data,\n                        files = file\n                        )\n\n            return
          [response.json(), response.status_code];\n        except Exception as e:
          \n            print(\"File \" + data[\"name\"] + \" could not be uploaded:
          \", e)\n\n    def upload_files(file_patterns, session, node_id, dir_path,
          recursive, file_identifier=\"\"):\n        \"\"\"\n        Uploads the files
          stored in a specific dir\n        to alfresco\n        Parameters:\n            session
          (Session):          A session object to make\n                                        requests
          to alfresco.\n            node_id (string):           Node id to which the
          file is going to be created\n            dir_path (string):          The
          name and path of the dir where files are stored\n            recursive (boolean):        A
          boolean to know if upload  must be recursive\n                                        in
          the specifed dir, and should preserve the\n                                        structure
          of dirs inside.\n            file_identifier (string):   File identifier
          for all files inside a dir\n        Returns:\n            (string):           Returns
          the info of recent created site.\n        \"\"\"\n\n        if recursive:\n            expression
          = \"/**/*\"\n        else:\n            expression = \"/*\"\n\n        files_in_dir
          = list(\n            itertools.chain.from_iterable(\n                glob.iglob(dir_path
          + expression + pattern, recursive=recursive)\n                for pattern
          in file_patterns\n            )\n        )\n        filename = \"logs/upload_log\"
          + dir_path.replace(''/'',''-'') + ''.txt''\n\n        os.makedirs(os.path.dirname(filename),
          exist_ok=True)\n\n        total_files = len(files_in_dir)\n        starttime
          = time.time()\n\n        try:\n            files_uploaded = []\n            for
          idx, file_with_path in enumerate(files_in_dir):\n\n                # total
          time since last login or script start\n                total_time = round((time.time()
          - starttime), 2)\n\n                if total_time > 2400:\n                    \"\"\"\n                    if
          total time is bigger than 2400\n                    or 40 minutes relogin
          to avoid ticket\n                    expiration\n                    \"\"\"\n                    time.sleep(5)\n\n                    print(\"Re-logging
          in to alfresco...\")\n\n                    session = login.login()\n                    #
          restart time\n                    starttime = time.time()\n                    time.sleep(5)\n                    print(\"Login
          sucessful, continuing upload\\\\n\")\n\n                len_of_path = len(file_with_path.split(\"/\"))\n                name_of_file
          = file_with_path.split(\"/\")[len_of_path - 1]\n                root_dir_path
          = file_with_path.replace(dir_path, \"\").replace(\n                    file_with_path.split(\"/\")[len_of_path
          - 1], \"\"\n                )\n\n                data = {\n                    \"name\":
          (\n                        name_of_file[0 : len(name_of_file) - 4]\n                        +
          file_identifier\n                        + name_of_file[len(name_of_file)
          - 4 : len(name_of_file)]\n                    ),\n                    \"nodeType\":
          \"cm:content\",\n                }\n\n                data[\"relativePath\"]
          = root_dir_path\n\n                data[\"properties\"] = {\n                    \"cm:title\":
          (\n                        name_of_file[0 : len(name_of_file) - 4]\n                        +
          file_identifier\n                        + name_of_file[len(name_of_file)
          - 4 : len(name_of_file)]\n                    )\n                }\n\n                print(\"Uploading
          \" + data[\"name\"] + \" file...\")\n\n                files = {\"filedata\":
          open(file_with_path, \"rb\")}\n                upload_response = upload(session,
          node_id, data, files)\n                if upload_response[1] and upload_response[1]
          == 201:\n                    files_uploaded.append(upload_response[0])\n                    print(\"Uploaded
          \" + data[\"name\"])\n\n                    filename = \"logs/upload_log\"
          + dir_path.replace(''/'',''-'') + ''.txt''\n                    with open(filename,
          ''a'') as log_file:\n                        log_file.writelines(\"%s\\\\n\"
          % file_with_path)\n\n                elif upload_response[1] and upload_response[1]
          == 409:\n                    if \"already exists\" in upload_response[0][\"error\"][\"errorKey\"]:\n                        print(\"File
          \" + data[\"name\"] + \" already uploaded\")\n\n                else:\n                    print(\"An
          error ocurred, file \" + data[\"name\"] + \" cannot be uploaded\")\n\n                print(\"Uploaded
          file \" + str(idx + 1) + \" of \" + str(total_files))\n                print(\"\\\\n\\\\n\")\n\n            return
          files_uploaded\n        except Exception as e:\n            print(\"An error
          ocurred in file upload: \", e)\n\n    def vectorize_soundscape(df, hash_name,
          indices):\n        \\''\\''\\''Return dataframe with array column containing
          indices by frequency\\''\\''\\''\n        return (df\n                .groupby(by=[\"id\",
          hash_name, \"start_time\", \"end_time\"])\n                .apply(get_vectors,
          indices)\n                .reset_index()\n                .rename(columns={0:\"index_vector\"}))\n    ''''''\n\n    _kale_block3
          = ''''''\n    load_dotenv()\n    session = login()\n    for sc_path in sub_folder_results:\n        for
          file in os.listdir(sc_path):\n            if file.split(\".\")[-1] in [\"png\",
          \"mp4\"]:\n                print(file)\n                change_type_sipecam_sc(session,
          ALFRESCO_NODE_ID, sc_path, file, ''soundscape:product'')\n    ''''''\n\n    #
          run the code blocks inside a jupyter kernel\n    from kale.common.jputils
          import run_code as _kale_run_code\n    from kale.common.kfputils import
          \\\n        update_uimetadata as _kale_update_uimetadata\n    _kale_blocks
          = (_kale_pipeline_parameters_block, _kale_data_loading_block,\n                    _kale_block1,\n                    _kale_block2,\n                    _kale_block3,\n                    )\n    _kale_html_artifact
          = _kale_run_code(_kale_blocks)\n    with open(\"/upload_alfresco_model_data.html\",
          \"w\") as f:\n        f.write(_kale_html_artifact)\n    _kale_update_uimetadata(''upload_alfresco_model_data'')\n\n    _kale_mlmdutils.call(\"mark_execution_complete\")\n\nimport
          argparse\n_parser = argparse.ArgumentParser(prog=''Upload alfresco model
          data'', description='''')\n_parser.add_argument(\"--ALFRESCO-NODE-ID\",
          dest=\"ALFRESCO_NODE_ID\", type=str, required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"--AUTH-ENDPOINT\",
          dest=\"AUTH_ENDPOINT\", type=str, required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"--BASE-ENDPOINT\",
          dest=\"BASE_ENDPOINT\", type=str, required=True, default=argparse.SUPPRESS)\n_parsed_args
          = vars(_parser.parse_args())\n\n_outputs = upload_alfresco_model_data(**_parsed_args)\n"],
          "image": "sipecam/audio-dgpi-kale-tensorflow-yuntu-dask-cert:0.6.1_dev"}},
          "inputs": [{"name": "ALFRESCO_NODE_ID", "type": "String"}, {"name": "AUTH_ENDPOINT",
          "type": "String"}, {"name": "BASE_ENDPOINT", "type": "String"}], "name":
          "Upload alfresco model data"}', pipelines.kubeflow.org/component_ref: '{}',
        pipelines.kubeflow.org/arguments.parameters: '{"ALFRESCO_NODE_ID": "{{inputs.parameters.ALFRESCO_NODE_ID}}",
          "AUTH_ENDPOINT": "{{inputs.parameters.AUTH_ENDPOINT}}", "BASE_ENDPOINT":
          "{{inputs.parameters.BASE_ENDPOINT}}"}'}
      labels:
        pipelines.kubeflow.org/metadata_written: "true"
        pipelines.kubeflow.org/kfp_sdk_version: 1.8.11
        pipelines.kubeflow.org/pipeline-sdk-type: kfp
        pipelines.kubeflow.org/enable_caching: "true"
    volumes:
    - name: pvolume-ef6fe65091618f865041935b363277953274adf6b420fd4a7b8277d
      persistentVolumeClaim: {claimName: '{{inputs.parameters.vol_shared_volume}}'}
  - name: upload-to-alfresco
    container:
      args: [--ALFRESCO-NODE-ID, '{{inputs.parameters.ALFRESCO_NODE_ID}}', --AUTH-ENDPOINT,
        '{{inputs.parameters.AUTH_ENDPOINT}}', --BASE-ENDPOINT, '{{inputs.parameters.BASE_ENDPOINT}}',
        --RESULTS-DIR, '{{inputs.parameters.RESULTS_DIR}}']
      command:
      - sh
      - -ec
      - |
        program_path=$(mktemp)
        printf "%s" "$0" > "$program_path"
        python3 -u "$program_path" "$@"
      - "def upload_to_alfresco(ALFRESCO_NODE_ID, AUTH_ENDPOINT, BASE_ENDPOINT, RESULTS_DIR):\n\
        \    _kale_pipeline_parameters_block = '''\n    ALFRESCO_NODE_ID = \"{}\"\n\
        \    AUTH_ENDPOINT = \"{}\"\n    BASE_ENDPOINT = \"{}\"\n    RESULTS_DIR =\
        \ \"{}\"\n    '''.format(ALFRESCO_NODE_ID, AUTH_ENDPOINT, BASE_ENDPOINT, RESULTS_DIR)\n\
        \n    from kale.common import mlmdutils as _kale_mlmdutils\n    _kale_mlmdutils.init_metadata()\n\
        \n    _kale_block1 = '''\n    import base64\n    import datetime\n    import\
        \ glob\n    import hashlib\n    import io\n    import itertools\n    import\
        \ json\n    import matplotlib.pyplot as plt\n    import multiprocessing \n\
        \    import numpy as np\n    import os\n    import pandas as pd\n    import\
        \ psutil\n    import requests\n    import shutil\n    import subprocess\n\
        \    import time\n    import warnings\n\n    from dask.distributed import\
        \ Client, LocalCluster\n    from datetime import timedelta\n    from dotenv\
        \ import load_dotenv\n    from matplotlib import cm\n    from moviepy.editor\
        \ import concatenate, VideoFileClip, AudioFileClip\n    from moviepy.audio.AudioClip\
        \ import AudioArrayClip\n    from moviepy.video.VideoClip import ImageClip\n\
        \    from os.path import exists as file_exists\n    from PIL import Image\n\
        \    from skimage.transform import resize\n\n    from yuntu import Audio\n\
        \    from yuntu.soundscape.utils import aware_time\n    from yuntu.collection.methods\
        \ import collection\n    from yuntu.soundscape.hashers.crono import DEFAULT_HASHER_CONFIG\n\
        \    from yuntu.soundscape.processors.indices.direct import ICOMPLEXITY, TAIL\n\
        \    from yuntu.soundscape.pipelines.build_soundscape import CronoSoundscape,\
        \ HASHER_CONFIG\n    '''\n\n    _kale_block2 = '''\n    def audio2video(audio_id,\n\
        \                    audio_df,\n                    save_path_folder,\n  \
        \                  product_spectrum,\n                    cumulus,\n     \
        \               abs_start=None,\n                    fps=60,\n           \
        \         spec_configs={'hop_length': 512, 'n_fft': 1024, 'window_function':\
        \ 'hann'},\n                    rate=24,\n                    frame_duration=3.0,\n\
        \                    min_freq=0,\n                    max_freq=None,\n   \
        \                 cmap=\"Greys\",\n                    figsize=(5, 8),\n \
        \                   dpi=100,\n                    bands=None):\n        \\\
        '\\'\\'Takes and audio object and produces a mp4 video of the spectrogram\
        \ with audio\\'\\'\\'\n\n        sub_audio_df = audio_df[audio_df[\"id\"]==audio_id]\n\
        \        id_audio = sub_audio_df['id'].values[0]\n        node = sub_audio_df['node'].values[0]\n\
        \        recorder = sub_audio_df['recorder'].values[0]\n        deployment\
        \ = sub_audio_df['deployment'].values[0]\n        audio = sub_audio_df.audio[0]\n\
        \n        colormap = cm.get_cmap(cmap)\n        duration = audio.duration\n\
        \        step = 1/rate\n        start = -(frame_duration/2.0)\n        stop\
        \ = start + frame_duration\n        clips = []\n        last_stop = None\n\
        \n        if max_freq is None:\n            max_freq = audio.samplerate /\
        \ 2.0\n\n        if min_freq is None:\n            min_freq = 0\n\n      \
        \  with audio.features.db_spectrogram(**spec_configs) as spec:\n         \
        \   min_spec = np.amin(spec)\n            max_spec = np.amax(spec)\n     \
        \       spec_range = (max_spec-min_spec)\n\n            while stop <= duration+(frame_duration/2.0):\n\
        \                clip = produce_clip(spec, frame_duration, min_freq, max_freq,\
        \ start, stop, step, abs_start, colormap,\n                              \
        \      min_spec, spec_range, figsize, dpi, bands=bands)\n                clips.append(clip)\n\
        \n                if start + step + frame_duration > duration:\n         \
        \           last_stop = stop\n\n                start = start + step\n   \
        \             stop = start + frame_duration\n\n        video = concatenate(clips)\n\
        \        # edaudio = AudioArrayClip(audio_array, fps=audio.samplerate)\n \
        \       edaudio = AudioFileClip(audio.path).set_end(audio.duration)\n    \
        \    video = video.set_audio(edaudio)\n        file_path = os.path.join(save_path_folder,\
        \ f\"{audio_id}.mp4\")\n        video.write_videofile(file_path, fps=fps)\n\
        \n        save_metadata_videoclip(audio_id, product_spectrum,\n          \
        \            save_path_folder, cumulus, node, recorder, deployment, 0.0, audio.duration)\n\
        \        video.close()\n        edaudio.close()\n\n        for c in clips:\n\
        \            c.close()\n\n    def change_type_sipecam_sc(session, root_folder_id,\
        \ path, file_type, node_type):\n        if file_type == \"sequence.png\":\n\
        \            metadata_name = \"soundscape_seq_metadata.json\"\n          \
        \  aggr_type = \"None\"\n        elif file_type == \"mean_soundscape.png\"\
        :\n            metadata_name = \"mean_soundscape_metadata.json\"\n       \
        \     aggr_type = \"Mean\"\n        elif file_type ==  \"std_soundscape.png\"\
        :\n            metadata_name = \"std_soundscape_metadata.json\" \n       \
        \     aggr_type = \"Standard deviation\"\n        elif file_type == \"hashed_soundscape.parquet\"\
        :\n            metadata_name = \"soundscape_metadata.json\" \n           \
        \ aggr_type = \"None\"\n        elif \".png\" in file_type and (file_type\
        \ not in [\"sequence.png\", \"mean_soundscape.png\", \"std_soundscape.png\"\
        ]):\n            metadata_name = file_type.split(\".\")[0] + \"_spectrogram_metadata.json\"\
        \n            aggr_type = \"Null\"\n        elif \".mp4\" in file_type and\
        \ (file_type not in [\"sequence.png\", \"mean_soundscape.png\", \"std_soundscape.png\"\
        ]):\n            metadata_name = file_type.split(\".\")[0] + \"_spectrogram_video_metadata.json\"\
        \n            aggr_type = \"Null\"\n\n        try:\n            semi_path\
        \ = path.split(\"soundscapes/\")[-1]\n            semi_path_file = os.path.join(semi_path,\
        \ file_type)\n            local_path_file_metadata = os.path.join(path, metadata_name)\n\
        \            print(f\"Changing type for {os.path.join(semi_path)}\")\n   \
        \         alfresco_path = os.path.join(\"/Company Home/Sites/sipecam-soundscape/documentLibrary/\"\
        , semi_path)\n\n            response = session.get(\n                os.getenv(\"\
        ALFRESCO_URL\")\n                + BASE_ENDPOINT\n                + \"/nodes/\"\
        \n                + root_folder_id\n                + \"/children?relativePath=\"\
        +semi_path+\"&include=aspectNames&skipCount=0\"\n            )        \n \
        \           # if request is successful then continue\n            if response.status_code\
        \ == 200:\n\n                data_file = open(local_path_file_metadata)\n\
        \                data_json = json.load(data_file)\n                response_entries\
        \ = response.json()[\"list\"][\"entries\"]\n\n                for entry in\
        \ response_entries:\n                    if entry['entry']['name']==file_type\
        \ and entry['entry']['isFile']:\n                        prop_dict = {}\n\n\
        \                        if entry['entry']['name']==file_type:\n\n       \
        \                     if entry['entry']['name'] in [\"sequence.png\", \"mean_soundscape.png\"\
        , \"std_soundscape.png\"]:\n                                prop_dict[\"soundscape:CumulusName\"\
        ] = str(data_json[\"CumulusName\"])\n                                prop_dict[\"\
        soundscape:DateDeployment\"] = data_json[\"DateDeployment\"]\n           \
        \                     prop_dict[\"soundscape:NodeCategoryIntegrity\"] = str(data_json[\"\
        NodeCategoryIntegrity\"])\n                                prop_dict[\"soundscape:NomenclatureNode\"\
        ] = str(data_json[\"NomenclatureNode\"])\n                               \
        \ prop_dict[\"soundscape:SerialNumber\"] = str(data_json[\"SerialNumber\"\
        ])\n                                prop_dict[\"soundscape:aggr\"] = str(aggr_type)\n\
        \                                prop_dict[\"soundscape:cycle_config_aware_start\"\
        ] = str(data_json[\"product_configs\"]['hasher_config']['kwargs']['aware_start'])\n\
        \                                prop_dict[\"soundscape:cycle_config_start_format\"\
        ] = str(data_json[\"product_configs\"]['hasher_config']['kwargs']['start_format'])\n\
        \                                prop_dict[\"soundscape:cycle_config_start_time\"\
        ] =  datetime.datetime.strptime(data_json[\"product_configs\"]['hasher_config']['kwargs']['start_time'],\
        \ \n                                                                     \
        \                                   \"%Y-%m-%d %H:%M:%S\").strftime(\"%Y-%m-%dT%H:%M:%S.%f%z\"\
        )\n                                prop_dict[\"soundscape:cycle_config_start_tzone\"\
        ] = str(data_json[\"product_configs\"]['hasher_config']['kwargs']['start_tzone'])\n\
        \                                prop_dict[\"soundscape:cycle_config_time_module\"\
        ] = int(data_json[\"product_configs\"]['hasher_config']['kwargs']['time_module'])\n\
        \                                prop_dict[\"soundscape:cycle_config_time_unit\"\
        ] = str(data_json[\"product_configs\"]['hasher_config']['kwargs']['time_unit'])\n\
        \                                prop_dict[\"soundscape:cycle_config_time_utc_column\"\
        ] = str(data_json[\"product_configs\"]['hasher_config']['kwargs']['time_utc_column'])\n\
        \                                prop_dict[\"soundscape:frequency_bins\"]\
        \ = int(data_json[\"product_configs\"][\"slice_config\"][\"frequency_bins\"\
        ])\n                                prop_dict[\"soundscape:frequency_hop\"\
        ] = int(data_json[\"product_configs\"][\"slice_config\"][\"frequency_hop\"\
        ])\n                                prop_dict[\"soundscape:frequency_limits\"\
        ] = str(data_json[\"product_configs\"][\"slice_config\"][\"frequency_limits\"\
        ])\n                                prop_dict[\"soundscape:hash_name\"] =\
        \ str(data_json[\"product_configs\"][\"hash_name\"])\n                   \
        \             prop_dict[\"soundscape:hop_length\"] = int(data_json[\"product_configs\"\
        ][\"slice_config\"][\"feature_config\"][\"hop_length\"])\n               \
        \                 prop_dict[\"soundscape:indices\"] =  \", \".join(map(str,\
        \ data_json['product_configs']['indices']))\n                            \
        \    prop_dict[\"soundscape:n_fft\"] = int(data_json[\"product_configs\"][\"\
        slice_config\"][\"feature_config\"][\"n_fft\"])\n                        \
        \        prop_dict[\"soundscape:npartitions\"] = int(data_json[\"product_configs\"\
        ]['npartitions'])\n                                prop_dict[\"soundscape:product_name\"\
        ] = str(data_json[\"product_name\"])\n                                prop_dict[\"\
        soundscape:product_parent\"] = str(data_json[\"product_parent\"])\n      \
        \                          prop_dict[\"soundscape:product_path\"] = str(alfresco_path)\n\
        \                                prop_dict[\"soundscape:product_spectrum\"\
        ] = str(data_json[\"product_spectrum\"])\n                               \
        \ prop_dict[\"soundscape:slice_config_feature_type\"] = str(data_json[\"product_configs\"\
        ][\"slice_config\"][\"feature_type\"])\n                                prop_dict[\"\
        soundscape:slice_config_frequency_bins\"] = int(data_json[\"product_configs\"\
        ][\"slice_config\"][\"frequency_bins\"])\n                               \
        \ prop_dict[\"soundscape:slice_config_time_unit\"] = int(data_json[\"product_configs\"\
        ][\"slice_config\"][\"time_unit\"])\n                                prop_dict[\"\
        soundscape:time_hop\"] = int(data_json[\"product_configs\"][\"slice_config\"\
        ][\"time_hop\"])\n                                prop_dict[\"soundscape:window_function\"\
        ] = str(data_json[\"product_configs\"][\"slice_config\"][\"feature_config\"\
        ][\"window_function\"])  \n\n                            elif (\"spectrogram\"\
        \ or \"video\") in entry['entry']['name']:\n                             \
        \   prop_dict[\"soundscape:product_name\"] = str(data_json[\"product_name\"\
        ])\n                                prop_dict[\"soundscape:product_parent\"\
        ] = str(data_json[\"product_parent\"])\n                                prop_dict[\"\
        soundscape:product_path\"] = str(alfresco_path)\n                        \
        \        prop_dict[\"soundscape:product_spectrum\"] = str(data_json[\"product_spectrum\"\
        ])\n                                prop_dict[\"soundscape:CumulusName\"]\
        \ = str(data_json[\"CumulusName\"])\n                                prop_dict[\"\
        soundscape:NodeCategoryIntegrity\"] = str(data_json[\"NodeCategoryIntegrity\"\
        ])\n                                prop_dict[\"soundscape:NomenclatureNode\"\
        ] = str(data_json[\"NomenclatureNode\"])\n                               \
        \ prop_dict[\"soundscape:SerialNumber\"] = str(data_json[\"SerialNumber\"\
        ])\n                                prop_dict[\"soundscape:DateDeployment\"\
        ] = data_json[\"DateDeployment\"]\n                                prop_dict[\"\
        soundscape:AudioID\"] = data_json[\"AudioID\"]\n\n                       \
        \ aspects = entry['entry']['aspectNames']\n                        data =\
        \ {\"aspectNames\": aspects, \"nodeType\": node_type, \"properties\": prop_dict}\n\
        \                        # update properties request\n                   \
        \     update = session.put(\n                            os.getenv(\"ALFRESCO_URL\"\
        )\n                            + BASE_ENDPOINT\n                         \
        \   + \"/nodes/\"\n                            + entry['entry']['id'],\n \
        \                           data=json.dumps(data),\n                     \
        \   )\n\n                        if update.status_code == 200:\n         \
        \                   print(\"Updated \" + entry['entry']['id'])           \
        \         \n\n        except Exception as e:\n            print(\"Could not\
        \ add any aspect to this file: \", e)\n\n    def create_results_folder_str(results_dir,\
        \ cumulo, nodes_list, rec_list, dep_list): \n        # results directory\n\
        \        os.makedirs(results_dir, exist_ok=True)\n        # cumulus subdir\n\
        \        cum_subdir = os.path.join(results_dir, str(cumulo))\n        os.makedirs(cum_subdir,\
        \ exist_ok=True)\n        # node subdirs\n        for node in nodes_list:\n\
        \            node_subdir = os.path.join(cum_subdir, node)\n            os.makedirs(node_subdir,\
        \ exist_ok=True)\n            # recorder subdirs\n            for rec in rec_list:\n\
        \                rec_subdir = os.path.join(node_subdir, rec)\n           \
        \     os.makedirs(rec_subdir, exist_ok=True)\n                # deployment\
        \ subdirs\n                for dep in dep_list:\n                    dep_subdir\
        \ = os.path.join(rec_subdir, dep)\n                    os.makedirs(dep_subdir,\
        \ exist_ok=True)\n\n    def distance_to_mean(vector, mean):\n        \\'\\\
        '\\'Return euclidean distance to mean\\'\\'\\'\n        return np.sqrt(np.sum(np.square(mean\
        \ - vector)))\n\n    def find_subfolders(path_abs):\n        subdir_list =\
        \ []\n        walk = list(os.walk(path_abs))\n        for path, _, _ in walk[::-1]:\n\
        \            len_path = path.split(\"/\")\n            if len(len_path) ==\
        \ 8:\n                subdir_list.append(path)  \n\n        return subdir_list\n\
        \n    def get_audio_ids(soundscape_path, indices, nsamples):\n        df =\
        \ pd.read_parquet(os.path.join(soundscape_path, \"hashed_soundscape.parquet\"\
        ))\n\n        df[\"time_raw_hour\"] = df[\"time_raw\"].apply(lambda x: datetime.datetime.strptime(x,'%H:%M:%S\
        \ %d/%m/%Y (%z)').strftime(\"%H\"))\n        hours_list = list(df.time_raw_hour.unique())\n\
        \        hours_list.sort(key = int)\n\n        with open(os.path.join(soundscape_path,\
        \ \"soundscape_metadata.json\")) as f:\n            metadata = json.load(f)\n\
        \            f.close()\n\n        # indices = metadata[\"product_configs\"\
        ][\"indices\"]\n        # indices = [\"EXAG\", \"ICOMPLEXITY\", \"CORE\"]\n\
        \        hash_name = metadata[\"product_configs\"][\"hash_name\"]\n      \
        \  cycle_config = metadata[\"product_configs\"][\"hasher_config\"][\"kwargs\"\
        ]\n        time_unit = cycle_config[\"time_unit\"]\n        zero_t = aware_time(cycle_config[\"\
        start_time\"], cycle_config[\"start_tzone\"], cycle_config[\"start_format\"\
        ]) \n\n        # iterate over hours\n        audio_id_list = []\n        for\
        \ hour in hours_list:\n            subdf = df.query(f\"time_raw_hour == '{hour}'\"\
        )\n            # sample\n            samples_df = get_recording_samples(subdf,\
        \ hash_name, indices, time_unit, zero_t, nsamples=3)\n            unique_crono_hash_list\
        \ = list(samples_df.crono_hash_30m.unique())\n            sub_df = samples_df[samples_df.crono_hash_30m\
        \ == min(unique_crono_hash_list)]\n            audio_id_list += list(sub_df.id.tolist())\n\
        \n        return audio_id_list\n\n    def get_recording_samples(df, hash_name,\
        \ indices, time_unit, zero_t, nsamples=5):\n        \\'\\'\\'Return dataframe\
        \ of 'nsamples' samples for each tag in 'hash_name' column that are closest\
        \ to the mean vector by tag\\'\\'\\'\n        proj_df = df[(df.max_freq <=\
        \ 10000)]\n        crono_tags = proj_df.crono_hash_30m.unique()\n        proj_df.loc[:\
        \ , f\"{hash_name}_time\"] = proj_df[hash_name].apply(lambda x: zero_t + datetime.timedelta(seconds=float(x*time_unit)))\n\
        \        vectors = vectorize_soundscape(proj_df, hash_name, indices)\n   \
        \     min_index_vector = np.amin(np.stack(list(vectors.index_vector.values)),\
        \ axis=(0,1))\n        max_index_vector = np.amax(np.stack(list(vectors.index_vector.values)),\
        \ axis=(0,1))\n        index_range = (max_index_vector - min_index_vector)\n\
        \        vectors.loc[:, \"normalized_index_vector\"] = vectors.index_vector.apply(lambda\
        \ x: (x-min_index_vector)/index_range)\n        all_samples = []\n\n     \
        \   for crono_tag in crono_tags:\n            unit_vectors = vectors[vectors[hash_name]\
        \ == crono_tag]\n            mean_unit_vector = unit_vectors.normalized_index_vector.mean()\n\
        \            unit_vectors.loc[:, \"distance\"] = unit_vectors.normalized_index_vector.apply(lambda\
        \ x: distance_to_mean(x, mean_unit_vector))\n            all_samples.append(unit_vectors.sort_values(by=\"\
        distance\").head(nsamples))\n        return pd.concat(all_samples)\n\n   \
        \ def get_vectors(group, indices):\n        \\'\\'\\'Return array of indices\
        \ by frequency\\'\\'\\'\n        return group.sort_values(by=\"max_freq\"\
        )[indices].values\n\n    def login():\n        \"\"\"\n        Tries a login\
        \ to alfresco api and returns a session\n        object with credentials \n\
        \        Returns: \n            session (Session):  A session object to make\
        \ \n                                requests to zendro.\n        \"\"\"\n\
        \        try:\n            auth = {\n                \"userId\": os.getenv(\"\
        ALFRESCO_USER\"),\n                \"password\": os.getenv(\"ALFRESCO_PASSWORD\"\
        ),\n            }\n\n            login = requests.post(os.getenv(\"ALFRESCO_URL\"\
        ) + AUTH_ENDPOINT + \"/tickets\",data=json.dumps(auth))\n\n            base64_login\
        \ = base64.b64encode(bytes(login.json()[\"entry\"][\"id\"], 'utf-8')).decode()\n\
        \n            # se crea un objeto de Session para hacer requests\n       \
        \     session = requests.Session()\n            # se establece bearer token\n\
        \            session.headers.update({'Authorization': 'Basic ' + base64_login})\n\
        \n            return session\n        except Exception as e:\n           \
        \ print(\"Login failed: \", e)\n\n    def plot_spectrogram(audio_id, audio_df,\
        \ save_path_folder, spectrum, cumulus):\n        sub_audio_df = audio_df[audio_df[\"\
        id\"]==audio_id]\n        node = sub_audio_df['node'].values[0]\n        recorder\
        \ = sub_audio_df['recorder'].values[0]\n        deployment = sub_audio_df['deployment'].values[0]\n\
        \        # plot\n        fig, ax = plt.subplots(2,1,figsize=(20,10), sharex=True)\n\
        \        sub_audio_df.audio[0].plot(ax=ax[0], color='grey')\n        sub_audio_df.audio[0].features.db_spectrogram().plot(ax=ax[1])\n\
        \        ax[0].set_ylabel('Amplitude')\n        ax[0].grid(False)\n      \
        \  ax[1].set_ylabel('F (KHz)')\n        ax[1].set_xlabel('Time (seconds)')\n\
        \        fig.text(0.75, 0.04, f\"Cumulus: {cumulus} - Node: {node} - Recorder:\
        \ {recorder}\", va='center')\n        plt.tight_layout()\n        if save_path_folder:\n\
        \            file_path = os.path.join(save_path_folder, f\"{audio_id}.png\"\
        )\n            fig.savefig(file_path)\n        plt.show()\n\n        save_metadata_spectrogram(audio_id,\
        \ spectrum, save_path_folder, \n                                  cumulus,\
        \ node, recorder, deployment, parent=\"Null\")\n\n    def plot_soundscape(soundscape,\
        \ product_type, product_spectrum, sc_config, path, \n                    \
        \    cumulus, node, recorder, deployment, parent, indices, min_freq=None,\n\
        \                      figsize=(20,15), plt_style='ggplot'):\n\n        if\
        \ min_freq:\n            soundscape = soundscape[soundscape['min_freq']<=min_freq]\n\
        \n        if product_type == \"sequence\":\n            file_path = os.path.join(path,\
        \ \"sequence.png\")\n            # product_id = hashlib.md5(file_path.encode('utf-8')).hexdigest()\n\
        \n            plt.style.use(plt_style)\n            fig, ax = plt.subplots(figsize=figsize)\n\
        \            soundscape.sndscape.plot_sequence(rgb=indices, time_format='%Y-%m\
        \ %H:%M', ax=ax)\n            plt.xticks(rotation = 90)\n            ax.grid(False)\n\
        \            plt.tight_layout()\n            plt.savefig(file_path) \n   \
        \         plt.show()\n            # save metadata\n            save_metadata_sc(product_type,\
        \ product_spectrum, sc_config,\n                      path, cumulus, node,\
        \ recorder, deployment, parent=parent)\n\n        elif product_type == \"\
        standard_deviation\":\n            file_path = os.path.join(path, \"std_soundscape.png\"\
        )\n            # product_id = hashlib.md5(file_path.encode('utf-8')).hexdigest()\n\
        \n            plt.style.use(plt_style)\n            fig, ax = plt.subplots(figsize=figsize)\n\
        \            soundscape.sndscape.plot_cycle(rgb=indices, aggr=\"std\", time_format='%H:%M',\
        \ \n                                           xticks=24, ax=ax)\n       \
        \     plt.xticks(rotation = 90)\n            ax.grid(False)\n            plt.tight_layout()\
        \ \n            plt.savefig(file_path)\n            plt.show()\n\n       \
        \     # save metadata\n            save_metadata_sc(product_type, product_spectrum,\
        \ sc_config,\n                      path, cumulus, node, recorder, deployment,\
        \ parent)     \n\n        elif product_type == \"mean\": \n            file_path\
        \ = os.path.join(path, \"mean_soundscape.png\")\n            # product_id\
        \ = hashlib.md5(file_path.encode('utf-8')).hexdigest()\n\n            plt.style.use(plt_style)\n\
        \            fig, ax = plt.subplots(figsize=figsize)\n            soundscape.sndscape.plot_cycle(rgb=indices,\
        \ aggr=\"mean\", time_format='%H:%M', \n                                 \
        \          xticks=24, ax=ax)\n            plt.xticks(rotation = 90)\n    \
        \        ax.grid(False)\n            plt.tight_layout()\n            plt.savefig(file_path)\n\
        \            plt.show()\n\n            # save metadata\n            save_metadata_sc(product_type,\
        \ product_spectrum, sc_config,\n                      path, cumulus, node,\
        \ recorder, deployment, parent)    \n\n        print(f\"File saved at {file_path}\"\
        )\n\n    def produce_clip(spec, frame_duration, min_freq, max_freq, start,\
        \ stop, step, abs_start=None, \n                     colormap=cm.get_cmap(\"\
        Greys\"), min_spec=0, spec_range=1.0, figsize=(5, 4), \n                 \
        \    dpi=100, bands=None):\n        \\'\\'\\'Takes an individual frame and\
        \ produces an image with references\\'\\'\\'\n        frame = spec.cut_array(start_time=start,\
        \ end_time=stop, min_freq=min_freq, max_freq=max_freq, pad=True)\n       \
        \ plt.style.use('dark_background')\n        frame = np.flip((frame - min_spec)/spec_range,\
        \ axis=0)\n        fig, ax = plt.subplots(figsize=figsize)\n        ax.imshow(frame,\
        \ cmap=colormap, extent=[0, frame_duration, min_freq/1000, max_freq/1000],\
        \ \n                  aspect=\"auto\", vmin = 0, vmax = 1.0)\n\n        if\
        \ bands is not None:\n            band_arr = np.flip(resize(np.expand_dims(bands,\
        \ axis=1), (frame.shape[0], frame.shape[1])), axis=0)\n            ax.imshow(band_arr,\
        \ extent=[0, frame_duration, min_freq/1000, max_freq/1000], aspect=\"auto\"\
        , vmin = 0, \n                      vmax = 1.0, alpha=0.5)\n\n        ax.tick_params(axis='both',\
        \ which='major', labelsize=8)\n        ax.tick_params(axis='both', which='minor',\
        \ labelsize=8)\n        mid = frame_duration/2.0\n        ax.axvline(x=mid,\
        \ color=\"red\")\n        ax.set_ylabel('F (kHz)')\n        ax.set_xticks([])\n\
        \        ax.set_xticks([], minor=True)\n\n        if abs_start is not None:\n\
        \            time_text = (abs_start + datetime.timedelta(seconds=start+mid)).strftime('%H:%M:%S.%f').strip()[:-4]\n\
        \            ax.text(mid-0.3, -0.6, time_text)\n\n        buf = io.BytesIO()\n\
        \        fig.tight_layout()\n        fig.savefig(buf, dpi=dpi)\n        buf.seek(0)\n\
        \        im = Image.open(buf)\n        im.format = \"PNG\"\n        plt.close(fig)\n\
        \n        return ImageClip(np.asarray(im),\n                         duration=step)\n\
        \n    def remove_empty_folders(path_abs):\n        walk = list(os.walk(path_abs))\n\
        \        for path, _, _ in walk[::-1]:\n            if len(os.listdir(path))\
        \ == 0:\n                os.rmdir(path)            \n\n    def save_metadata_sc(product_type,\
        \ product_spectrum, sc_config,\n                      path, cumulus, node,\
        \ recorder, deployment, parent=\"Null\"):\n        if product_type == \"soundscape\"\
        :\n            product_name = \"Soundscape\"\n            file_path = os.path.join(path,\
        \ \"hashed_soundscape.parquet\")\n            metadata_filename = os.path.join(path,\
        \ \"soundscape_metadata.json\")\n        elif product_type == \"sequence\"\
        :\n            product_name = \"Soundscape sequential plot\"\n           \
        \ file_path = os.path.join(path, \"soundscape_seq.png\")\n            metadata_filename\
        \ = os.path.join(path, \"soundscape_seq_metadata.json\")\n        elif product_type\
        \ == \"standard_deviation\":\n            product_name = \"Soundscape standard\
        \ deviation plot\"\n            file_path = os.path.join(path, \"std_soundscape.png\"\
        )\n            metadata_filename = os.path.join(path, \"std_soundscape_metadata.json\"\
        )\n        elif product_type == \"mean\":\n            product_name = \"Soundscape\
        \ mean plot\"\n            file_path = os.path.join(path, \"mean_soundscape.png\"\
        )\n            metadata_filename = os.path.join(path, \"mean_soundscape_metadata.json\"\
        )\n\n        if int(node.split(\"_\")[2]) == 0:\n            node_category\
        \ = \"Degradado\"\n        elif int(node.split(\"_\")[2]) == 1:\n        \
        \    node_category = \"Integro\"\n\n        metadata = {\n            \"product_parent\"\
        : parent,\n            \"product_name\": product_name,\n            \"product_configs\"\
        : sc_config,\n            \"product_path\": file_path,\n            \"product_spectrum\"\
        : product_spectrum,\n            \"CumulusName\": cumulus,\n            \"\
        NodeCategoryIntegrity\": node_category,\n            \"NomenclatureNode\"\
        : node,\n            \"SerialNumber\": recorder,\n            \"DateDeployment\"\
        : deployment\n        }\n\n        with open(metadata_filename, 'w', encoding='utf-8')\
        \ as f:\n            json.dump(metadata, f, ensure_ascii=False, indent=4)\n\
        \n    def save_metadata_spectrogram(audio_id, product_spectrum,\n        \
        \              path, cumulus, node, recorder, deployment, parent=\"Null\"\
        ):\n        # identifier is being used as audio_id in alfresco\n        product_name\
        \ = \"Spectrogram\"\n        file_path = os.path.join(path, f\"{audio_id}.png\"\
        )\n        metadata_filename = os.path.join(path, f\"{audio_id}_spectrogram_metadata.json\"\
        )\n\n        if int(node.split(\"_\")[2]) == 0:\n            node_category\
        \ = \"Degradado\"\n        elif int(node.split(\"_\")[2]) == 1:\n        \
        \    node_category = \"Integro\"\n\n        metadata = {\n            \"product_parent\"\
        : parent,\n            \"product_name\": product_name,\n            \"product_path\"\
        : file_path,\n            \"product_spectrum\": product_spectrum,\n      \
        \      \"CumulusName\": cumulus,\n            \"NodeCategoryIntegrity\": node_category,\n\
        \            \"NomenclatureNode\": node,\n            \"SerialNumber\": recorder,\n\
        \            \"DateDeployment\": deployment,\n            \"AudioID\": audio_id\n\
        \        }\n        with open(metadata_filename, 'w', encoding='utf-8') as\
        \ f:\n            json.dump(metadata, f, ensure_ascii=False, indent=4)\n\n\
        \        print(f\"{file_path} saved.\")\n        print(f\"{metadata_filename}\
        \ saved.\")\n\n    def save_metadata_videoclip(audio_id, product_spectrum,\
        \ path, cumulus, node, recorder, \n                                deployment,\
        \ clip_start, clip_end, parent=\"Null\"):\n        # identifier is being used\
        \ as audio_id in alfresco\n        product_name = \"spectrogram_video\"\n\
        \        file_path = os.path.join(path, f\"{audio_id}.mp4\")\n        metadata_filename\
        \ = os.path.join(path, f\"{audio_id}_spectrogram_video_metadata.json\")\n\n\
        \        if int(node.split(\"_\")[2]) == 0:\n            node_category = \"\
        Degradado\"\n        elif int(node.split(\"_\")[2]) == 1:\n            node_category\
        \ = \"Integro\"\n\n        metadata = {\n            \"product_parent\": parent,\n\
        \            \"product_name\": product_name,\n            \"product_description\"\
        : \"Spectrogram Video. Time is show in local timezone\",\n            \"product_path\"\
        : file_path,\n            \"product_spectrum\": product_spectrum,\n      \
        \      \"CumulusName\": cumulus,\n            \"NodeCategoryIntegrity\": node_category,\n\
        \            \"NomenclatureNode\": node,\n            \"SerialNumber\": recorder,\n\
        \            \"DateDeployment\": deployment,\n            \"ClipStart\": clip_start,\n\
        \            \"ClipEnd\": clip_end,\n            \"AudioID\": audio_id\n \
        \       }\n\n        with open(metadata_filename, 'w', encoding='utf-8') as\
        \ f:\n            json.dump(metadata, f, ensure_ascii=False, indent=4)\n\n\
        \        print(f\"{file_path} saved.\")\n        print(f\"{metadata_filename}\
        \ saved.\")\n\n    def upload(session, node_id, data, file):\n        \"\"\
        \"\n        Uploads a file to a specific folder.\n        Parameters:\n  \
        \          session (Session):          A session object to make\n        \
        \                                requests to alfresco.\n            node_id\
        \ (string):           Node id to which the file is going to be created\n \
        \           data (dict):                Dict that contains file options\n\
        \            file (object):              File to upload\n\n        Returns:\n\
        \            (list):     A list containing status code and status data\n \
        \       \"\"\"\n\n        try:\n            response = session.post(os.getenv(\"\
        ALFRESCO_URL\")\n                        + BASE_ENDPOINT + \"/nodes/\" + node_id\
        \ + \"/children\",\n                        data = data,\n               \
        \         files = file\n                        )\n\n            return [response.json(),\
        \ response.status_code];\n        except Exception as e: \n            print(\"\
        File \" + data[\"name\"] + \" could not be uploaded: \", e)\n\n    def upload_files(file_patterns,\
        \ session, node_id, dir_path, recursive, file_identifier=\"\"):\n        \"\
        \"\"\n        Uploads the files stored in a specific dir\n        to alfresco\n\
        \        Parameters:\n            session (Session):          A session object\
        \ to make\n                                        requests to alfresco.\n\
        \            node_id (string):           Node id to which the file is going\
        \ to be created\n            dir_path (string):          The name and path\
        \ of the dir where files are stored\n            recursive (boolean):    \
        \    A boolean to know if upload  must be recursive\n                    \
        \                    in the specifed dir, and should preserve the\n      \
        \                                  structure of dirs inside.\n           \
        \ file_identifier (string):   File identifier for all files inside a dir\n\
        \        Returns:\n            (string):           Returns the info of recent\
        \ created site.\n        \"\"\"\n\n        if recursive:\n            expression\
        \ = \"/**/*\"\n        else:\n            expression = \"/*\"\n\n        files_in_dir\
        \ = list(\n            itertools.chain.from_iterable(\n                glob.iglob(dir_path\
        \ + expression + pattern, recursive=recursive)\n                for pattern\
        \ in file_patterns\n            )\n        )\n        filename = \"logs/upload_log\"\
        \ + dir_path.replace('/','-') + '.txt'\n\n        os.makedirs(os.path.dirname(filename),\
        \ exist_ok=True)\n\n        total_files = len(files_in_dir)\n        starttime\
        \ = time.time()\n\n        try:\n            files_uploaded = []\n       \
        \     for idx, file_with_path in enumerate(files_in_dir):\n\n            \
        \    # total time since last login or script start\n                total_time\
        \ = round((time.time() - starttime), 2)\n\n                if total_time >\
        \ 2400:\n                    \"\"\"\n                    if total time is\
        \ bigger than 2400\n                    or 40 minutes relogin to avoid ticket\n\
        \                    expiration\n                    \"\"\"\n            \
        \        time.sleep(5)\n\n                    print(\"Re-logging in to alfresco...\"\
        )\n\n                    session = login.login()\n                    # restart\
        \ time\n                    starttime = time.time()\n                    time.sleep(5)\n\
        \                    print(\"Login sucessful, continuing upload\\\\n\")\n\n\
        \                len_of_path = len(file_with_path.split(\"/\"))\n        \
        \        name_of_file = file_with_path.split(\"/\")[len_of_path - 1]\n   \
        \             root_dir_path = file_with_path.replace(dir_path, \"\").replace(\n\
        \                    file_with_path.split(\"/\")[len_of_path - 1], \"\"\n\
        \                )\n\n                data = {\n                    \"name\"\
        : (\n                        name_of_file[0 : len(name_of_file) - 4]\n   \
        \                     + file_identifier\n                        + name_of_file[len(name_of_file)\
        \ - 4 : len(name_of_file)]\n                    ),\n                    \"\
        nodeType\": \"cm:content\",\n                }\n\n                data[\"\
        relativePath\"] = root_dir_path\n\n                data[\"properties\"] =\
        \ {\n                    \"cm:title\": (\n                        name_of_file[0\
        \ : len(name_of_file) - 4]\n                        + file_identifier\n  \
        \                      + name_of_file[len(name_of_file) - 4 : len(name_of_file)]\n\
        \                    )\n                }\n\n                print(\"Uploading\
        \ \" + data[\"name\"] + \" file...\")\n\n                files = {\"filedata\"\
        : open(file_with_path, \"rb\")}\n                upload_response = upload(session,\
        \ node_id, data, files)\n                if upload_response[1] and upload_response[1]\
        \ == 201:\n                    files_uploaded.append(upload_response[0])\n\
        \                    print(\"Uploaded \" + data[\"name\"])\n\n           \
        \         filename = \"logs/upload_log\" + dir_path.replace('/','-') + '.txt'\n\
        \                    with open(filename, 'a') as log_file:\n             \
        \           log_file.writelines(\"%s\\\\n\" % file_with_path)\n\n        \
        \        elif upload_response[1] and upload_response[1] == 409:\n        \
        \            if \"already exists\" in upload_response[0][\"error\"][\"errorKey\"\
        ]:\n                        print(\"File \" + data[\"name\"] + \" already\
        \ uploaded\")\n\n                else:\n                    print(\"An error\
        \ ocurred, file \" + data[\"name\"] + \" cannot be uploaded\")\n\n       \
        \         print(\"Uploaded file \" + str(idx + 1) + \" of \" + str(total_files))\n\
        \                print(\"\\\\n\\\\n\")\n\n            return files_uploaded\n\
        \        except Exception as e:\n            print(\"An error ocurred in file\
        \ upload: \", e)\n\n    def vectorize_soundscape(df, hash_name, indices):\n\
        \        \\'\\'\\'Return dataframe with array column containing indices by\
        \ frequency\\'\\'\\'\n        return (df\n                .groupby(by=[\"\
        id\", hash_name, \"start_time\", \"end_time\"])\n                .apply(get_vectors,\
        \ indices)\n                .reset_index()\n                .rename(columns={0:\"\
        index_vector\"}))\n    '''\n\n    _kale_block3 = '''\n    FILE_PATTERNS =\
        \ [\".mp4\", \".png\"] #\".parquet\"\n    load_dotenv()\n    session = login()\n\
        \    upload_files(FILE_PATTERNS, session, ALFRESCO_NODE_ID, RESULTS_DIR, recursive=\
        \ True, file_identifier=\"\")\n    '''\n\n    # run the code blocks inside\
        \ a jupyter kernel\n    from kale.common.jputils import run_code as _kale_run_code\n\
        \    from kale.common.kfputils import \\\n        update_uimetadata as _kale_update_uimetadata\n\
        \    _kale_blocks = (_kale_pipeline_parameters_block,\n                  \
        \  _kale_block1,\n                    _kale_block2,\n                    _kale_block3,\n\
        \                    )\n    _kale_html_artifact = _kale_run_code(_kale_blocks)\n\
        \    with open(\"/upload_to_alfresco.html\", \"w\") as f:\n        f.write(_kale_html_artifact)\n\
        \    _kale_update_uimetadata('upload_to_alfresco')\n\n    _kale_mlmdutils.call(\"\
        mark_execution_complete\")\n\nimport argparse\n_parser = argparse.ArgumentParser(prog='Upload\
        \ to alfresco', description='')\n_parser.add_argument(\"--ALFRESCO-NODE-ID\"\
        , dest=\"ALFRESCO_NODE_ID\", type=str, required=True, default=argparse.SUPPRESS)\n\
        _parser.add_argument(\"--AUTH-ENDPOINT\", dest=\"AUTH_ENDPOINT\", type=str,\
        \ required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"--BASE-ENDPOINT\"\
        , dest=\"BASE_ENDPOINT\", type=str, required=True, default=argparse.SUPPRESS)\n\
        _parser.add_argument(\"--RESULTS-DIR\", dest=\"RESULTS_DIR\", type=str, required=True,\
        \ default=argparse.SUPPRESS)\n_parsed_args = vars(_parser.parse_args())\n\n\
        _outputs = upload_to_alfresco(**_parsed_args)\n"
      image: sipecam/audio-dgpi-kale-tensorflow-yuntu-dask-cert:0.6.1_dev
      securityContext: {runAsUser: 0}
      volumeMounts:
      - {mountPath: /shared_volume, name: pvolume-ef6fe65091618f865041935b363277953274adf6b420fd4a7b8277d}
      workingDir: //shared_volume/audio
    inputs:
      parameters:
      - {name: ALFRESCO_NODE_ID}
      - {name: AUTH_ENDPOINT}
      - {name: BASE_ENDPOINT}
      - {name: RESULTS_DIR}
      - {name: vol_shared_volume}
    outputs:
      artifacts:
      - {name: mlpipeline-ui-metadata, path: /tmp/mlpipeline-ui-metadata.json}
      - {name: upload_to_alfresco, path: /upload_to_alfresco.html}
    metadata:
      annotations: {kubeflow-kale.org/dependent-templates: '["spec-n-specvid"]', pipelines.kubeflow.org/component_spec: '{"implementation":
          {"container": {"args": ["--ALFRESCO-NODE-ID", {"inputValue": "ALFRESCO_NODE_ID"},
          "--AUTH-ENDPOINT", {"inputValue": "AUTH_ENDPOINT"}, "--BASE-ENDPOINT", {"inputValue":
          "BASE_ENDPOINT"}, "--RESULTS-DIR", {"inputValue": "RESULTS_DIR"}], "command":
          ["sh", "-ec", "program_path=$(mktemp)\nprintf \"%s\" \"$0\" > \"$program_path\"\npython3
          -u \"$program_path\" \"$@\"\n", "def upload_to_alfresco(ALFRESCO_NODE_ID,
          AUTH_ENDPOINT, BASE_ENDPOINT, RESULTS_DIR):\n    _kale_pipeline_parameters_block
          = ''''''\n    ALFRESCO_NODE_ID = \"{}\"\n    AUTH_ENDPOINT = \"{}\"\n    BASE_ENDPOINT
          = \"{}\"\n    RESULTS_DIR = \"{}\"\n    ''''''.format(ALFRESCO_NODE_ID,
          AUTH_ENDPOINT, BASE_ENDPOINT, RESULTS_DIR)\n\n    from kale.common import
          mlmdutils as _kale_mlmdutils\n    _kale_mlmdutils.init_metadata()\n\n    _kale_block1
          = ''''''\n    import base64\n    import datetime\n    import glob\n    import
          hashlib\n    import io\n    import itertools\n    import json\n    import
          matplotlib.pyplot as plt\n    import multiprocessing \n    import numpy
          as np\n    import os\n    import pandas as pd\n    import psutil\n    import
          requests\n    import shutil\n    import subprocess\n    import time\n    import
          warnings\n\n    from dask.distributed import Client, LocalCluster\n    from
          datetime import timedelta\n    from dotenv import load_dotenv\n    from
          matplotlib import cm\n    from moviepy.editor import concatenate, VideoFileClip,
          AudioFileClip\n    from moviepy.audio.AudioClip import AudioArrayClip\n    from
          moviepy.video.VideoClip import ImageClip\n    from os.path import exists
          as file_exists\n    from PIL import Image\n    from skimage.transform import
          resize\n\n    from yuntu import Audio\n    from yuntu.soundscape.utils import
          aware_time\n    from yuntu.collection.methods import collection\n    from
          yuntu.soundscape.hashers.crono import DEFAULT_HASHER_CONFIG\n    from yuntu.soundscape.processors.indices.direct
          import ICOMPLEXITY, TAIL\n    from yuntu.soundscape.pipelines.build_soundscape
          import CronoSoundscape, HASHER_CONFIG\n    ''''''\n\n    _kale_block2 =
          ''''''\n    def audio2video(audio_id,\n                    audio_df,\n                    save_path_folder,\n                    product_spectrum,\n                    cumulus,\n                    abs_start=None,\n                    fps=60,\n                    spec_configs={''hop_length'':
          512, ''n_fft'': 1024, ''window_function'': ''hann''},\n                    rate=24,\n                    frame_duration=3.0,\n                    min_freq=0,\n                    max_freq=None,\n                    cmap=\"Greys\",\n                    figsize=(5,
          8),\n                    dpi=100,\n                    bands=None):\n        \\''\\''\\''Takes
          and audio object and produces a mp4 video of the spectrogram with audio\\''\\''\\''\n\n        sub_audio_df
          = audio_df[audio_df[\"id\"]==audio_id]\n        id_audio = sub_audio_df[''id''].values[0]\n        node
          = sub_audio_df[''node''].values[0]\n        recorder = sub_audio_df[''recorder''].values[0]\n        deployment
          = sub_audio_df[''deployment''].values[0]\n        audio = sub_audio_df.audio[0]\n\n        colormap
          = cm.get_cmap(cmap)\n        duration = audio.duration\n        step = 1/rate\n        start
          = -(frame_duration/2.0)\n        stop = start + frame_duration\n        clips
          = []\n        last_stop = None\n\n        if max_freq is None:\n            max_freq
          = audio.samplerate / 2.0\n\n        if min_freq is None:\n            min_freq
          = 0\n\n        with audio.features.db_spectrogram(**spec_configs) as spec:\n            min_spec
          = np.amin(spec)\n            max_spec = np.amax(spec)\n            spec_range
          = (max_spec-min_spec)\n\n            while stop <= duration+(frame_duration/2.0):\n                clip
          = produce_clip(spec, frame_duration, min_freq, max_freq, start, stop, step,
          abs_start, colormap,\n                                    min_spec, spec_range,
          figsize, dpi, bands=bands)\n                clips.append(clip)\n\n                if
          start + step + frame_duration > duration:\n                    last_stop
          = stop\n\n                start = start + step\n                stop = start
          + frame_duration\n\n        video = concatenate(clips)\n        # edaudio
          = AudioArrayClip(audio_array, fps=audio.samplerate)\n        edaudio = AudioFileClip(audio.path).set_end(audio.duration)\n        video
          = video.set_audio(edaudio)\n        file_path = os.path.join(save_path_folder,
          f\"{audio_id}.mp4\")\n        video.write_videofile(file_path, fps=fps)\n\n        save_metadata_videoclip(audio_id,
          product_spectrum,\n                      save_path_folder, cumulus, node,
          recorder, deployment, 0.0, audio.duration)\n        video.close()\n        edaudio.close()\n\n        for
          c in clips:\n            c.close()\n\n    def change_type_sipecam_sc(session,
          root_folder_id, path, file_type, node_type):\n        if file_type == \"sequence.png\":\n            metadata_name
          = \"soundscape_seq_metadata.json\"\n            aggr_type = \"None\"\n        elif
          file_type == \"mean_soundscape.png\":\n            metadata_name = \"mean_soundscape_metadata.json\"\n            aggr_type
          = \"Mean\"\n        elif file_type ==  \"std_soundscape.png\":\n            metadata_name
          = \"std_soundscape_metadata.json\" \n            aggr_type = \"Standard
          deviation\"\n        elif file_type == \"hashed_soundscape.parquet\":\n            metadata_name
          = \"soundscape_metadata.json\" \n            aggr_type = \"None\"\n        elif
          \".png\" in file_type and (file_type not in [\"sequence.png\", \"mean_soundscape.png\",
          \"std_soundscape.png\"]):\n            metadata_name = file_type.split(\".\")[0]
          + \"_spectrogram_metadata.json\"\n            aggr_type = \"Null\"\n        elif
          \".mp4\" in file_type and (file_type not in [\"sequence.png\", \"mean_soundscape.png\",
          \"std_soundscape.png\"]):\n            metadata_name = file_type.split(\".\")[0]
          + \"_spectrogram_video_metadata.json\"\n            aggr_type = \"Null\"\n\n        try:\n            semi_path
          = path.split(\"soundscapes/\")[-1]\n            semi_path_file = os.path.join(semi_path,
          file_type)\n            local_path_file_metadata = os.path.join(path, metadata_name)\n            print(f\"Changing
          type for {os.path.join(semi_path)}\")\n            alfresco_path = os.path.join(\"/Company
          Home/Sites/sipecam-soundscape/documentLibrary/\", semi_path)\n\n            response
          = session.get(\n                os.getenv(\"ALFRESCO_URL\")\n                +
          BASE_ENDPOINT\n                + \"/nodes/\"\n                + root_folder_id\n                +
          \"/children?relativePath=\"+semi_path+\"&include=aspectNames&skipCount=0\"\n            )        \n            #
          if request is successful then continue\n            if response.status_code
          == 200:\n\n                data_file = open(local_path_file_metadata)\n                data_json
          = json.load(data_file)\n                response_entries = response.json()[\"list\"][\"entries\"]\n\n                for
          entry in response_entries:\n                    if entry[''entry''][''name'']==file_type
          and entry[''entry''][''isFile'']:\n                        prop_dict = {}\n\n                        if
          entry[''entry''][''name'']==file_type:\n\n                            if
          entry[''entry''][''name''] in [\"sequence.png\", \"mean_soundscape.png\",
          \"std_soundscape.png\"]:\n                                prop_dict[\"soundscape:CumulusName\"]
          = str(data_json[\"CumulusName\"])\n                                prop_dict[\"soundscape:DateDeployment\"]
          = data_json[\"DateDeployment\"]\n                                prop_dict[\"soundscape:NodeCategoryIntegrity\"]
          = str(data_json[\"NodeCategoryIntegrity\"])\n                                prop_dict[\"soundscape:NomenclatureNode\"]
          = str(data_json[\"NomenclatureNode\"])\n                                prop_dict[\"soundscape:SerialNumber\"]
          = str(data_json[\"SerialNumber\"])\n                                prop_dict[\"soundscape:aggr\"]
          = str(aggr_type)\n                                prop_dict[\"soundscape:cycle_config_aware_start\"]
          = str(data_json[\"product_configs\"][''hasher_config''][''kwargs''][''aware_start''])\n                                prop_dict[\"soundscape:cycle_config_start_format\"]
          = str(data_json[\"product_configs\"][''hasher_config''][''kwargs''][''start_format''])\n                                prop_dict[\"soundscape:cycle_config_start_time\"]
          =  datetime.datetime.strptime(data_json[\"product_configs\"][''hasher_config''][''kwargs''][''start_time''],
          \n                                                                                                        \"%Y-%m-%d
          %H:%M:%S\").strftime(\"%Y-%m-%dT%H:%M:%S.%f%z\")\n                                prop_dict[\"soundscape:cycle_config_start_tzone\"]
          = str(data_json[\"product_configs\"][''hasher_config''][''kwargs''][''start_tzone''])\n                                prop_dict[\"soundscape:cycle_config_time_module\"]
          = int(data_json[\"product_configs\"][''hasher_config''][''kwargs''][''time_module''])\n                                prop_dict[\"soundscape:cycle_config_time_unit\"]
          = str(data_json[\"product_configs\"][''hasher_config''][''kwargs''][''time_unit''])\n                                prop_dict[\"soundscape:cycle_config_time_utc_column\"]
          = str(data_json[\"product_configs\"][''hasher_config''][''kwargs''][''time_utc_column''])\n                                prop_dict[\"soundscape:frequency_bins\"]
          = int(data_json[\"product_configs\"][\"slice_config\"][\"frequency_bins\"])\n                                prop_dict[\"soundscape:frequency_hop\"]
          = int(data_json[\"product_configs\"][\"slice_config\"][\"frequency_hop\"])\n                                prop_dict[\"soundscape:frequency_limits\"]
          = str(data_json[\"product_configs\"][\"slice_config\"][\"frequency_limits\"])\n                                prop_dict[\"soundscape:hash_name\"]
          = str(data_json[\"product_configs\"][\"hash_name\"])\n                                prop_dict[\"soundscape:hop_length\"]
          = int(data_json[\"product_configs\"][\"slice_config\"][\"feature_config\"][\"hop_length\"])\n                                prop_dict[\"soundscape:indices\"]
          =  \", \".join(map(str, data_json[''product_configs''][''indices'']))\n                                prop_dict[\"soundscape:n_fft\"]
          = int(data_json[\"product_configs\"][\"slice_config\"][\"feature_config\"][\"n_fft\"])\n                                prop_dict[\"soundscape:npartitions\"]
          = int(data_json[\"product_configs\"][''npartitions''])\n                                prop_dict[\"soundscape:product_name\"]
          = str(data_json[\"product_name\"])\n                                prop_dict[\"soundscape:product_parent\"]
          = str(data_json[\"product_parent\"])\n                                prop_dict[\"soundscape:product_path\"]
          = str(alfresco_path)\n                                prop_dict[\"soundscape:product_spectrum\"]
          = str(data_json[\"product_spectrum\"])\n                                prop_dict[\"soundscape:slice_config_feature_type\"]
          = str(data_json[\"product_configs\"][\"slice_config\"][\"feature_type\"])\n                                prop_dict[\"soundscape:slice_config_frequency_bins\"]
          = int(data_json[\"product_configs\"][\"slice_config\"][\"frequency_bins\"])\n                                prop_dict[\"soundscape:slice_config_time_unit\"]
          = int(data_json[\"product_configs\"][\"slice_config\"][\"time_unit\"])\n                                prop_dict[\"soundscape:time_hop\"]
          = int(data_json[\"product_configs\"][\"slice_config\"][\"time_hop\"])\n                                prop_dict[\"soundscape:window_function\"]
          = str(data_json[\"product_configs\"][\"slice_config\"][\"feature_config\"][\"window_function\"])  \n\n                            elif
          (\"spectrogram\" or \"video\") in entry[''entry''][''name'']:\n                                prop_dict[\"soundscape:product_name\"]
          = str(data_json[\"product_name\"])\n                                prop_dict[\"soundscape:product_parent\"]
          = str(data_json[\"product_parent\"])\n                                prop_dict[\"soundscape:product_path\"]
          = str(alfresco_path)\n                                prop_dict[\"soundscape:product_spectrum\"]
          = str(data_json[\"product_spectrum\"])\n                                prop_dict[\"soundscape:CumulusName\"]
          = str(data_json[\"CumulusName\"])\n                                prop_dict[\"soundscape:NodeCategoryIntegrity\"]
          = str(data_json[\"NodeCategoryIntegrity\"])\n                                prop_dict[\"soundscape:NomenclatureNode\"]
          = str(data_json[\"NomenclatureNode\"])\n                                prop_dict[\"soundscape:SerialNumber\"]
          = str(data_json[\"SerialNumber\"])\n                                prop_dict[\"soundscape:DateDeployment\"]
          = data_json[\"DateDeployment\"]\n                                prop_dict[\"soundscape:AudioID\"]
          = data_json[\"AudioID\"]\n\n                        aspects = entry[''entry''][''aspectNames'']\n                        data
          = {\"aspectNames\": aspects, \"nodeType\": node_type, \"properties\": prop_dict}\n                        #
          update properties request\n                        update = session.put(\n                            os.getenv(\"ALFRESCO_URL\")\n                            +
          BASE_ENDPOINT\n                            + \"/nodes/\"\n                            +
          entry[''entry''][''id''],\n                            data=json.dumps(data),\n                        )\n\n                        if
          update.status_code == 200:\n                            print(\"Updated
          \" + entry[''entry''][''id''])                    \n\n        except Exception
          as e:\n            print(\"Could not add any aspect to this file: \", e)\n\n    def
          create_results_folder_str(results_dir, cumulo, nodes_list, rec_list, dep_list):
          \n        # results directory\n        os.makedirs(results_dir, exist_ok=True)\n        #
          cumulus subdir\n        cum_subdir = os.path.join(results_dir, str(cumulo))\n        os.makedirs(cum_subdir,
          exist_ok=True)\n        # node subdirs\n        for node in nodes_list:\n            node_subdir
          = os.path.join(cum_subdir, node)\n            os.makedirs(node_subdir, exist_ok=True)\n            #
          recorder subdirs\n            for rec in rec_list:\n                rec_subdir
          = os.path.join(node_subdir, rec)\n                os.makedirs(rec_subdir,
          exist_ok=True)\n                # deployment subdirs\n                for
          dep in dep_list:\n                    dep_subdir = os.path.join(rec_subdir,
          dep)\n                    os.makedirs(dep_subdir, exist_ok=True)\n\n    def
          distance_to_mean(vector, mean):\n        \\''\\''\\''Return euclidean distance
          to mean\\''\\''\\''\n        return np.sqrt(np.sum(np.square(mean - vector)))\n\n    def
          find_subfolders(path_abs):\n        subdir_list = []\n        walk = list(os.walk(path_abs))\n        for
          path, _, _ in walk[::-1]:\n            len_path = path.split(\"/\")\n            if
          len(len_path) == 8:\n                subdir_list.append(path)  \n\n        return
          subdir_list\n\n    def get_audio_ids(soundscape_path, indices, nsamples):\n        df
          = pd.read_parquet(os.path.join(soundscape_path, \"hashed_soundscape.parquet\"))\n\n        df[\"time_raw_hour\"]
          = df[\"time_raw\"].apply(lambda x: datetime.datetime.strptime(x,''%H:%M:%S
          %d/%m/%Y (%z)'').strftime(\"%H\"))\n        hours_list = list(df.time_raw_hour.unique())\n        hours_list.sort(key
          = int)\n\n        with open(os.path.join(soundscape_path, \"soundscape_metadata.json\"))
          as f:\n            metadata = json.load(f)\n            f.close()\n\n        #
          indices = metadata[\"product_configs\"][\"indices\"]\n        # indices
          = [\"EXAG\", \"ICOMPLEXITY\", \"CORE\"]\n        hash_name = metadata[\"product_configs\"][\"hash_name\"]\n        cycle_config
          = metadata[\"product_configs\"][\"hasher_config\"][\"kwargs\"]\n        time_unit
          = cycle_config[\"time_unit\"]\n        zero_t = aware_time(cycle_config[\"start_time\"],
          cycle_config[\"start_tzone\"], cycle_config[\"start_format\"]) \n\n        #
          iterate over hours\n        audio_id_list = []\n        for hour in hours_list:\n            subdf
          = df.query(f\"time_raw_hour == ''{hour}''\")\n            # sample\n            samples_df
          = get_recording_samples(subdf, hash_name, indices, time_unit, zero_t, nsamples=3)\n            unique_crono_hash_list
          = list(samples_df.crono_hash_30m.unique())\n            sub_df = samples_df[samples_df.crono_hash_30m
          == min(unique_crono_hash_list)]\n            audio_id_list += list(sub_df.id.tolist())\n\n        return
          audio_id_list\n\n    def get_recording_samples(df, hash_name, indices, time_unit,
          zero_t, nsamples=5):\n        \\''\\''\\''Return dataframe of ''nsamples''
          samples for each tag in ''hash_name'' column that are closest to the mean
          vector by tag\\''\\''\\''\n        proj_df = df[(df.max_freq <= 10000)]\n        crono_tags
          = proj_df.crono_hash_30m.unique()\n        proj_df.loc[: , f\"{hash_name}_time\"]
          = proj_df[hash_name].apply(lambda x: zero_t + datetime.timedelta(seconds=float(x*time_unit)))\n        vectors
          = vectorize_soundscape(proj_df, hash_name, indices)\n        min_index_vector
          = np.amin(np.stack(list(vectors.index_vector.values)), axis=(0,1))\n        max_index_vector
          = np.amax(np.stack(list(vectors.index_vector.values)), axis=(0,1))\n        index_range
          = (max_index_vector - min_index_vector)\n        vectors.loc[:, \"normalized_index_vector\"]
          = vectors.index_vector.apply(lambda x: (x-min_index_vector)/index_range)\n        all_samples
          = []\n\n        for crono_tag in crono_tags:\n            unit_vectors =
          vectors[vectors[hash_name] == crono_tag]\n            mean_unit_vector =
          unit_vectors.normalized_index_vector.mean()\n            unit_vectors.loc[:,
          \"distance\"] = unit_vectors.normalized_index_vector.apply(lambda x: distance_to_mean(x,
          mean_unit_vector))\n            all_samples.append(unit_vectors.sort_values(by=\"distance\").head(nsamples))\n        return
          pd.concat(all_samples)\n\n    def get_vectors(group, indices):\n        \\''\\''\\''Return
          array of indices by frequency\\''\\''\\''\n        return group.sort_values(by=\"max_freq\")[indices].values\n\n    def
          login():\n        \"\"\"\n        Tries a login to alfresco api and returns
          a session\n        object with credentials \n        Returns: \n            session
          (Session):  A session object to make \n                                requests
          to zendro.\n        \"\"\"\n        try:\n            auth = {\n                \"userId\":
          os.getenv(\"ALFRESCO_USER\"),\n                \"password\": os.getenv(\"ALFRESCO_PASSWORD\"),\n            }\n\n            login
          = requests.post(os.getenv(\"ALFRESCO_URL\") + AUTH_ENDPOINT + \"/tickets\",data=json.dumps(auth))\n\n            base64_login
          = base64.b64encode(bytes(login.json()[\"entry\"][\"id\"], ''utf-8'')).decode()\n\n            #
          se crea un objeto de Session para hacer requests\n            session =
          requests.Session()\n            # se establece bearer token\n            session.headers.update({''Authorization'':
          ''Basic '' + base64_login})\n\n            return session\n        except
          Exception as e:\n            print(\"Login failed: \", e)\n\n    def plot_spectrogram(audio_id,
          audio_df, save_path_folder, spectrum, cumulus):\n        sub_audio_df =
          audio_df[audio_df[\"id\"]==audio_id]\n        node = sub_audio_df[''node''].values[0]\n        recorder
          = sub_audio_df[''recorder''].values[0]\n        deployment = sub_audio_df[''deployment''].values[0]\n        #
          plot\n        fig, ax = plt.subplots(2,1,figsize=(20,10), sharex=True)\n        sub_audio_df.audio[0].plot(ax=ax[0],
          color=''grey'')\n        sub_audio_df.audio[0].features.db_spectrogram().plot(ax=ax[1])\n        ax[0].set_ylabel(''Amplitude'')\n        ax[0].grid(False)\n        ax[1].set_ylabel(''F
          (KHz)'')\n        ax[1].set_xlabel(''Time (seconds)'')\n        fig.text(0.75,
          0.04, f\"Cumulus: {cumulus} - Node: {node} - Recorder: {recorder}\", va=''center'')\n        plt.tight_layout()\n        if
          save_path_folder:\n            file_path = os.path.join(save_path_folder,
          f\"{audio_id}.png\")\n            fig.savefig(file_path)\n        plt.show()\n\n        save_metadata_spectrogram(audio_id,
          spectrum, save_path_folder, \n                                  cumulus,
          node, recorder, deployment, parent=\"Null\")\n\n    def plot_soundscape(soundscape,
          product_type, product_spectrum, sc_config, path, \n                        cumulus,
          node, recorder, deployment, parent, indices, min_freq=None,\n                      figsize=(20,15),
          plt_style=''ggplot''):\n\n        if min_freq:\n            soundscape =
          soundscape[soundscape[''min_freq'']<=min_freq]\n\n        if product_type
          == \"sequence\":\n            file_path = os.path.join(path, \"sequence.png\")\n            #
          product_id = hashlib.md5(file_path.encode(''utf-8'')).hexdigest()\n\n            plt.style.use(plt_style)\n            fig,
          ax = plt.subplots(figsize=figsize)\n            soundscape.sndscape.plot_sequence(rgb=indices,
          time_format=''%Y-%m %H:%M'', ax=ax)\n            plt.xticks(rotation = 90)\n            ax.grid(False)\n            plt.tight_layout()\n            plt.savefig(file_path)
          \n            plt.show()\n            # save metadata\n            save_metadata_sc(product_type,
          product_spectrum, sc_config,\n                      path, cumulus, node,
          recorder, deployment, parent=parent)\n\n        elif product_type == \"standard_deviation\":\n            file_path
          = os.path.join(path, \"std_soundscape.png\")\n            # product_id =
          hashlib.md5(file_path.encode(''utf-8'')).hexdigest()\n\n            plt.style.use(plt_style)\n            fig,
          ax = plt.subplots(figsize=figsize)\n            soundscape.sndscape.plot_cycle(rgb=indices,
          aggr=\"std\", time_format=''%H:%M'', \n                                           xticks=24,
          ax=ax)\n            plt.xticks(rotation = 90)\n            ax.grid(False)\n            plt.tight_layout()
          \n            plt.savefig(file_path)\n            plt.show()\n\n            #
          save metadata\n            save_metadata_sc(product_type, product_spectrum,
          sc_config,\n                      path, cumulus, node, recorder, deployment,
          parent)     \n\n        elif product_type == \"mean\": \n            file_path
          = os.path.join(path, \"mean_soundscape.png\")\n            # product_id
          = hashlib.md5(file_path.encode(''utf-8'')).hexdigest()\n\n            plt.style.use(plt_style)\n            fig,
          ax = plt.subplots(figsize=figsize)\n            soundscape.sndscape.plot_cycle(rgb=indices,
          aggr=\"mean\", time_format=''%H:%M'', \n                                           xticks=24,
          ax=ax)\n            plt.xticks(rotation = 90)\n            ax.grid(False)\n            plt.tight_layout()\n            plt.savefig(file_path)\n            plt.show()\n\n            #
          save metadata\n            save_metadata_sc(product_type, product_spectrum,
          sc_config,\n                      path, cumulus, node, recorder, deployment,
          parent)    \n\n        print(f\"File saved at {file_path}\")\n\n    def
          produce_clip(spec, frame_duration, min_freq, max_freq, start, stop, step,
          abs_start=None, \n                     colormap=cm.get_cmap(\"Greys\"),
          min_spec=0, spec_range=1.0, figsize=(5, 4), \n                     dpi=100,
          bands=None):\n        \\''\\''\\''Takes an individual frame and produces
          an image with references\\''\\''\\''\n        frame = spec.cut_array(start_time=start,
          end_time=stop, min_freq=min_freq, max_freq=max_freq, pad=True)\n        plt.style.use(''dark_background'')\n        frame
          = np.flip((frame - min_spec)/spec_range, axis=0)\n        fig, ax = plt.subplots(figsize=figsize)\n        ax.imshow(frame,
          cmap=colormap, extent=[0, frame_duration, min_freq/1000, max_freq/1000],
          \n                  aspect=\"auto\", vmin = 0, vmax = 1.0)\n\n        if
          bands is not None:\n            band_arr = np.flip(resize(np.expand_dims(bands,
          axis=1), (frame.shape[0], frame.shape[1])), axis=0)\n            ax.imshow(band_arr,
          extent=[0, frame_duration, min_freq/1000, max_freq/1000], aspect=\"auto\",
          vmin = 0, \n                      vmax = 1.0, alpha=0.5)\n\n        ax.tick_params(axis=''both'',
          which=''major'', labelsize=8)\n        ax.tick_params(axis=''both'', which=''minor'',
          labelsize=8)\n        mid = frame_duration/2.0\n        ax.axvline(x=mid,
          color=\"red\")\n        ax.set_ylabel(''F (kHz)'')\n        ax.set_xticks([])\n        ax.set_xticks([],
          minor=True)\n\n        if abs_start is not None:\n            time_text
          = (abs_start + datetime.timedelta(seconds=start+mid)).strftime(''%H:%M:%S.%f'').strip()[:-4]\n            ax.text(mid-0.3,
          -0.6, time_text)\n\n        buf = io.BytesIO()\n        fig.tight_layout()\n        fig.savefig(buf,
          dpi=dpi)\n        buf.seek(0)\n        im = Image.open(buf)\n        im.format
          = \"PNG\"\n        plt.close(fig)\n\n        return ImageClip(np.asarray(im),\n                         duration=step)\n\n    def
          remove_empty_folders(path_abs):\n        walk = list(os.walk(path_abs))\n        for
          path, _, _ in walk[::-1]:\n            if len(os.listdir(path)) == 0:\n                os.rmdir(path)            \n\n    def
          save_metadata_sc(product_type, product_spectrum, sc_config,\n                      path,
          cumulus, node, recorder, deployment, parent=\"Null\"):\n        if product_type
          == \"soundscape\":\n            product_name = \"Soundscape\"\n            file_path
          = os.path.join(path, \"hashed_soundscape.parquet\")\n            metadata_filename
          = os.path.join(path, \"soundscape_metadata.json\")\n        elif product_type
          == \"sequence\":\n            product_name = \"Soundscape sequential plot\"\n            file_path
          = os.path.join(path, \"soundscape_seq.png\")\n            metadata_filename
          = os.path.join(path, \"soundscape_seq_metadata.json\")\n        elif product_type
          == \"standard_deviation\":\n            product_name = \"Soundscape standard
          deviation plot\"\n            file_path = os.path.join(path, \"std_soundscape.png\")\n            metadata_filename
          = os.path.join(path, \"std_soundscape_metadata.json\")\n        elif product_type
          == \"mean\":\n            product_name = \"Soundscape mean plot\"\n            file_path
          = os.path.join(path, \"mean_soundscape.png\")\n            metadata_filename
          = os.path.join(path, \"mean_soundscape_metadata.json\")\n\n        if int(node.split(\"_\")[2])
          == 0:\n            node_category = \"Degradado\"\n        elif int(node.split(\"_\")[2])
          == 1:\n            node_category = \"Integro\"\n\n        metadata = {\n            \"product_parent\":
          parent,\n            \"product_name\": product_name,\n            \"product_configs\":
          sc_config,\n            \"product_path\": file_path,\n            \"product_spectrum\":
          product_spectrum,\n            \"CumulusName\": cumulus,\n            \"NodeCategoryIntegrity\":
          node_category,\n            \"NomenclatureNode\": node,\n            \"SerialNumber\":
          recorder,\n            \"DateDeployment\": deployment\n        }\n\n        with
          open(metadata_filename, ''w'', encoding=''utf-8'') as f:\n            json.dump(metadata,
          f, ensure_ascii=False, indent=4)\n\n    def save_metadata_spectrogram(audio_id,
          product_spectrum,\n                      path, cumulus, node, recorder,
          deployment, parent=\"Null\"):\n        # identifier is being used as audio_id
          in alfresco\n        product_name = \"Spectrogram\"\n        file_path =
          os.path.join(path, f\"{audio_id}.png\")\n        metadata_filename = os.path.join(path,
          f\"{audio_id}_spectrogram_metadata.json\")\n\n        if int(node.split(\"_\")[2])
          == 0:\n            node_category = \"Degradado\"\n        elif int(node.split(\"_\")[2])
          == 1:\n            node_category = \"Integro\"\n\n        metadata = {\n            \"product_parent\":
          parent,\n            \"product_name\": product_name,\n            \"product_path\":
          file_path,\n            \"product_spectrum\": product_spectrum,\n            \"CumulusName\":
          cumulus,\n            \"NodeCategoryIntegrity\": node_category,\n            \"NomenclatureNode\":
          node,\n            \"SerialNumber\": recorder,\n            \"DateDeployment\":
          deployment,\n            \"AudioID\": audio_id\n        }\n        with
          open(metadata_filename, ''w'', encoding=''utf-8'') as f:\n            json.dump(metadata,
          f, ensure_ascii=False, indent=4)\n\n        print(f\"{file_path} saved.\")\n        print(f\"{metadata_filename}
          saved.\")\n\n    def save_metadata_videoclip(audio_id, product_spectrum,
          path, cumulus, node, recorder, \n                                deployment,
          clip_start, clip_end, parent=\"Null\"):\n        # identifier is being used
          as audio_id in alfresco\n        product_name = \"spectrogram_video\"\n        file_path
          = os.path.join(path, f\"{audio_id}.mp4\")\n        metadata_filename = os.path.join(path,
          f\"{audio_id}_spectrogram_video_metadata.json\")\n\n        if int(node.split(\"_\")[2])
          == 0:\n            node_category = \"Degradado\"\n        elif int(node.split(\"_\")[2])
          == 1:\n            node_category = \"Integro\"\n\n        metadata = {\n            \"product_parent\":
          parent,\n            \"product_name\": product_name,\n            \"product_description\":
          \"Spectrogram Video. Time is show in local timezone\",\n            \"product_path\":
          file_path,\n            \"product_spectrum\": product_spectrum,\n            \"CumulusName\":
          cumulus,\n            \"NodeCategoryIntegrity\": node_category,\n            \"NomenclatureNode\":
          node,\n            \"SerialNumber\": recorder,\n            \"DateDeployment\":
          deployment,\n            \"ClipStart\": clip_start,\n            \"ClipEnd\":
          clip_end,\n            \"AudioID\": audio_id\n        }\n\n        with
          open(metadata_filename, ''w'', encoding=''utf-8'') as f:\n            json.dump(metadata,
          f, ensure_ascii=False, indent=4)\n\n        print(f\"{file_path} saved.\")\n        print(f\"{metadata_filename}
          saved.\")\n\n    def upload(session, node_id, data, file):\n        \"\"\"\n        Uploads
          a file to a specific folder.\n        Parameters:\n            session (Session):          A
          session object to make\n                                        requests
          to alfresco.\n            node_id (string):           Node id to which the
          file is going to be created\n            data (dict):                Dict
          that contains file options\n            file (object):              File
          to upload\n\n        Returns:\n            (list):     A list containing
          status code and status data\n        \"\"\"\n\n        try:\n            response
          = session.post(os.getenv(\"ALFRESCO_URL\")\n                        + BASE_ENDPOINT
          + \"/nodes/\" + node_id + \"/children\",\n                        data =
          data,\n                        files = file\n                        )\n\n            return
          [response.json(), response.status_code];\n        except Exception as e:
          \n            print(\"File \" + data[\"name\"] + \" could not be uploaded:
          \", e)\n\n    def upload_files(file_patterns, session, node_id, dir_path,
          recursive, file_identifier=\"\"):\n        \"\"\"\n        Uploads the files
          stored in a specific dir\n        to alfresco\n        Parameters:\n            session
          (Session):          A session object to make\n                                        requests
          to alfresco.\n            node_id (string):           Node id to which the
          file is going to be created\n            dir_path (string):          The
          name and path of the dir where files are stored\n            recursive (boolean):        A
          boolean to know if upload  must be recursive\n                                        in
          the specifed dir, and should preserve the\n                                        structure
          of dirs inside.\n            file_identifier (string):   File identifier
          for all files inside a dir\n        Returns:\n            (string):           Returns
          the info of recent created site.\n        \"\"\"\n\n        if recursive:\n            expression
          = \"/**/*\"\n        else:\n            expression = \"/*\"\n\n        files_in_dir
          = list(\n            itertools.chain.from_iterable(\n                glob.iglob(dir_path
          + expression + pattern, recursive=recursive)\n                for pattern
          in file_patterns\n            )\n        )\n        filename = \"logs/upload_log\"
          + dir_path.replace(''/'',''-'') + ''.txt''\n\n        os.makedirs(os.path.dirname(filename),
          exist_ok=True)\n\n        total_files = len(files_in_dir)\n        starttime
          = time.time()\n\n        try:\n            files_uploaded = []\n            for
          idx, file_with_path in enumerate(files_in_dir):\n\n                # total
          time since last login or script start\n                total_time = round((time.time()
          - starttime), 2)\n\n                if total_time > 2400:\n                    \"\"\"\n                    if
          total time is bigger than 2400\n                    or 40 minutes relogin
          to avoid ticket\n                    expiration\n                    \"\"\"\n                    time.sleep(5)\n\n                    print(\"Re-logging
          in to alfresco...\")\n\n                    session = login.login()\n                    #
          restart time\n                    starttime = time.time()\n                    time.sleep(5)\n                    print(\"Login
          sucessful, continuing upload\\\\n\")\n\n                len_of_path = len(file_with_path.split(\"/\"))\n                name_of_file
          = file_with_path.split(\"/\")[len_of_path - 1]\n                root_dir_path
          = file_with_path.replace(dir_path, \"\").replace(\n                    file_with_path.split(\"/\")[len_of_path
          - 1], \"\"\n                )\n\n                data = {\n                    \"name\":
          (\n                        name_of_file[0 : len(name_of_file) - 4]\n                        +
          file_identifier\n                        + name_of_file[len(name_of_file)
          - 4 : len(name_of_file)]\n                    ),\n                    \"nodeType\":
          \"cm:content\",\n                }\n\n                data[\"relativePath\"]
          = root_dir_path\n\n                data[\"properties\"] = {\n                    \"cm:title\":
          (\n                        name_of_file[0 : len(name_of_file) - 4]\n                        +
          file_identifier\n                        + name_of_file[len(name_of_file)
          - 4 : len(name_of_file)]\n                    )\n                }\n\n                print(\"Uploading
          \" + data[\"name\"] + \" file...\")\n\n                files = {\"filedata\":
          open(file_with_path, \"rb\")}\n                upload_response = upload(session,
          node_id, data, files)\n                if upload_response[1] and upload_response[1]
          == 201:\n                    files_uploaded.append(upload_response[0])\n                    print(\"Uploaded
          \" + data[\"name\"])\n\n                    filename = \"logs/upload_log\"
          + dir_path.replace(''/'',''-'') + ''.txt''\n                    with open(filename,
          ''a'') as log_file:\n                        log_file.writelines(\"%s\\\\n\"
          % file_with_path)\n\n                elif upload_response[1] and upload_response[1]
          == 409:\n                    if \"already exists\" in upload_response[0][\"error\"][\"errorKey\"]:\n                        print(\"File
          \" + data[\"name\"] + \" already uploaded\")\n\n                else:\n                    print(\"An
          error ocurred, file \" + data[\"name\"] + \" cannot be uploaded\")\n\n                print(\"Uploaded
          file \" + str(idx + 1) + \" of \" + str(total_files))\n                print(\"\\\\n\\\\n\")\n\n            return
          files_uploaded\n        except Exception as e:\n            print(\"An error
          ocurred in file upload: \", e)\n\n    def vectorize_soundscape(df, hash_name,
          indices):\n        \\''\\''\\''Return dataframe with array column containing
          indices by frequency\\''\\''\\''\n        return (df\n                .groupby(by=[\"id\",
          hash_name, \"start_time\", \"end_time\"])\n                .apply(get_vectors,
          indices)\n                .reset_index()\n                .rename(columns={0:\"index_vector\"}))\n    ''''''\n\n    _kale_block3
          = ''''''\n    FILE_PATTERNS = [\".mp4\", \".png\"] #\".parquet\"\n    load_dotenv()\n    session
          = login()\n    upload_files(FILE_PATTERNS, session, ALFRESCO_NODE_ID, RESULTS_DIR,
          recursive= True, file_identifier=\"\")\n    ''''''\n\n    # run the code
          blocks inside a jupyter kernel\n    from kale.common.jputils import run_code
          as _kale_run_code\n    from kale.common.kfputils import \\\n        update_uimetadata
          as _kale_update_uimetadata\n    _kale_blocks = (_kale_pipeline_parameters_block,\n                    _kale_block1,\n                    _kale_block2,\n                    _kale_block3,\n                    )\n    _kale_html_artifact
          = _kale_run_code(_kale_blocks)\n    with open(\"/upload_to_alfresco.html\",
          \"w\") as f:\n        f.write(_kale_html_artifact)\n    _kale_update_uimetadata(''upload_to_alfresco'')\n\n    _kale_mlmdutils.call(\"mark_execution_complete\")\n\nimport
          argparse\n_parser = argparse.ArgumentParser(prog=''Upload to alfresco'',
          description='''')\n_parser.add_argument(\"--ALFRESCO-NODE-ID\", dest=\"ALFRESCO_NODE_ID\",
          type=str, required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"--AUTH-ENDPOINT\",
          dest=\"AUTH_ENDPOINT\", type=str, required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"--BASE-ENDPOINT\",
          dest=\"BASE_ENDPOINT\", type=str, required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"--RESULTS-DIR\",
          dest=\"RESULTS_DIR\", type=str, required=True, default=argparse.SUPPRESS)\n_parsed_args
          = vars(_parser.parse_args())\n\n_outputs = upload_to_alfresco(**_parsed_args)\n"],
          "image": "sipecam/audio-dgpi-kale-tensorflow-yuntu-dask-cert:0.6.1_dev"}},
          "inputs": [{"name": "ALFRESCO_NODE_ID", "type": "String"}, {"name": "AUTH_ENDPOINT",
          "type": "String"}, {"name": "BASE_ENDPOINT", "type": "String"}, {"name":
          "RESULTS_DIR", "type": "String"}], "name": "Upload to alfresco"}', pipelines.kubeflow.org/component_ref: '{}',
        pipelines.kubeflow.org/arguments.parameters: '{"ALFRESCO_NODE_ID": "{{inputs.parameters.ALFRESCO_NODE_ID}}",
          "AUTH_ENDPOINT": "{{inputs.parameters.AUTH_ENDPOINT}}", "BASE_ENDPOINT":
          "{{inputs.parameters.BASE_ENDPOINT}}", "RESULTS_DIR": "{{inputs.parameters.RESULTS_DIR}}"}'}
      labels:
        pipelines.kubeflow.org/metadata_written: "true"
        pipelines.kubeflow.org/kfp_sdk_version: 1.8.11
        pipelines.kubeflow.org/pipeline-sdk-type: kfp
        pipelines.kubeflow.org/enable_caching: "true"
    volumes:
    - name: pvolume-ef6fe65091618f865041935b363277953274adf6b420fd4a7b8277d
      persistentVolumeClaim: {claimName: '{{inputs.parameters.vol_shared_volume}}'}
  arguments:
    parameters:
    - {name: ALFRESCO_NODE_ID, value: cf3a1b97-965d-489f-bfdf-5c8e26c4ac95}
    - {name: AUTH_ENDPOINT, value: alfresco/api/-default-/public/authentication/versions/1}
    - {name: BASE_ENDPOINT, value: alfresco/api/-default-/public/alfresco/versions/1}
    - {name: BLUE_IDX, value: CORE}
    - {name: CUMULO, value: '92'}
    - {name: FREQUENCY_BINS, value: '96'}
    - {name: FREQUENCY_LIMITS_LB, value: '0'}
    - {name: FREQUENCY_LIMITS_UB, value: '24000'}
    - {name: GREEN_IDX, value: INFORMATION}
    - {name: HASHER_TIME_MODULE, value: '48'}
    - {name: HASHER_TIME_UNIT, value: '1800'}
    - {name: HASH_NAME, value: crono_hash_30m}
    - name: LIMIT
      value: "False"
    - {name: MIN_FREQ_SC, value: '10000'}
    - {name: PAGESIZE, value: '10000'}
    - {name: RED_IDX, value: EXAG}
    - {name: RESULTS_DIR, value: /shared_volume/audio/soundscapes}
    - {name: SAMPLERATE, value: '48000.0'}
    - {name: SPECTRUM, value: Audible}
    - {name: THREADS_PER_WORKER, value: '2'}
    - {name: TIME_UNIT, value: '30'}
    - {name: VIDS_PER_HOUR, value: '3'}
    - {name: WORK_DIR_PIPELINE, value: .}
    - {name: vol_shared_volume, value: hostpath-pvc}
  serviceAccountName: pipeline-runner
