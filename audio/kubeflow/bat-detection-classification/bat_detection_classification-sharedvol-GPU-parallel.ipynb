{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Bat Detection/Classsification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "skip"
    ]
   },
   "outputs": [],
   "source": [
    "!pip install geojson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "imports"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n",
      "1 Physical GPUs, 1 Logical GPUs\n",
      "1 Physical GPUs, 1 Logical GPUs\n",
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "import base64\n",
    "import itertools\n",
    "import json\n",
    "import os\n",
    "import geojson\n",
    "import  matplotlib.pyplot as plt\n",
    "import multiprocessing \n",
    "import requests\n",
    "import shapely.wkt\n",
    "import shutil\n",
    "import time\n",
    "\n",
    "from datetime import datetime\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from dask_cuda import LocalCUDACluster\n",
    "from dask.distributed import Client\n",
    "\n",
    "from yuntu.core.geometry.intervals import TimeInterval\n",
    "from yuntu.collection.methods import collection\n",
    "from BATMX_full.probe import BATMX_probe\n",
    "from BATMX_full.utils import LABELS\n",
    "\n",
    "from termcolor import cprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "pipeline-parameters"
    ]
   },
   "outputs": [],
   "source": [
    "LIMIT = 1000\n",
    "# alfresco query\n",
    "CUMULUS = 13 # INT\n",
    "PAGESIZE = 5000\n",
    "\n",
    "# probe config\n",
    "DETECTION_THRESOLHOLD = 0.5\n",
    "MIN_ANN_DURATION = 0.05\n",
    "BATCH_SIZE = 50\n",
    "DETECTION_THRESHOLD = 0.9\n",
    "\n",
    "# Dask\n",
    "N_WORKERS = 2\n",
    "\n",
    "# results directory\n",
    "RESULTS_DIR = \"/shared_volume_efs/audio/bat_detection_classification/bat-detection\"\n",
    "\n",
    "# upload to alfresco\n",
    "ALFRESCO_NODE_ID = \"031a7669-335a-4c9d-bb36-89d595201309\"\n",
    "BASE_ENDPOINT = \"alfresco/api/-default-/public/alfresco/versions/1\"\n",
    "AUTH_ENDPOINT = \"alfresco/api/-default-/public/authentication/versions/1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [
     "functions"
    ]
   },
   "outputs": [],
   "source": [
    "def convert2geoJson(wkt_string):\n",
    "    # Convert to a shapely.geometry.polygon.Polygon object\n",
    "    g1 = shapely.wkt.loads(wkt_string)\n",
    "    g2 = geojson.Feature(geometry=g1, properties={})\n",
    "    \n",
    "    return g2.geometry\n",
    "\n",
    "def create_results_folder_str(results_dir, cumulo, nodes_list, rec_list, dep_list): \n",
    "    # results directory\n",
    "    os.makedirs(results_dir, exist_ok=True)\n",
    "    # cumulus subdir\n",
    "    cum_subdir = os.path.join(results_dir, str(cumulo))\n",
    "    os.makedirs(cum_subdir, exist_ok=True)\n",
    "    # node subdirs\n",
    "    for node in nodes_list:\n",
    "        node_subdir = os.path.join(cum_subdir, node)\n",
    "        os.makedirs(node_subdir, exist_ok=True)\n",
    "        # recorder subdirs\n",
    "        for rec in rec_list:\n",
    "            rec_subdir = os.path.join(node_subdir, rec)\n",
    "            os.makedirs(rec_subdir, exist_ok=True)\n",
    "            # deployment subdirs\n",
    "            for dep in dep_list:\n",
    "                dep_subdir = os.path.join(rec_subdir, dep)\n",
    "                os.makedirs(dep_subdir, exist_ok=True)\n",
    "                \n",
    "def filter_pred(entry, detection_threshold=0.8):\n",
    "    if entry['metadata']['score']['detection']['mean'] >= detection_threshold:\n",
    "        return entry\n",
    "    \n",
    "def filter_pred_list(pred_list, detection_threshold):\n",
    "    filtered_preds = [filter_pred(e, detection_threshold) for e in pred_list]\n",
    "    filtered_preds = [i for i in filtered_preds if i != None] \n",
    "    return filtered_preds\n",
    "    \n",
    "def login():\n",
    "    \"\"\"\n",
    "    Tries a login to alfresco api and returns a session\n",
    "    object with credentials \n",
    "    Returns: \n",
    "        session (Session):  A session object to make \n",
    "                            requests to zendro.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        auth = {\n",
    "            \"userId\": os.getenv(\"ALFRESCO_USER\"),\n",
    "            \"password\": os.getenv(\"ALFRESCO_PASSWORD\"),\n",
    "        }\n",
    "\n",
    "        login = requests.post(os.getenv(\"ALFRESCO_URL\") + AUTH_ENDPOINT + \"/tickets\",data=json.dumps(auth))\n",
    "\n",
    "        base64_login = base64.b64encode(bytes(login.json()[\"entry\"][\"id\"], 'utf-8')).decode()\n",
    "\n",
    "        # se crea un objeto de Session para hacer requests\n",
    "        session = requests.Session()\n",
    "        # se establece bearer token\n",
    "        session.headers.update({'Authorization': 'Basic ' + base64_login})\n",
    "\n",
    "        return session\n",
    "    except Exception as e:\n",
    "        print(\"Login failed: \", e)\n",
    "                \n",
    "def remove_empty_folders(path_abs):\n",
    "    walk = list(os.walk(path_abs))\n",
    "    for path, _, _ in walk[::-1]:\n",
    "        if len(os.listdir(path)) == 0:\n",
    "            os.rmdir(path)    \n",
    "\n",
    "def get_annotation_list(audio_id, annotations_df):\n",
    "    annotations_list = []\n",
    "    for idx_ann, ann in annotations_df.iterrows():\n",
    "        ann_dict = {\n",
    "            \"observation_type\" : \"animal\",\n",
    "            \"file_id\" : audio_id,\n",
    "            \"geometry\" : convert2geoJson(str(ann[\"geometry\"])),\n",
    "            \"video_frame_num\" : int(idx_ann + 1),\n",
    "            \"frequency_min\" : float(ann[\"min_freq\"]),\n",
    "            \"frequency_max\" : float(ann[\"max_freq\"]),\n",
    "            \"time_min\" : float(ann[\"start_time\"]),\n",
    "            \"time_max\" : float(ann[\"end_time\"]),\n",
    "            \"metadata\" : ann[\"metadata\"],\n",
    "#             \"updatedAt\" : datetime.now(),\n",
    "#             \"createdAt\" : datetime.now()\n",
    "        }\n",
    "        annotations_list.append(ann_dict) \n",
    "            \n",
    "    #save file\n",
    "    return annotations_list    \n",
    "    \n",
    "def plot_annotated_audio(audio_obj, audio_id, annotations_df, cumulus, node, recorder, deployment,  save_path_folder=False, figsize=(20,10)):\n",
    "    ax = audio_obj.features.db_spectrogram().plot(figsize=figsize)\n",
    "    ax.set_ylabel('F (KHz)')\n",
    "    for _, ann in annotations_df.iterrows():\n",
    "        geom = TimeInterval(start_time=ann[\"start_time\"],\n",
    "                            end_time=ann[\"end_time\"])\n",
    "        geom.plot(ax=ax)  \n",
    "\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_path_folder:\n",
    "        file_path = os.path.join(save_path_folder, f\"{audio_id}_annSpectrogram.png\")\n",
    "        plt.savefig(file_path)\n",
    "    # plt.show()\n",
    "    \n",
    "    save_metadata_annotated_spectrogram(audio_id, save_path_folder, \n",
    "                              cumulus, node, recorder, deployment, parent=\"Null\")\n",
    "            \n",
    "def remove_empty_folders(path_abs):\n",
    "    walk = list(os.walk(path_abs))\n",
    "    for path, _, _ in walk[::-1]:\n",
    "        if len(os.listdir(path)) == 0:\n",
    "            os.rmdir(path)  \n",
    "            \n",
    "def save_metadata_annotated_spectrogram(audio_id,\n",
    "                  path, cumulus, node, recorder, deployment, parent=\"Null\"):\n",
    "\n",
    "    product_name = \"Spectrogram - Bat detection and classification\"\n",
    "    file_path = os.path.join(path, f\"{audio_id}_annSpectrogram.png\")\n",
    "    metadata_filename = os.path.join(path, f\"{audio_id}_annSpectrogram_metadata.json\")\n",
    "\n",
    "    if int(node.split(\"_\")[2]) == 0:\n",
    "        node_category = \"Degradado\"\n",
    "    elif int(node.split(\"_\")[2]) == 1:\n",
    "        node_category = \"Integro\"\n",
    "\n",
    "    metadata = {\n",
    "        \"product_parent\": parent,\n",
    "        \"product_name\": product_name,\n",
    "        \"product_path\": file_path,\n",
    "        \"product_spectrum\": \"Ultrasonic\",\n",
    "        \"CumulusName\": cumulus,\n",
    "        \"NodeCategoryIntegrity\": node_category,\n",
    "        \"NomenclatureNode\": node,\n",
    "        \"SerialNumber\": recorder,\n",
    "        \"DateDeployment\": deployment,\n",
    "        \"AudioID\": audio_id\n",
    "    }\n",
    "    with open(metadata_filename, 'w', encoding='utf-8') as f:\n",
    "        json.dump(metadata, f, ensure_ascii=False, indent=4)\n",
    "        \n",
    "    # print(f\"{file_path} saved.\")\n",
    "    print(f\"{metadata_filename} saved.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "block:create_audio_collection"
    ]
   },
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "DB_CONFIG = {\n",
    "    'provider': 'alfresco',\n",
    "    'config': {\n",
    "        'api_url': 'https://api.conabio.gob.mx/alfresco/',\n",
    "        'page_size': PAGESIZE,\n",
    "        'api_key': os.getenv(\"X_API_KEY\"),\n",
    "        'base_filter': \"+TYPE: \\\"sipecam:Audio\\\" AND -TYPE:\\\"dummy\\\"\",\n",
    "        'recording_parser': {\"path\": \"/shared_volume_efs/audio/bat_detection_classification/utils.py\",\n",
    "                             \"object_name\": \"parser\"}\n",
    "        \n",
    "    }\n",
    "}\n",
    "COL_CONFIG = {\n",
    "    \"col_type\": \"alfresco\",\n",
    "    \"db_config\": DB_CONFIG\n",
    "}\n",
    "\n",
    "col = collection(**COL_CONFIG)\n",
    "query = f\"(sipecam:CumulusName:\\\"{CUMULUS}\\\")\"  # AND (sipecam:SampleRate:{SAMPLERATE})\n",
    "\n",
    "if LIMIT:\n",
    "    recs = col.get_recording_dataframe(query, limit=LIMIT, with_metadata = True, with_geometry = False)\n",
    "else:\n",
    "    recs = col.get_recording_dataframe(query, with_metadata = True, with_geometry = False)\n",
    "\n",
    "# include filtering columns for processing units\n",
    "recs = recs[recs[\"spectrum\"]==\"ultrasonic\"]\n",
    "recs.loc[:, \"node\"] = recs.metadata.apply(lambda x: x[\"entry\"][\"properties\"][\"sipecam:NomenclatureNode\"])\n",
    "recs.loc[:, \"recorder\"] = recs.metadata.apply(lambda x: x[\"entry\"][\"properties\"][\"sipecam:SerialNumber\"]) \n",
    "recs.loc[:, \"deployment\"] = recs.metadata.apply(lambda x: x[\"entry\"][\"path\"][\"name\"].split(\"/audio\")[0].split(\"/\")[-1])\n",
    "recs.loc[:,\"proc_unit\"] = recs.apply(lambda x: (x[\"node\"], x[\"recorder\"], x[\"deployment\"]), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Folder structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "block:create_folder_structure",
     "prev:create_audio_collection"
    ]
   },
   "outputs": [],
   "source": [
    "# create results folder structure\n",
    "nodes_list = recs.node.unique()\n",
    "recorders_list = recs.recorder.unique()\n",
    "deployments_list = recs.deployment.unique()\n",
    "if os.path.isdir(RESULTS_DIR):\n",
    "    shutil.rmtree(RESULTS_DIR)\n",
    "create_results_folder_str(RESULTS_DIR, CUMULUS, nodes_list, recorders_list, deployments_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Probe processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "block:detection_classification",
     "prev:create_folder_structure",
     "prev:create_audio_collection",
     "limit:nvidia.com/gpu:2"
    ]
   },
   "outputs": [],
   "source": [
    "PROBE_CONFIG = {\n",
    "    \"module\": {\n",
    "        \"path\": \"/shared_volume_efs/audio/bat_detection_classification/BATMX_full/probe.py\",\n",
    "        \"object_name\": \"BATMX_probe\"\n",
    "    },\n",
    "    \"kwargs\": {},\n",
    "    \"annotate_args\": {\n",
    "        \"detection_threshold\": DETECTION_THRESOLHOLD,\n",
    "        \"min_ann_duration\": 0.05,\n",
    "        \"batch_size\": 200\n",
    "    },\n",
    "    \"use_metadata\": False,\n",
    "    \"use_annotations\": False\n",
    "}\n",
    "\n",
    "\n",
    "cluster = LocalCUDACluster()\n",
    "client = Client(cluster)\n",
    "npartitions=len(client.ncores())\n",
    "\n",
    "# process audio for each processing-unit\n",
    "start_time = time.time()\n",
    "proc_units = recs.proc_unit.unique()\n",
    "not_processed_units = []\n",
    "for proc_unit in proc_units:\n",
    "    node, recorder, deployment = proc_unit\n",
    "    print(f\"* Processing: node {node} | recorder {recorder} | deployment date {deployment}\")\n",
    "    file_path = os.path.join(RESULTS_DIR, str(CUMULUS), str(node), recorder, deployment)\n",
    "    unit_audio_col_df = recs[recs.proc_unit == proc_unit]\n",
    "    audio_ids_list = unit_audio_col_df.id.unique().tolist() # list of audios\n",
    "    print(f\"\\tNumber of audios in df: {unit_audio_col_df.shape[0]}\")\n",
    "    # apply probe to each audio\n",
    "    annotations_df = unit_audio_col_df.audio.apply_probe(PROBE_CONFIG, client=client, npartitions=npartitions, \n",
    "                                                         work_dir=\"/shared_volume_efs/audio/bat_detection_classification/\")\n",
    "    elapsed = time.time() - start_time\n",
    "    print(f\"Elapsed: {(elapsed)/60} mins\")\n",
    "    \n",
    "    # for each audio plot annotations\n",
    "    for audio_id in [audio_ids_list]:\n",
    "        sub_ann_df = annotations_df.query(f\"recording=='{audio_id}'\").reset_index(drop=True) \n",
    "        sub_ann_df.loc[:, \"detection_score\"] = sub_ann_df.metadata.apply(lambda x: x[\"score\"][\"detection\"][\"mean\"]) \n",
    "        sub_ann_df = sub_ann_df.query(f\"detection_score >= {DETECTION_THRESHOLD}\")\n",
    "        print(f\"# Annotations {sub_ann_df.shape[0]}\")\n",
    "        audio_obj = unit_audio_col_df.query(f\"id=='{audio_id}'\")\n",
    "        alfresco_id = audio_obj.iloc[0][\"metadata\"][\"entry\"]['id']\n",
    "\n",
    "        if sub_ann_df.shape[0] > 0: # has at least one annotation\n",
    "            print(f\"\\t-Processing audio: {audio_id}\")\n",
    "            plot_annotated_audio(audio_obj.audio[0], \n",
    "                                 alfresco_id, sub_ann_df,\n",
    "                                 CUMULUS, node, recorder, deployment, \n",
    "                                 save_path_folder=file_path)  \n",
    "            \n",
    "            # save metadata from annotations list\n",
    "            annotations_list = get_annotation_list(audio_id, sub_ann_df)\n",
    "            annotations_dict = {}\n",
    "            for idx, ann in enumerate(annotations_list):\n",
    "                annotations_dict[str(idx)] = ann\n",
    "                \n",
    "            file_path_ann_metadata = os.path.join(file_path, f\"{audio_id}_annotations_metadata.json\")\n",
    "            with open(file_path_ann_metadata, 'w', encoding='utf-8') as f:\n",
    "                json.dump(annotations_dict, f, ensure_ascii=False, indent=4)\n",
    "        else:\n",
    "            print(f\"\\t-Skipping audio: {audio_id}\")\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"Total time {(start_time - end_time)/60}\")\n",
    "client.close()\n",
    "cluster.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each audio plot annotations\n",
    "for audio_id in audio_ids_list:\n",
    "    sub_ann_df = annotations_df.query(f\"recording=='{audio_id}'\").reset_index(drop=True) \n",
    "    sub_ann_df.loc[:, \"detection_score\"] = sub_ann_df.metadata.apply(lambda x: x[\"score\"][\"detection\"][\"mean\"]) \n",
    "    sub_ann_df = sub_ann_df.query(f\"detection_score >= {DETECTION_THRESHOLD}\")\n",
    "    print(f\"# Annotations {sub_ann_df.shape[0]}\")\n",
    "    audio_obj = unit_audio_col_df.query(f\"id=='{audio_id}'\")\n",
    "    alfresco_id = audio_obj.iloc[0][\"metadata\"][\"entry\"]['id']\n",
    "\n",
    "    if sub_ann_df.shape[0] > 0: # has at least one annotation\n",
    "        print(f\"\\t-Processing audio: {audio_id}\")\n",
    "        plot_annotated_audio(audio_obj.audio[0], \n",
    "                             alfresco_id, sub_ann_df,\n",
    "                             CUMULUS, node, recorder, deployment, \n",
    "                             save_path_folder=file_path)  \n",
    "\n",
    "        # save metadata from annotations list\n",
    "        annotations_list = get_annotation_list(audio_id, sub_ann_df)\n",
    "        annotations_dict = {}\n",
    "        for idx, ann in enumerate(annotations_list):\n",
    "            annotations_dict[str(idx)] = ann\n",
    "\n",
    "        file_path_ann_metadata = os.path.join(file_path, f\"{audio_id}_annotations_metadata.json\")\n",
    "        with open(file_path_ann_metadata, 'w', encoding='utf-8') as f:\n",
    "            json.dump(annotations_dict, f, ensure_ascii=False, indent=4)\n",
    "    else:\n",
    "        print(f\"\\t-Skipping audio: {audio_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write metadata to Zendro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Remove empty subdirectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_empty_folders(RESULTS_DIR)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "kubeflow_notebook": {
   "autosnapshot": false,
   "docker_image": "sipecam/audio-dgpi-kale-tensorflow-yuntu-dask-gpu-cert:0.6.1_alfresco",
   "experiment": {
    "id": "9781c353-80ec-416a-8557-a802c70b7523",
    "name": "Default"
   },
   "experiment_name": "Default",
   "katib_metadata": {
    "algorithm": {
     "algorithmName": "grid"
    },
    "maxFailedTrialCount": 3,
    "maxTrialCount": 12,
    "objective": {
     "objectiveMetricName": "",
     "type": "minimize"
    },
    "parallelTrialCount": 3,
    "parameters": []
   },
   "katib_run": false,
   "pipeline_description": "Bat detection and clssification using cumulus, node, recorder and deployment",
   "pipeline_name": "bat-detectclassif-nod-rec-dep-gpu",
   "snapshot_volumes": false,
   "steps_defaults": [],
   "volume_access_mode": "rwm",
   "volumes": [
    {
     "annotations": [],
     "mount_point": "/shared_volume",
     "name": "hostpath-pvc",
     "size": 1,
     "size_type": "Gi",
     "snapshot": false,
     "snapshot_name": "",
     "type": "pvc"
    }
   ]
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
